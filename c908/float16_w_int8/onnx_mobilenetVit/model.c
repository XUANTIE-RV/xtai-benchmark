/* auto generate by HHB_VERSION 3.0.26-beta */

#include <csi_nn.h>

void *csinn_(char *params_base) {
  struct csinn_session *sess = csinn_alloc_session();
  sess->base_run_mode = CSINN_RM_CPU_GRAPH;
  sess->base_quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  sess->model.save_mode = CSINN_RUN_ONLY;
  sess->base_api = CSINN_C908;
  sess->base_dtype = CSINN_DTYPE_FLOAT16;
  sess->dynamic_shape = CSINN_FALSE;
  csinn_session_init(sess);
  csinn_set_input_number(1, sess);
  csinn_set_output_number(1, sess);

  struct csinn_tensor *input = csinn_alloc_tensor(sess);
  input->name = "input@@conv2d_/conv_1/block/conv/Conv_1_fuse_bias_add_/conv_1/block/conv/Conv_2_0";
  input->dtype = CSINN_DTYPE_FLOAT16;
  input->layout = CSINN_LAYOUT_NCHW;
  input->dim[0] = 1;
  input->dim[1] = 3;
  input->dim[2] = 256;
  input->dim[3] = 256;
  input->dim_count = 4;
  memcpy(input->qinfo, params_base + 0, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *output_0 = csinn_alloc_tensor(sess);
  output_0->name = "output_0";
  output_0->dtype = CSINN_DTYPE_FLOAT16;
  output_0->layout = CSINN_LAYOUT_NCHW;
  output_0->dim[0] = 1;
  output_0->dim[1] = 16;
  output_0->dim[2] = 128;
  output_0->dim[3] = 128;
  output_0->dim_count = 4;
  memcpy(output_0->qinfo, params_base + 24, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_0 = csinn_alloc_tensor(sess);
  kernel_0->name = "kernel_0";
  kernel_0->data = params_base + 432;
  kernel_0->is_const = 1;
  kernel_0->dtype = CSINN_DTYPE_INT8;
  kernel_0->layout = CSINN_LAYOUT_OIHW;
  kernel_0->dim[0] = 16;
  kernel_0->dim[1] = 3;
  kernel_0->dim[2] = 3;
  kernel_0->dim[3] = 3;
  kernel_0->dim_count = 4;
  csinn_realloc_quant_info(kernel_0, 16);
  memcpy(kernel_0->qinfo, params_base + 48, sizeof(struct csinn_quant_info) * 16);
  struct csinn_tensor *bias_0 = csinn_alloc_tensor(sess);
  bias_0->name = "bias_0";
  bias_0->data = params_base + 1248;
  bias_0->is_const = 1;
  bias_0->dtype = CSINN_DTYPE_FLOAT16;
  bias_0->layout = CSINN_LAYOUT_O;
  bias_0->dim[0] = 16;
  bias_0->dim_count = 1;
  csinn_realloc_quant_info(bias_0, 16);
  memcpy(bias_0->qinfo, params_base + 864, sizeof(struct csinn_quant_info) * 16);
  struct csinn_conv2d_params *params_0 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_0->group = 1;
  params_0->stride_height = 2;
  params_0->stride_width = 2;
  params_0->dilation_height = 1;
  params_0->dilation_width = 1;
  params_0->conv_extra.kernel_tm = NULL;
  params_0->conv_extra.conv_mode = CSINN_DIRECT;
  params_0->pad_top = 1;
  params_0->pad_left = 1;
  params_0->pad_down = 1;
  params_0->pad_right = 1;
  params_0->base.name = "conv2d_/conv_1/block/conv/Conv_1_fuse_bias_add_/conv_1/block/conv/Conv_2";
  params_0->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(input, output_0, kernel_0, bias_0, params_0);
  struct csinn_tensor *output_2 = csinn_alloc_tensor(sess);
  output_2->name = "output_2";
  output_2->dtype = CSINN_DTYPE_FLOAT16;
  output_2->layout = CSINN_LAYOUT_NCHW;
  output_2->dim[0] = 1;
  output_2->dim[1] = 16;
  output_2->dim[2] = 128;
  output_2->dim[3] = 128;
  output_2->dim_count = 4;
  memcpy(output_2->qinfo, params_base + 1280, sizeof(struct csinn_quant_info) * 1);
  struct csinn_sigmoid_params *params_2 = csinn_alloc_params(sizeof(struct csinn_sigmoid_params), sess);
  params_2->base.name = "sigmoid_/conv_1/block/act/Sigmoid_3";
  params_2->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_sigmoid_init(output_0, output_2, params_2);
  struct csinn_tensor *output_3 = csinn_alloc_tensor(sess);
  output_3->name = "output_3";
  output_3->dtype = CSINN_DTYPE_FLOAT16;
  output_3->layout = CSINN_LAYOUT_NCHW;
  output_3->dim[0] = 1;
  output_3->dim[1] = 16;
  output_3->dim[2] = 128;
  output_3->dim[3] = 128;
  output_3->dim_count = 4;
  memcpy(output_3->qinfo, params_base + 1304, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_3 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_3->base.name = "multiply_/conv_1/block/act/Mul_4";
  params_3->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_mul_init(output_0, output_2, output_3, params_3);
  struct csinn_tensor *output_5 = csinn_alloc_tensor(sess);
  output_5->name = "output_5";
  output_5->dtype = CSINN_DTYPE_FLOAT16;
  output_5->layout = CSINN_LAYOUT_NCHW;
  output_5->dim[0] = 1;
  output_5->dim[1] = 64;
  output_5->dim[2] = 128;
  output_5->dim[3] = 128;
  output_5->dim_count = 4;
  memcpy(output_5->qinfo, params_base + 1328, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_5 = csinn_alloc_tensor(sess);
  kernel_5->name = "kernel_5";
  kernel_5->data = params_base + 2888;
  kernel_5->is_const = 1;
  kernel_5->dtype = CSINN_DTYPE_INT8;
  kernel_5->layout = CSINN_LAYOUT_OIHW;
  kernel_5->dim[0] = 64;
  kernel_5->dim[1] = 16;
  kernel_5->dim[2] = 1;
  kernel_5->dim[3] = 1;
  kernel_5->dim_count = 4;
  csinn_realloc_quant_info(kernel_5, 64);
  memcpy(kernel_5->qinfo, params_base + 1352, sizeof(struct csinn_quant_info) * 64);
  struct csinn_tensor *bias_5 = csinn_alloc_tensor(sess);
  bias_5->name = "bias_5";
  bias_5->data = params_base + 5448;
  bias_5->is_const = 1;
  bias_5->dtype = CSINN_DTYPE_FLOAT16;
  bias_5->layout = CSINN_LAYOUT_O;
  bias_5->dim[0] = 64;
  bias_5->dim_count = 1;
  csinn_realloc_quant_info(bias_5, 64);
  memcpy(bias_5->qinfo, params_base + 3912, sizeof(struct csinn_quant_info) * 64);
  struct csinn_conv2d_params *params_5 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_5->group = 1;
  params_5->stride_height = 1;
  params_5->stride_width = 1;
  params_5->dilation_height = 1;
  params_5->dilation_width = 1;
  params_5->conv_extra.kernel_tm = NULL;
  params_5->conv_extra.conv_mode = CSINN_DIRECT;
  params_5->pad_top = 0;
  params_5->pad_left = 0;
  params_5->pad_down = 0;
  params_5->pad_right = 0;
  params_5->base.name = "conv2d_/layer_1/layer_1.0/block/exp_1x1/block/conv/Conv_5_fuse_bias_add_/layer_1/layer_1.0/block/exp_1x1/block/conv/Conv_6";
  params_5->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_3, output_5, kernel_5, bias_5, params_5);
  struct csinn_tensor *output_7 = csinn_alloc_tensor(sess);
  output_7->name = "output_7";
  output_7->dtype = CSINN_DTYPE_FLOAT16;
  output_7->layout = CSINN_LAYOUT_NCHW;
  output_7->dim[0] = 1;
  output_7->dim[1] = 64;
  output_7->dim[2] = 128;
  output_7->dim[3] = 128;
  output_7->dim_count = 4;
  memcpy(output_7->qinfo, params_base + 5576, sizeof(struct csinn_quant_info) * 1);
  struct csinn_sigmoid_params *params_7 = csinn_alloc_params(sizeof(struct csinn_sigmoid_params), sess);
  params_7->base.name = "sigmoid_/layer_1/layer_1.0/block/exp_1x1/block/act/Sigmoid_7";
  params_7->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_sigmoid_init(output_5, output_7, params_7);
  struct csinn_tensor *output_8 = csinn_alloc_tensor(sess);
  output_8->name = "output_8";
  output_8->dtype = CSINN_DTYPE_FLOAT16;
  output_8->layout = CSINN_LAYOUT_NCHW;
  output_8->dim[0] = 1;
  output_8->dim[1] = 64;
  output_8->dim[2] = 128;
  output_8->dim[3] = 128;
  output_8->dim_count = 4;
  memcpy(output_8->qinfo, params_base + 5600, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_8 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_8->base.name = "multiply_/layer_1/layer_1.0/block/exp_1x1/block/act/Mul_8";
  params_8->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_mul_init(output_5, output_7, output_8, params_8);
  struct csinn_tensor *output_10 = csinn_alloc_tensor(sess);
  output_10->name = "output_10";
  output_10->dtype = CSINN_DTYPE_FLOAT16;
  output_10->layout = CSINN_LAYOUT_NCHW;
  output_10->dim[0] = 1;
  output_10->dim[1] = 64;
  output_10->dim[2] = 128;
  output_10->dim[3] = 128;
  output_10->dim_count = 4;
  memcpy(output_10->qinfo, params_base + 5624, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_10 = csinn_alloc_tensor(sess);
  kernel_10->name = "kernel_10";
  kernel_10->data = params_base + 7184;
  kernel_10->is_const = 1;
  kernel_10->dtype = CSINN_DTYPE_INT8;
  kernel_10->layout = CSINN_LAYOUT_OIHW;
  kernel_10->dim[0] = 64;
  kernel_10->dim[1] = 1;
  kernel_10->dim[2] = 3;
  kernel_10->dim[3] = 3;
  kernel_10->dim_count = 4;
  csinn_realloc_quant_info(kernel_10, 64);
  memcpy(kernel_10->qinfo, params_base + 5648, sizeof(struct csinn_quant_info) * 64);
  struct csinn_tensor *bias_10 = csinn_alloc_tensor(sess);
  bias_10->name = "bias_10";
  bias_10->data = params_base + 9296;
  bias_10->is_const = 1;
  bias_10->dtype = CSINN_DTYPE_FLOAT16;
  bias_10->layout = CSINN_LAYOUT_O;
  bias_10->dim[0] = 64;
  bias_10->dim_count = 1;
  csinn_realloc_quant_info(bias_10, 64);
  memcpy(bias_10->qinfo, params_base + 7760, sizeof(struct csinn_quant_info) * 64);
  struct csinn_conv2d_params *params_10 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_10->group = 64;
  params_10->stride_height = 1;
  params_10->stride_width = 1;
  params_10->dilation_height = 1;
  params_10->dilation_width = 1;
  params_10->conv_extra.kernel_tm = NULL;
  params_10->conv_extra.conv_mode = CSINN_DIRECT;
  params_10->pad_top = 1;
  params_10->pad_left = 1;
  params_10->pad_down = 1;
  params_10->pad_right = 1;
  params_10->base.name = "conv2d_/layer_1/layer_1.0/block/conv_3x3/block/conv/Conv_9_fuse_bias_add_/layer_1/layer_1.0/block/conv_3x3/block/conv/Conv_10";
  params_10->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_8, output_10, kernel_10, bias_10, params_10);
  struct csinn_tensor *output_12 = csinn_alloc_tensor(sess);
  output_12->name = "output_12";
  output_12->dtype = CSINN_DTYPE_FLOAT16;
  output_12->layout = CSINN_LAYOUT_NCHW;
  output_12->dim[0] = 1;
  output_12->dim[1] = 64;
  output_12->dim[2] = 128;
  output_12->dim[3] = 128;
  output_12->dim_count = 4;
  memcpy(output_12->qinfo, params_base + 9424, sizeof(struct csinn_quant_info) * 1);
  struct csinn_sigmoid_params *params_12 = csinn_alloc_params(sizeof(struct csinn_sigmoid_params), sess);
  params_12->base.name = "sigmoid_/layer_1/layer_1.0/block/conv_3x3/block/act/Sigmoid_11";
  params_12->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_sigmoid_init(output_10, output_12, params_12);
  struct csinn_tensor *output_13 = csinn_alloc_tensor(sess);
  output_13->name = "output_13";
  output_13->dtype = CSINN_DTYPE_FLOAT16;
  output_13->layout = CSINN_LAYOUT_NCHW;
  output_13->dim[0] = 1;
  output_13->dim[1] = 64;
  output_13->dim[2] = 128;
  output_13->dim[3] = 128;
  output_13->dim_count = 4;
  memcpy(output_13->qinfo, params_base + 9448, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_13 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_13->base.name = "multiply_/layer_1/layer_1.0/block/conv_3x3/block/act/Mul_12";
  params_13->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_mul_init(output_10, output_12, output_13, params_13);
  struct csinn_tensor *output_15 = csinn_alloc_tensor(sess);
  output_15->name = "output_15";
  output_15->dtype = CSINN_DTYPE_FLOAT16;
  output_15->layout = CSINN_LAYOUT_NCHW;
  output_15->dim[0] = 1;
  output_15->dim[1] = 32;
  output_15->dim[2] = 128;
  output_15->dim[3] = 128;
  output_15->dim_count = 4;
  memcpy(output_15->qinfo, params_base + 9472, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_15 = csinn_alloc_tensor(sess);
  kernel_15->name = "kernel_15";
  kernel_15->data = params_base + 10264;
  kernel_15->is_const = 1;
  kernel_15->dtype = CSINN_DTYPE_INT8;
  kernel_15->layout = CSINN_LAYOUT_OIHW;
  kernel_15->dim[0] = 32;
  kernel_15->dim[1] = 64;
  kernel_15->dim[2] = 1;
  kernel_15->dim[3] = 1;
  kernel_15->dim_count = 4;
  csinn_realloc_quant_info(kernel_15, 32);
  memcpy(kernel_15->qinfo, params_base + 9496, sizeof(struct csinn_quant_info) * 32);
  struct csinn_tensor *bias_15 = csinn_alloc_tensor(sess);
  bias_15->name = "bias_15";
  bias_15->data = params_base + 13080;
  bias_15->is_const = 1;
  bias_15->dtype = CSINN_DTYPE_FLOAT16;
  bias_15->layout = CSINN_LAYOUT_O;
  bias_15->dim[0] = 32;
  bias_15->dim_count = 1;
  csinn_realloc_quant_info(bias_15, 32);
  memcpy(bias_15->qinfo, params_base + 12312, sizeof(struct csinn_quant_info) * 32);
  struct csinn_conv2d_params *params_15 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_15->group = 1;
  params_15->stride_height = 1;
  params_15->stride_width = 1;
  params_15->dilation_height = 1;
  params_15->dilation_width = 1;
  params_15->conv_extra.kernel_tm = NULL;
  params_15->conv_extra.conv_mode = CSINN_DIRECT;
  params_15->pad_top = 0;
  params_15->pad_left = 0;
  params_15->pad_down = 0;
  params_15->pad_right = 0;
  params_15->base.name = "conv2d_/layer_1/layer_1.0/block/red_1x1/block/conv/Conv_13_fuse_bias_add_/layer_1/layer_1.0/block/red_1x1/block/conv/Conv_14";
  params_15->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_13, output_15, kernel_15, bias_15, params_15);
  struct csinn_tensor *output_16 = csinn_alloc_tensor(sess);
  output_16->name = "output_16";
  output_16->dtype = CSINN_DTYPE_FLOAT16;
  output_16->layout = CSINN_LAYOUT_NCHW;
  output_16->dim[0] = 1;
  output_16->dim[1] = 128;
  output_16->dim[2] = 128;
  output_16->dim[3] = 128;
  output_16->dim_count = 4;
  memcpy(output_16->qinfo, params_base + 13144, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_16 = csinn_alloc_tensor(sess);
  kernel_16->name = "kernel_16";
  kernel_16->data = params_base + 16240;
  kernel_16->is_const = 1;
  kernel_16->dtype = CSINN_DTYPE_INT8;
  kernel_16->layout = CSINN_LAYOUT_OIHW;
  kernel_16->dim[0] = 128;
  kernel_16->dim[1] = 32;
  kernel_16->dim[2] = 1;
  kernel_16->dim[3] = 1;
  kernel_16->dim_count = 4;
  csinn_realloc_quant_info(kernel_16, 128);
  memcpy(kernel_16->qinfo, params_base + 13168, sizeof(struct csinn_quant_info) * 128);
  struct csinn_tensor *bias_16 = csinn_alloc_tensor(sess);
  bias_16->name = "bias_16";
  bias_16->data = params_base + 23408;
  bias_16->is_const = 1;
  bias_16->dtype = CSINN_DTYPE_FLOAT16;
  bias_16->layout = CSINN_LAYOUT_O;
  bias_16->dim[0] = 128;
  bias_16->dim_count = 1;
  csinn_realloc_quant_info(bias_16, 128);
  memcpy(bias_16->qinfo, params_base + 20336, sizeof(struct csinn_quant_info) * 128);
  struct csinn_conv2d_params *params_16 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_16->group = 1;
  params_16->stride_height = 1;
  params_16->stride_width = 1;
  params_16->dilation_height = 1;
  params_16->dilation_width = 1;
  params_16->conv_extra.kernel_tm = NULL;
  params_16->conv_extra.conv_mode = CSINN_DIRECT;
  params_16->pad_top = 0;
  params_16->pad_left = 0;
  params_16->pad_down = 0;
  params_16->pad_right = 0;
  params_16->base.name = "conv2d_/layer_2/layer_2.0/block/exp_1x1/block/conv/Conv_15_fuse_bias_add_/layer_2/layer_2.0/block/exp_1x1/block/conv/Conv_16";
  params_16->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_15, output_16, kernel_16, bias_16, params_16);
  struct csinn_tensor *output_18 = csinn_alloc_tensor(sess);
  output_18->name = "output_18";
  output_18->dtype = CSINN_DTYPE_FLOAT16;
  output_18->layout = CSINN_LAYOUT_NCHW;
  output_18->dim[0] = 1;
  output_18->dim[1] = 128;
  output_18->dim[2] = 128;
  output_18->dim[3] = 128;
  output_18->dim_count = 4;
  memcpy(output_18->qinfo, params_base + 23664, sizeof(struct csinn_quant_info) * 1);
  struct csinn_sigmoid_params *params_18 = csinn_alloc_params(sizeof(struct csinn_sigmoid_params), sess);
  params_18->base.name = "sigmoid_/layer_2/layer_2.0/block/exp_1x1/block/act/Sigmoid_17";
  params_18->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_sigmoid_init(output_16, output_18, params_18);
  struct csinn_tensor *output_19 = csinn_alloc_tensor(sess);
  output_19->name = "output_19";
  output_19->dtype = CSINN_DTYPE_FLOAT16;
  output_19->layout = CSINN_LAYOUT_NCHW;
  output_19->dim[0] = 1;
  output_19->dim[1] = 128;
  output_19->dim[2] = 128;
  output_19->dim[3] = 128;
  output_19->dim_count = 4;
  memcpy(output_19->qinfo, params_base + 23688, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_19 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_19->base.name = "multiply_/layer_2/layer_2.0/block/exp_1x1/block/act/Mul_18";
  params_19->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_mul_init(output_16, output_18, output_19, params_19);
  struct csinn_tensor *output_21 = csinn_alloc_tensor(sess);
  output_21->name = "output_21";
  output_21->dtype = CSINN_DTYPE_FLOAT16;
  output_21->layout = CSINN_LAYOUT_NCHW;
  output_21->dim[0] = 1;
  output_21->dim[1] = 128;
  output_21->dim[2] = 64;
  output_21->dim[3] = 64;
  output_21->dim_count = 4;
  memcpy(output_21->qinfo, params_base + 23712, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_21 = csinn_alloc_tensor(sess);
  kernel_21->name = "kernel_21";
  kernel_21->data = params_base + 26808;
  kernel_21->is_const = 1;
  kernel_21->dtype = CSINN_DTYPE_INT8;
  kernel_21->layout = CSINN_LAYOUT_OIHW;
  kernel_21->dim[0] = 128;
  kernel_21->dim[1] = 1;
  kernel_21->dim[2] = 3;
  kernel_21->dim[3] = 3;
  kernel_21->dim_count = 4;
  csinn_realloc_quant_info(kernel_21, 128);
  memcpy(kernel_21->qinfo, params_base + 23736, sizeof(struct csinn_quant_info) * 128);
  struct csinn_tensor *bias_21 = csinn_alloc_tensor(sess);
  bias_21->name = "bias_21";
  bias_21->data = params_base + 31032;
  bias_21->is_const = 1;
  bias_21->dtype = CSINN_DTYPE_FLOAT16;
  bias_21->layout = CSINN_LAYOUT_O;
  bias_21->dim[0] = 128;
  bias_21->dim_count = 1;
  csinn_realloc_quant_info(bias_21, 128);
  memcpy(bias_21->qinfo, params_base + 27960, sizeof(struct csinn_quant_info) * 128);
  struct csinn_conv2d_params *params_21 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_21->group = 128;
  params_21->stride_height = 2;
  params_21->stride_width = 2;
  params_21->dilation_height = 1;
  params_21->dilation_width = 1;
  params_21->conv_extra.kernel_tm = NULL;
  params_21->conv_extra.conv_mode = CSINN_DIRECT;
  params_21->pad_top = 1;
  params_21->pad_left = 1;
  params_21->pad_down = 1;
  params_21->pad_right = 1;
  params_21->base.name = "conv2d_/layer_2/layer_2.0/block/conv_3x3/block/conv/Conv_19_fuse_bias_add_/layer_2/layer_2.0/block/conv_3x3/block/conv/Conv_20";
  params_21->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_19, output_21, kernel_21, bias_21, params_21);
  struct csinn_tensor *output_23 = csinn_alloc_tensor(sess);
  output_23->name = "output_23";
  output_23->dtype = CSINN_DTYPE_FLOAT16;
  output_23->layout = CSINN_LAYOUT_NCHW;
  output_23->dim[0] = 1;
  output_23->dim[1] = 128;
  output_23->dim[2] = 64;
  output_23->dim[3] = 64;
  output_23->dim_count = 4;
  memcpy(output_23->qinfo, params_base + 31288, sizeof(struct csinn_quant_info) * 1);
  struct csinn_sigmoid_params *params_23 = csinn_alloc_params(sizeof(struct csinn_sigmoid_params), sess);
  params_23->base.name = "sigmoid_/layer_2/layer_2.0/block/conv_3x3/block/act/Sigmoid_21";
  params_23->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_sigmoid_init(output_21, output_23, params_23);
  struct csinn_tensor *output_24 = csinn_alloc_tensor(sess);
  output_24->name = "output_24";
  output_24->dtype = CSINN_DTYPE_FLOAT16;
  output_24->layout = CSINN_LAYOUT_NCHW;
  output_24->dim[0] = 1;
  output_24->dim[1] = 128;
  output_24->dim[2] = 64;
  output_24->dim[3] = 64;
  output_24->dim_count = 4;
  memcpy(output_24->qinfo, params_base + 31312, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_24 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_24->base.name = "multiply_/layer_2/layer_2.0/block/conv_3x3/block/act/Mul_22";
  params_24->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_mul_init(output_21, output_23, output_24, params_24);
  struct csinn_tensor *output_26 = csinn_alloc_tensor(sess);
  output_26->name = "output_26";
  output_26->dtype = CSINN_DTYPE_FLOAT16;
  output_26->layout = CSINN_LAYOUT_NCHW;
  output_26->dim[0] = 1;
  output_26->dim[1] = 64;
  output_26->dim[2] = 64;
  output_26->dim[3] = 64;
  output_26->dim_count = 4;
  memcpy(output_26->qinfo, params_base + 31336, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_26 = csinn_alloc_tensor(sess);
  kernel_26->name = "kernel_26";
  kernel_26->data = params_base + 32896;
  kernel_26->is_const = 1;
  kernel_26->dtype = CSINN_DTYPE_INT8;
  kernel_26->layout = CSINN_LAYOUT_OIHW;
  kernel_26->dim[0] = 64;
  kernel_26->dim[1] = 128;
  kernel_26->dim[2] = 1;
  kernel_26->dim[3] = 1;
  kernel_26->dim_count = 4;
  csinn_realloc_quant_info(kernel_26, 64);
  memcpy(kernel_26->qinfo, params_base + 31360, sizeof(struct csinn_quant_info) * 64);
  struct csinn_tensor *bias_26 = csinn_alloc_tensor(sess);
  bias_26->name = "bias_26";
  bias_26->data = params_base + 42624;
  bias_26->is_const = 1;
  bias_26->dtype = CSINN_DTYPE_FLOAT16;
  bias_26->layout = CSINN_LAYOUT_O;
  bias_26->dim[0] = 64;
  bias_26->dim_count = 1;
  csinn_realloc_quant_info(bias_26, 64);
  memcpy(bias_26->qinfo, params_base + 41088, sizeof(struct csinn_quant_info) * 64);
  struct csinn_conv2d_params *params_26 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_26->group = 1;
  params_26->stride_height = 1;
  params_26->stride_width = 1;
  params_26->dilation_height = 1;
  params_26->dilation_width = 1;
  params_26->conv_extra.kernel_tm = NULL;
  params_26->conv_extra.conv_mode = CSINN_DIRECT;
  params_26->pad_top = 0;
  params_26->pad_left = 0;
  params_26->pad_down = 0;
  params_26->pad_right = 0;
  params_26->base.name = "conv2d_/layer_2/layer_2.0/block/red_1x1/block/conv/Conv_23_fuse_bias_add_/layer_2/layer_2.0/block/red_1x1/block/conv/Conv_24";
  params_26->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_24, output_26, kernel_26, bias_26, params_26);
  struct csinn_tensor *output_28 = csinn_alloc_tensor(sess);
  output_28->name = "output_28";
  output_28->dtype = CSINN_DTYPE_FLOAT16;
  output_28->layout = CSINN_LAYOUT_NCHW;
  output_28->dim[0] = 1;
  output_28->dim[1] = 256;
  output_28->dim[2] = 64;
  output_28->dim[3] = 64;
  output_28->dim_count = 4;
  memcpy(output_28->qinfo, params_base + 42752, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_28 = csinn_alloc_tensor(sess);
  kernel_28->name = "kernel_28";
  kernel_28->data = params_base + 48920;
  kernel_28->is_const = 1;
  kernel_28->dtype = CSINN_DTYPE_INT8;
  kernel_28->layout = CSINN_LAYOUT_OIHW;
  kernel_28->dim[0] = 256;
  kernel_28->dim[1] = 64;
  kernel_28->dim[2] = 1;
  kernel_28->dim[3] = 1;
  kernel_28->dim_count = 4;
  csinn_realloc_quant_info(kernel_28, 256);
  memcpy(kernel_28->qinfo, params_base + 42776, sizeof(struct csinn_quant_info) * 256);
  struct csinn_tensor *bias_28 = csinn_alloc_tensor(sess);
  bias_28->name = "bias_28";
  bias_28->data = params_base + 71448;
  bias_28->is_const = 1;
  bias_28->dtype = CSINN_DTYPE_FLOAT16;
  bias_28->layout = CSINN_LAYOUT_O;
  bias_28->dim[0] = 256;
  bias_28->dim_count = 1;
  csinn_realloc_quant_info(bias_28, 256);
  memcpy(bias_28->qinfo, params_base + 65304, sizeof(struct csinn_quant_info) * 256);
  struct csinn_conv2d_params *params_28 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_28->group = 1;
  params_28->stride_height = 1;
  params_28->stride_width = 1;
  params_28->dilation_height = 1;
  params_28->dilation_width = 1;
  params_28->conv_extra.kernel_tm = NULL;
  params_28->conv_extra.conv_mode = CSINN_DIRECT;
  params_28->pad_top = 0;
  params_28->pad_left = 0;
  params_28->pad_down = 0;
  params_28->pad_right = 0;
  params_28->base.name = "conv2d_/layer_2/layer_2.1/block/exp_1x1/block/conv/Conv_25_fuse_bias_add_/layer_2/layer_2.1/block/exp_1x1/block/conv/Conv_26";
  params_28->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_26, output_28, kernel_28, bias_28, params_28);
  struct csinn_tensor *output_30 = csinn_alloc_tensor(sess);
  output_30->name = "output_30";
  output_30->dtype = CSINN_DTYPE_FLOAT16;
  output_30->layout = CSINN_LAYOUT_NCHW;
  output_30->dim[0] = 1;
  output_30->dim[1] = 256;
  output_30->dim[2] = 64;
  output_30->dim[3] = 64;
  output_30->dim_count = 4;
  memcpy(output_30->qinfo, params_base + 71960, sizeof(struct csinn_quant_info) * 1);
  struct csinn_sigmoid_params *params_30 = csinn_alloc_params(sizeof(struct csinn_sigmoid_params), sess);
  params_30->base.name = "sigmoid_/layer_2/layer_2.1/block/exp_1x1/block/act/Sigmoid_27";
  params_30->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_sigmoid_init(output_28, output_30, params_30);
  struct csinn_tensor *output_31 = csinn_alloc_tensor(sess);
  output_31->name = "output_31";
  output_31->dtype = CSINN_DTYPE_FLOAT16;
  output_31->layout = CSINN_LAYOUT_NCHW;
  output_31->dim[0] = 1;
  output_31->dim[1] = 256;
  output_31->dim[2] = 64;
  output_31->dim[3] = 64;
  output_31->dim_count = 4;
  memcpy(output_31->qinfo, params_base + 71984, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_31 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_31->base.name = "multiply_/layer_2/layer_2.1/block/exp_1x1/block/act/Mul_28";
  params_31->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_mul_init(output_28, output_30, output_31, params_31);
  struct csinn_tensor *output_33 = csinn_alloc_tensor(sess);
  output_33->name = "output_33";
  output_33->dtype = CSINN_DTYPE_FLOAT16;
  output_33->layout = CSINN_LAYOUT_NCHW;
  output_33->dim[0] = 1;
  output_33->dim[1] = 256;
  output_33->dim[2] = 64;
  output_33->dim[3] = 64;
  output_33->dim_count = 4;
  memcpy(output_33->qinfo, params_base + 72008, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_33 = csinn_alloc_tensor(sess);
  kernel_33->name = "kernel_33";
  kernel_33->data = params_base + 78176;
  kernel_33->is_const = 1;
  kernel_33->dtype = CSINN_DTYPE_INT8;
  kernel_33->layout = CSINN_LAYOUT_OIHW;
  kernel_33->dim[0] = 256;
  kernel_33->dim[1] = 1;
  kernel_33->dim[2] = 3;
  kernel_33->dim[3] = 3;
  kernel_33->dim_count = 4;
  csinn_realloc_quant_info(kernel_33, 256);
  memcpy(kernel_33->qinfo, params_base + 72032, sizeof(struct csinn_quant_info) * 256);
  struct csinn_tensor *bias_33 = csinn_alloc_tensor(sess);
  bias_33->name = "bias_33";
  bias_33->data = params_base + 86624;
  bias_33->is_const = 1;
  bias_33->dtype = CSINN_DTYPE_FLOAT16;
  bias_33->layout = CSINN_LAYOUT_O;
  bias_33->dim[0] = 256;
  bias_33->dim_count = 1;
  csinn_realloc_quant_info(bias_33, 256);
  memcpy(bias_33->qinfo, params_base + 80480, sizeof(struct csinn_quant_info) * 256);
  struct csinn_conv2d_params *params_33 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_33->group = 256;
  params_33->stride_height = 1;
  params_33->stride_width = 1;
  params_33->dilation_height = 1;
  params_33->dilation_width = 1;
  params_33->conv_extra.kernel_tm = NULL;
  params_33->conv_extra.conv_mode = CSINN_DIRECT;
  params_33->pad_top = 1;
  params_33->pad_left = 1;
  params_33->pad_down = 1;
  params_33->pad_right = 1;
  params_33->base.name = "conv2d_/layer_2/layer_2.1/block/conv_3x3/block/conv/Conv_29_fuse_bias_add_/layer_2/layer_2.1/block/conv_3x3/block/conv/Conv_30";
  params_33->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_31, output_33, kernel_33, bias_33, params_33);
  struct csinn_tensor *output_35 = csinn_alloc_tensor(sess);
  output_35->name = "output_35";
  output_35->dtype = CSINN_DTYPE_FLOAT16;
  output_35->layout = CSINN_LAYOUT_NCHW;
  output_35->dim[0] = 1;
  output_35->dim[1] = 256;
  output_35->dim[2] = 64;
  output_35->dim[3] = 64;
  output_35->dim_count = 4;
  memcpy(output_35->qinfo, params_base + 87136, sizeof(struct csinn_quant_info) * 1);
  struct csinn_sigmoid_params *params_35 = csinn_alloc_params(sizeof(struct csinn_sigmoid_params), sess);
  params_35->base.name = "sigmoid_/layer_2/layer_2.1/block/conv_3x3/block/act/Sigmoid_31";
  params_35->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_sigmoid_init(output_33, output_35, params_35);
  struct csinn_tensor *output_36 = csinn_alloc_tensor(sess);
  output_36->name = "output_36";
  output_36->dtype = CSINN_DTYPE_FLOAT16;
  output_36->layout = CSINN_LAYOUT_NCHW;
  output_36->dim[0] = 1;
  output_36->dim[1] = 256;
  output_36->dim[2] = 64;
  output_36->dim[3] = 64;
  output_36->dim_count = 4;
  memcpy(output_36->qinfo, params_base + 87160, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_36 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_36->base.name = "multiply_/layer_2/layer_2.1/block/conv_3x3/block/act/Mul_32";
  params_36->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_mul_init(output_33, output_35, output_36, params_36);
  struct csinn_tensor *output_38 = csinn_alloc_tensor(sess);
  output_38->name = "output_38";
  output_38->dtype = CSINN_DTYPE_FLOAT16;
  output_38->layout = CSINN_LAYOUT_NCHW;
  output_38->dim[0] = 1;
  output_38->dim[1] = 64;
  output_38->dim[2] = 64;
  output_38->dim[3] = 64;
  output_38->dim_count = 4;
  memcpy(output_38->qinfo, params_base + 87184, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_38 = csinn_alloc_tensor(sess);
  kernel_38->name = "kernel_38";
  kernel_38->data = params_base + 88744;
  kernel_38->is_const = 1;
  kernel_38->dtype = CSINN_DTYPE_INT8;
  kernel_38->layout = CSINN_LAYOUT_OIHW;
  kernel_38->dim[0] = 64;
  kernel_38->dim[1] = 256;
  kernel_38->dim[2] = 1;
  kernel_38->dim[3] = 1;
  kernel_38->dim_count = 4;
  csinn_realloc_quant_info(kernel_38, 64);
  memcpy(kernel_38->qinfo, params_base + 87208, sizeof(struct csinn_quant_info) * 64);
  struct csinn_tensor *bias_38 = csinn_alloc_tensor(sess);
  bias_38->name = "bias_38";
  bias_38->data = params_base + 106664;
  bias_38->is_const = 1;
  bias_38->dtype = CSINN_DTYPE_FLOAT16;
  bias_38->layout = CSINN_LAYOUT_O;
  bias_38->dim[0] = 64;
  bias_38->dim_count = 1;
  csinn_realloc_quant_info(bias_38, 64);
  memcpy(bias_38->qinfo, params_base + 105128, sizeof(struct csinn_quant_info) * 64);
  struct csinn_conv2d_params *params_38 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_38->group = 1;
  params_38->stride_height = 1;
  params_38->stride_width = 1;
  params_38->dilation_height = 1;
  params_38->dilation_width = 1;
  params_38->conv_extra.kernel_tm = NULL;
  params_38->conv_extra.conv_mode = CSINN_DIRECT;
  params_38->pad_top = 0;
  params_38->pad_left = 0;
  params_38->pad_down = 0;
  params_38->pad_right = 0;
  params_38->base.name = "conv2d_/layer_2/layer_2.1/block/red_1x1/block/conv/Conv_33_fuse_bias_add_/layer_2/layer_2.1/block/red_1x1/block/conv/Conv_34";
  params_38->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_36, output_38, kernel_38, bias_38, params_38);
  struct csinn_tensor *output_39 = csinn_alloc_tensor(sess);
  output_39->name = "output_39";
  output_39->dtype = CSINN_DTYPE_FLOAT16;
  output_39->layout = CSINN_LAYOUT_NCHW;
  output_39->dim[0] = 1;
  output_39->dim[1] = 64;
  output_39->dim[2] = 64;
  output_39->dim[3] = 64;
  output_39->dim_count = 4;
  memcpy(output_39->qinfo, params_base + 106792, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_39 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_39->base.name = "add_/layer_2/layer_2.1/Add_35";
  params_39->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_26, output_38, output_39, params_39);
  struct csinn_tensor *output_42 = csinn_alloc_tensor(sess);
  output_42->name = "output_42";
  output_42->dtype = CSINN_DTYPE_FLOAT16;
  output_42->layout = CSINN_LAYOUT_NCHW;
  output_42->dim[0] = 1;
  output_42->dim[1] = 256;
  output_42->dim[2] = 64;
  output_42->dim[3] = 64;
  output_42->dim_count = 4;
  memcpy(output_42->qinfo, params_base + 106816, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_42 = csinn_alloc_tensor(sess);
  kernel_42->name = "kernel_42";
  kernel_42->data = params_base + 112984;
  kernel_42->is_const = 1;
  kernel_42->dtype = CSINN_DTYPE_INT8;
  kernel_42->layout = CSINN_LAYOUT_OIHW;
  kernel_42->dim[0] = 256;
  kernel_42->dim[1] = 64;
  kernel_42->dim[2] = 1;
  kernel_42->dim[3] = 1;
  kernel_42->dim_count = 4;
  csinn_realloc_quant_info(kernel_42, 256);
  memcpy(kernel_42->qinfo, params_base + 106840, sizeof(struct csinn_quant_info) * 256);
  struct csinn_tensor *bias_42 = csinn_alloc_tensor(sess);
  bias_42->name = "bias_42";
  bias_42->data = params_base + 135512;
  bias_42->is_const = 1;
  bias_42->dtype = CSINN_DTYPE_FLOAT16;
  bias_42->layout = CSINN_LAYOUT_O;
  bias_42->dim[0] = 256;
  bias_42->dim_count = 1;
  csinn_realloc_quant_info(bias_42, 256);
  memcpy(bias_42->qinfo, params_base + 129368, sizeof(struct csinn_quant_info) * 256);
  struct csinn_conv2d_params *params_42 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_42->group = 1;
  params_42->stride_height = 1;
  params_42->stride_width = 1;
  params_42->dilation_height = 1;
  params_42->dilation_width = 1;
  params_42->conv_extra.kernel_tm = NULL;
  params_42->conv_extra.conv_mode = CSINN_DIRECT;
  params_42->pad_top = 0;
  params_42->pad_left = 0;
  params_42->pad_down = 0;
  params_42->pad_right = 0;
  params_42->base.name = "conv2d_/layer_2/layer_2.2/block/exp_1x1/block/conv/Conv_36_fuse_bias_add_/layer_2/layer_2.2/block/exp_1x1/block/conv/Conv_37";
  params_42->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_39, output_42, kernel_42, bias_42, params_42);
  struct csinn_tensor *output_44 = csinn_alloc_tensor(sess);
  output_44->name = "output_44";
  output_44->dtype = CSINN_DTYPE_FLOAT16;
  output_44->layout = CSINN_LAYOUT_NCHW;
  output_44->dim[0] = 1;
  output_44->dim[1] = 256;
  output_44->dim[2] = 64;
  output_44->dim[3] = 64;
  output_44->dim_count = 4;
  memcpy(output_44->qinfo, params_base + 136024, sizeof(struct csinn_quant_info) * 1);
  struct csinn_sigmoid_params *params_44 = csinn_alloc_params(sizeof(struct csinn_sigmoid_params), sess);
  params_44->base.name = "sigmoid_/layer_2/layer_2.2/block/exp_1x1/block/act/Sigmoid_38";
  params_44->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_sigmoid_init(output_42, output_44, params_44);
  struct csinn_tensor *output_45 = csinn_alloc_tensor(sess);
  output_45->name = "output_45";
  output_45->dtype = CSINN_DTYPE_FLOAT16;
  output_45->layout = CSINN_LAYOUT_NCHW;
  output_45->dim[0] = 1;
  output_45->dim[1] = 256;
  output_45->dim[2] = 64;
  output_45->dim[3] = 64;
  output_45->dim_count = 4;
  memcpy(output_45->qinfo, params_base + 136048, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_45 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_45->base.name = "multiply_/layer_2/layer_2.2/block/exp_1x1/block/act/Mul_39";
  params_45->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_mul_init(output_42, output_44, output_45, params_45);
  struct csinn_tensor *output_47 = csinn_alloc_tensor(sess);
  output_47->name = "output_47";
  output_47->dtype = CSINN_DTYPE_FLOAT16;
  output_47->layout = CSINN_LAYOUT_NCHW;
  output_47->dim[0] = 1;
  output_47->dim[1] = 256;
  output_47->dim[2] = 64;
  output_47->dim[3] = 64;
  output_47->dim_count = 4;
  memcpy(output_47->qinfo, params_base + 136072, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_47 = csinn_alloc_tensor(sess);
  kernel_47->name = "kernel_47";
  kernel_47->data = params_base + 142240;
  kernel_47->is_const = 1;
  kernel_47->dtype = CSINN_DTYPE_INT8;
  kernel_47->layout = CSINN_LAYOUT_OIHW;
  kernel_47->dim[0] = 256;
  kernel_47->dim[1] = 1;
  kernel_47->dim[2] = 3;
  kernel_47->dim[3] = 3;
  kernel_47->dim_count = 4;
  csinn_realloc_quant_info(kernel_47, 256);
  memcpy(kernel_47->qinfo, params_base + 136096, sizeof(struct csinn_quant_info) * 256);
  struct csinn_tensor *bias_47 = csinn_alloc_tensor(sess);
  bias_47->name = "bias_47";
  bias_47->data = params_base + 150688;
  bias_47->is_const = 1;
  bias_47->dtype = CSINN_DTYPE_FLOAT16;
  bias_47->layout = CSINN_LAYOUT_O;
  bias_47->dim[0] = 256;
  bias_47->dim_count = 1;
  csinn_realloc_quant_info(bias_47, 256);
  memcpy(bias_47->qinfo, params_base + 144544, sizeof(struct csinn_quant_info) * 256);
  struct csinn_conv2d_params *params_47 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_47->group = 256;
  params_47->stride_height = 1;
  params_47->stride_width = 1;
  params_47->dilation_height = 1;
  params_47->dilation_width = 1;
  params_47->conv_extra.kernel_tm = NULL;
  params_47->conv_extra.conv_mode = CSINN_DIRECT;
  params_47->pad_top = 1;
  params_47->pad_left = 1;
  params_47->pad_down = 1;
  params_47->pad_right = 1;
  params_47->base.name = "conv2d_/layer_2/layer_2.2/block/conv_3x3/block/conv/Conv_40_fuse_bias_add_/layer_2/layer_2.2/block/conv_3x3/block/conv/Conv_41";
  params_47->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_45, output_47, kernel_47, bias_47, params_47);
  struct csinn_tensor *output_49 = csinn_alloc_tensor(sess);
  output_49->name = "output_49";
  output_49->dtype = CSINN_DTYPE_FLOAT16;
  output_49->layout = CSINN_LAYOUT_NCHW;
  output_49->dim[0] = 1;
  output_49->dim[1] = 256;
  output_49->dim[2] = 64;
  output_49->dim[3] = 64;
  output_49->dim_count = 4;
  memcpy(output_49->qinfo, params_base + 151200, sizeof(struct csinn_quant_info) * 1);
  struct csinn_sigmoid_params *params_49 = csinn_alloc_params(sizeof(struct csinn_sigmoid_params), sess);
  params_49->base.name = "sigmoid_/layer_2/layer_2.2/block/conv_3x3/block/act/Sigmoid_42";
  params_49->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_sigmoid_init(output_47, output_49, params_49);
  struct csinn_tensor *output_50 = csinn_alloc_tensor(sess);
  output_50->name = "output_50";
  output_50->dtype = CSINN_DTYPE_FLOAT16;
  output_50->layout = CSINN_LAYOUT_NCHW;
  output_50->dim[0] = 1;
  output_50->dim[1] = 256;
  output_50->dim[2] = 64;
  output_50->dim[3] = 64;
  output_50->dim_count = 4;
  memcpy(output_50->qinfo, params_base + 151224, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_50 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_50->base.name = "multiply_/layer_2/layer_2.2/block/conv_3x3/block/act/Mul_43";
  params_50->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_mul_init(output_47, output_49, output_50, params_50);
  struct csinn_tensor *output_52 = csinn_alloc_tensor(sess);
  output_52->name = "output_52";
  output_52->dtype = CSINN_DTYPE_FLOAT16;
  output_52->layout = CSINN_LAYOUT_NCHW;
  output_52->dim[0] = 1;
  output_52->dim[1] = 64;
  output_52->dim[2] = 64;
  output_52->dim[3] = 64;
  output_52->dim_count = 4;
  memcpy(output_52->qinfo, params_base + 151248, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_52 = csinn_alloc_tensor(sess);
  kernel_52->name = "kernel_52";
  kernel_52->data = params_base + 152808;
  kernel_52->is_const = 1;
  kernel_52->dtype = CSINN_DTYPE_INT8;
  kernel_52->layout = CSINN_LAYOUT_OIHW;
  kernel_52->dim[0] = 64;
  kernel_52->dim[1] = 256;
  kernel_52->dim[2] = 1;
  kernel_52->dim[3] = 1;
  kernel_52->dim_count = 4;
  csinn_realloc_quant_info(kernel_52, 64);
  memcpy(kernel_52->qinfo, params_base + 151272, sizeof(struct csinn_quant_info) * 64);
  struct csinn_tensor *bias_52 = csinn_alloc_tensor(sess);
  bias_52->name = "bias_52";
  bias_52->data = params_base + 170728;
  bias_52->is_const = 1;
  bias_52->dtype = CSINN_DTYPE_FLOAT16;
  bias_52->layout = CSINN_LAYOUT_O;
  bias_52->dim[0] = 64;
  bias_52->dim_count = 1;
  csinn_realloc_quant_info(bias_52, 64);
  memcpy(bias_52->qinfo, params_base + 169192, sizeof(struct csinn_quant_info) * 64);
  struct csinn_conv2d_params *params_52 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_52->group = 1;
  params_52->stride_height = 1;
  params_52->stride_width = 1;
  params_52->dilation_height = 1;
  params_52->dilation_width = 1;
  params_52->conv_extra.kernel_tm = NULL;
  params_52->conv_extra.conv_mode = CSINN_DIRECT;
  params_52->pad_top = 0;
  params_52->pad_left = 0;
  params_52->pad_down = 0;
  params_52->pad_right = 0;
  params_52->base.name = "conv2d_/layer_2/layer_2.2/block/red_1x1/block/conv/Conv_44_fuse_bias_add_/layer_2/layer_2.2/block/red_1x1/block/conv/Conv_45";
  params_52->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_50, output_52, kernel_52, bias_52, params_52);
  struct csinn_tensor *output_53 = csinn_alloc_tensor(sess);
  output_53->name = "output_53";
  output_53->dtype = CSINN_DTYPE_FLOAT16;
  output_53->layout = CSINN_LAYOUT_NCHW;
  output_53->dim[0] = 1;
  output_53->dim[1] = 64;
  output_53->dim[2] = 64;
  output_53->dim[3] = 64;
  output_53->dim_count = 4;
  memcpy(output_53->qinfo, params_base + 170856, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_53 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_53->base.name = "add_/layer_2/layer_2.2/Add_46";
  params_53->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_39, output_52, output_53, params_53);
  struct csinn_tensor *output_55 = csinn_alloc_tensor(sess);
  output_55->name = "output_55";
  output_55->dtype = CSINN_DTYPE_FLOAT16;
  output_55->layout = CSINN_LAYOUT_NCHW;
  output_55->dim[0] = 1;
  output_55->dim[1] = 256;
  output_55->dim[2] = 64;
  output_55->dim[3] = 64;
  output_55->dim_count = 4;
  memcpy(output_55->qinfo, params_base + 170880, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_55 = csinn_alloc_tensor(sess);
  kernel_55->name = "kernel_55";
  kernel_55->data = params_base + 177048;
  kernel_55->is_const = 1;
  kernel_55->dtype = CSINN_DTYPE_INT8;
  kernel_55->layout = CSINN_LAYOUT_OIHW;
  kernel_55->dim[0] = 256;
  kernel_55->dim[1] = 64;
  kernel_55->dim[2] = 1;
  kernel_55->dim[3] = 1;
  kernel_55->dim_count = 4;
  csinn_realloc_quant_info(kernel_55, 256);
  memcpy(kernel_55->qinfo, params_base + 170904, sizeof(struct csinn_quant_info) * 256);
  struct csinn_tensor *bias_55 = csinn_alloc_tensor(sess);
  bias_55->name = "bias_55";
  bias_55->data = params_base + 199576;
  bias_55->is_const = 1;
  bias_55->dtype = CSINN_DTYPE_FLOAT16;
  bias_55->layout = CSINN_LAYOUT_O;
  bias_55->dim[0] = 256;
  bias_55->dim_count = 1;
  csinn_realloc_quant_info(bias_55, 256);
  memcpy(bias_55->qinfo, params_base + 193432, sizeof(struct csinn_quant_info) * 256);
  struct csinn_conv2d_params *params_55 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_55->group = 1;
  params_55->stride_height = 1;
  params_55->stride_width = 1;
  params_55->dilation_height = 1;
  params_55->dilation_width = 1;
  params_55->conv_extra.kernel_tm = NULL;
  params_55->conv_extra.conv_mode = CSINN_DIRECT;
  params_55->pad_top = 0;
  params_55->pad_left = 0;
  params_55->pad_down = 0;
  params_55->pad_right = 0;
  params_55->base.name = "conv2d_/layer_3/layer_3.0/block/exp_1x1/block/conv/Conv_47_fuse_bias_add_/layer_3/layer_3.0/block/exp_1x1/block/conv/Conv_48";
  params_55->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_53, output_55, kernel_55, bias_55, params_55);
  struct csinn_tensor *output_57 = csinn_alloc_tensor(sess);
  output_57->name = "output_57";
  output_57->dtype = CSINN_DTYPE_FLOAT16;
  output_57->layout = CSINN_LAYOUT_NCHW;
  output_57->dim[0] = 1;
  output_57->dim[1] = 256;
  output_57->dim[2] = 64;
  output_57->dim[3] = 64;
  output_57->dim_count = 4;
  memcpy(output_57->qinfo, params_base + 200088, sizeof(struct csinn_quant_info) * 1);
  struct csinn_sigmoid_params *params_57 = csinn_alloc_params(sizeof(struct csinn_sigmoid_params), sess);
  params_57->base.name = "sigmoid_/layer_3/layer_3.0/block/exp_1x1/block/act/Sigmoid_49";
  params_57->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_sigmoid_init(output_55, output_57, params_57);
  struct csinn_tensor *output_58 = csinn_alloc_tensor(sess);
  output_58->name = "output_58";
  output_58->dtype = CSINN_DTYPE_FLOAT16;
  output_58->layout = CSINN_LAYOUT_NCHW;
  output_58->dim[0] = 1;
  output_58->dim[1] = 256;
  output_58->dim[2] = 64;
  output_58->dim[3] = 64;
  output_58->dim_count = 4;
  memcpy(output_58->qinfo, params_base + 200112, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_58 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_58->base.name = "multiply_/layer_3/layer_3.0/block/exp_1x1/block/act/Mul_50";
  params_58->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_mul_init(output_55, output_57, output_58, params_58);
  struct csinn_tensor *output_60 = csinn_alloc_tensor(sess);
  output_60->name = "output_60";
  output_60->dtype = CSINN_DTYPE_FLOAT16;
  output_60->layout = CSINN_LAYOUT_NCHW;
  output_60->dim[0] = 1;
  output_60->dim[1] = 256;
  output_60->dim[2] = 32;
  output_60->dim[3] = 32;
  output_60->dim_count = 4;
  memcpy(output_60->qinfo, params_base + 200136, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_60 = csinn_alloc_tensor(sess);
  kernel_60->name = "kernel_60";
  kernel_60->data = params_base + 206304;
  kernel_60->is_const = 1;
  kernel_60->dtype = CSINN_DTYPE_INT8;
  kernel_60->layout = CSINN_LAYOUT_OIHW;
  kernel_60->dim[0] = 256;
  kernel_60->dim[1] = 1;
  kernel_60->dim[2] = 3;
  kernel_60->dim[3] = 3;
  kernel_60->dim_count = 4;
  csinn_realloc_quant_info(kernel_60, 256);
  memcpy(kernel_60->qinfo, params_base + 200160, sizeof(struct csinn_quant_info) * 256);
  struct csinn_tensor *bias_60 = csinn_alloc_tensor(sess);
  bias_60->name = "bias_60";
  bias_60->data = params_base + 214752;
  bias_60->is_const = 1;
  bias_60->dtype = CSINN_DTYPE_FLOAT16;
  bias_60->layout = CSINN_LAYOUT_O;
  bias_60->dim[0] = 256;
  bias_60->dim_count = 1;
  csinn_realloc_quant_info(bias_60, 256);
  memcpy(bias_60->qinfo, params_base + 208608, sizeof(struct csinn_quant_info) * 256);
  struct csinn_conv2d_params *params_60 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_60->group = 256;
  params_60->stride_height = 2;
  params_60->stride_width = 2;
  params_60->dilation_height = 1;
  params_60->dilation_width = 1;
  params_60->conv_extra.kernel_tm = NULL;
  params_60->conv_extra.conv_mode = CSINN_DIRECT;
  params_60->pad_top = 1;
  params_60->pad_left = 1;
  params_60->pad_down = 1;
  params_60->pad_right = 1;
  params_60->base.name = "conv2d_/layer_3/layer_3.0/block/conv_3x3/block/conv/Conv_51_fuse_bias_add_/layer_3/layer_3.0/block/conv_3x3/block/conv/Conv_52";
  params_60->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_58, output_60, kernel_60, bias_60, params_60);
  struct csinn_tensor *output_62 = csinn_alloc_tensor(sess);
  output_62->name = "output_62";
  output_62->dtype = CSINN_DTYPE_FLOAT16;
  output_62->layout = CSINN_LAYOUT_NCHW;
  output_62->dim[0] = 1;
  output_62->dim[1] = 256;
  output_62->dim[2] = 32;
  output_62->dim[3] = 32;
  output_62->dim_count = 4;
  memcpy(output_62->qinfo, params_base + 215264, sizeof(struct csinn_quant_info) * 1);
  struct csinn_sigmoid_params *params_62 = csinn_alloc_params(sizeof(struct csinn_sigmoid_params), sess);
  params_62->base.name = "sigmoid_/layer_3/layer_3.0/block/conv_3x3/block/act/Sigmoid_53";
  params_62->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_sigmoid_init(output_60, output_62, params_62);
  struct csinn_tensor *output_63 = csinn_alloc_tensor(sess);
  output_63->name = "output_63";
  output_63->dtype = CSINN_DTYPE_FLOAT16;
  output_63->layout = CSINN_LAYOUT_NCHW;
  output_63->dim[0] = 1;
  output_63->dim[1] = 256;
  output_63->dim[2] = 32;
  output_63->dim[3] = 32;
  output_63->dim_count = 4;
  memcpy(output_63->qinfo, params_base + 215288, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_63 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_63->base.name = "multiply_/layer_3/layer_3.0/block/conv_3x3/block/act/Mul_54";
  params_63->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_mul_init(output_60, output_62, output_63, params_63);
  struct csinn_tensor *output_65 = csinn_alloc_tensor(sess);
  output_65->name = "output_65";
  output_65->dtype = CSINN_DTYPE_FLOAT16;
  output_65->layout = CSINN_LAYOUT_NCHW;
  output_65->dim[0] = 1;
  output_65->dim[1] = 96;
  output_65->dim[2] = 32;
  output_65->dim[3] = 32;
  output_65->dim_count = 4;
  memcpy(output_65->qinfo, params_base + 215312, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_65 = csinn_alloc_tensor(sess);
  kernel_65->name = "kernel_65";
  kernel_65->data = params_base + 217640;
  kernel_65->is_const = 1;
  kernel_65->dtype = CSINN_DTYPE_INT8;
  kernel_65->layout = CSINN_LAYOUT_OIHW;
  kernel_65->dim[0] = 96;
  kernel_65->dim[1] = 256;
  kernel_65->dim[2] = 1;
  kernel_65->dim[3] = 1;
  kernel_65->dim_count = 4;
  csinn_realloc_quant_info(kernel_65, 96);
  memcpy(kernel_65->qinfo, params_base + 215336, sizeof(struct csinn_quant_info) * 96);
  struct csinn_tensor *bias_65 = csinn_alloc_tensor(sess);
  bias_65->name = "bias_65";
  bias_65->data = params_base + 244520;
  bias_65->is_const = 1;
  bias_65->dtype = CSINN_DTYPE_FLOAT16;
  bias_65->layout = CSINN_LAYOUT_O;
  bias_65->dim[0] = 96;
  bias_65->dim_count = 1;
  csinn_realloc_quant_info(bias_65, 96);
  memcpy(bias_65->qinfo, params_base + 242216, sizeof(struct csinn_quant_info) * 96);
  struct csinn_conv2d_params *params_65 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_65->group = 1;
  params_65->stride_height = 1;
  params_65->stride_width = 1;
  params_65->dilation_height = 1;
  params_65->dilation_width = 1;
  params_65->conv_extra.kernel_tm = NULL;
  params_65->conv_extra.conv_mode = CSINN_DIRECT;
  params_65->pad_top = 0;
  params_65->pad_left = 0;
  params_65->pad_down = 0;
  params_65->pad_right = 0;
  params_65->base.name = "conv2d_/layer_3/layer_3.0/block/red_1x1/block/conv/Conv_55_fuse_bias_add_/layer_3/layer_3.0/block/red_1x1/block/conv/Conv_56";
  params_65->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_63, output_65, kernel_65, bias_65, params_65);
  struct csinn_tensor *output_66 = csinn_alloc_tensor(sess);
  output_66->name = "output_66";
  output_66->dtype = CSINN_DTYPE_FLOAT16;
  output_66->layout = CSINN_LAYOUT_NCHW;
  output_66->dim[0] = 1;
  output_66->dim[1] = 96;
  output_66->dim[2] = 32;
  output_66->dim[3] = 32;
  output_66->dim_count = 4;
  memcpy(output_66->qinfo, params_base + 244712, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_66 = csinn_alloc_tensor(sess);
  kernel_66->name = "kernel_66";
  kernel_66->data = params_base + 247040;
  kernel_66->is_const = 1;
  kernel_66->dtype = CSINN_DTYPE_INT8;
  kernel_66->layout = CSINN_LAYOUT_OIHW;
  kernel_66->dim[0] = 96;
  kernel_66->dim[1] = 96;
  kernel_66->dim[2] = 3;
  kernel_66->dim[3] = 3;
  kernel_66->dim_count = 4;
  csinn_realloc_quant_info(kernel_66, 96);
  memcpy(kernel_66->qinfo, params_base + 244736, sizeof(struct csinn_quant_info) * 96);
  struct csinn_tensor *bias_66 = csinn_alloc_tensor(sess);
  bias_66->name = "bias_66";
  bias_66->data = params_base + 332288;
  bias_66->is_const = 1;
  bias_66->dtype = CSINN_DTYPE_FLOAT16;
  bias_66->layout = CSINN_LAYOUT_O;
  bias_66->dim[0] = 96;
  bias_66->dim_count = 1;
  csinn_realloc_quant_info(bias_66, 96);
  memcpy(bias_66->qinfo, params_base + 329984, sizeof(struct csinn_quant_info) * 96);
  struct csinn_conv2d_params *params_66 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_66->group = 1;
  params_66->stride_height = 1;
  params_66->stride_width = 1;
  params_66->dilation_height = 1;
  params_66->dilation_width = 1;
  params_66->conv_extra.kernel_tm = NULL;
  params_66->conv_extra.conv_mode = CSINN_DIRECT;
  params_66->pad_top = 1;
  params_66->pad_left = 1;
  params_66->pad_down = 1;
  params_66->pad_right = 1;
  params_66->base.name = "conv2d_/layer_3/layer_3.1/local_rep/conv_3x3/block/conv/Conv_57_fuse_bias_add_/layer_3/layer_3.1/local_rep/conv_3x3/block/conv/Conv_58";
  params_66->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_65, output_66, kernel_66, bias_66, params_66);
  struct csinn_tensor *output_68 = csinn_alloc_tensor(sess);
  output_68->name = "output_68";
  output_68->dtype = CSINN_DTYPE_FLOAT16;
  output_68->layout = CSINN_LAYOUT_NCHW;
  output_68->dim[0] = 1;
  output_68->dim[1] = 96;
  output_68->dim[2] = 32;
  output_68->dim[3] = 32;
  output_68->dim_count = 4;
  memcpy(output_68->qinfo, params_base + 332480, sizeof(struct csinn_quant_info) * 1);
  struct csinn_sigmoid_params *params_68 = csinn_alloc_params(sizeof(struct csinn_sigmoid_params), sess);
  params_68->base.name = "sigmoid_/layer_3/layer_3.1/local_rep/conv_3x3/block/act/Sigmoid_59";
  params_68->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_sigmoid_init(output_66, output_68, params_68);
  struct csinn_tensor *output_69 = csinn_alloc_tensor(sess);
  output_69->name = "output_69";
  output_69->dtype = CSINN_DTYPE_FLOAT16;
  output_69->layout = CSINN_LAYOUT_NCHW;
  output_69->dim[0] = 1;
  output_69->dim[1] = 96;
  output_69->dim[2] = 32;
  output_69->dim[3] = 32;
  output_69->dim_count = 4;
  memcpy(output_69->qinfo, params_base + 332504, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_69 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_69->base.name = "multiply_/layer_3/layer_3.1/local_rep/conv_3x3/block/act/Mul_60";
  params_69->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_mul_init(output_66, output_68, output_69, params_69);
  struct csinn_tensor *bias_71 = csinn_alloc_tensor(sess);
  bias_71->data = NULL;
  bias_71->name = "bias_71";
  bias_71->is_const = 1;
  bias_71->dim_count = 0;
  struct csinn_tensor *output_71 = csinn_alloc_tensor(sess);
  output_71->name = "output_71";
  output_71->dtype = CSINN_DTYPE_FLOAT16;
  output_71->layout = CSINN_LAYOUT_NCHW;
  output_71->dim[0] = 1;
  output_71->dim[1] = 144;
  output_71->dim[2] = 32;
  output_71->dim[3] = 32;
  output_71->dim_count = 4;
  memcpy(output_71->qinfo, params_base + 332528, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_71 = csinn_alloc_tensor(sess);
  kernel_71->name = "kernel_71";
  kernel_71->data = params_base + 336008;
  kernel_71->is_const = 1;
  kernel_71->dtype = CSINN_DTYPE_INT8;
  kernel_71->layout = CSINN_LAYOUT_OIHW;
  kernel_71->dim[0] = 144;
  kernel_71->dim[1] = 96;
  kernel_71->dim[2] = 1;
  kernel_71->dim[3] = 1;
  kernel_71->dim_count = 4;
  csinn_realloc_quant_info(kernel_71, 144);
  memcpy(kernel_71->qinfo, params_base + 332552, sizeof(struct csinn_quant_info) * 144);
  struct csinn_conv2d_params *params_71 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_71->group = 1;
  params_71->stride_height = 1;
  params_71->stride_width = 1;
  params_71->dilation_height = 1;
  params_71->dilation_width = 1;
  params_71->conv_extra.kernel_tm = NULL;
  params_71->conv_extra.conv_mode = CSINN_DIRECT;
  params_71->pad_top = 0;
  params_71->pad_left = 0;
  params_71->pad_down = 0;
  params_71->pad_right = 0;
  params_71->base.name = "conv2d_/layer_3/layer_3.1/local_rep/conv_1x1/block/conv/Conv_61";
  params_71->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_69, output_71, kernel_71, bias_71, params_71);
  int32_t *shape_72 = malloc(4 * 4);
  shape_72[0] = 2304;
  shape_72[1] = 2;
  shape_72[2] = 16;
  shape_72[3] = 2;
  struct csinn_tensor *output_72 = csinn_alloc_tensor(sess);
  output_72->name = "output_72";
  output_72->dtype = CSINN_DTYPE_FLOAT16;
  output_72->layout = CSINN_LAYOUT_NCHW;
  output_72->dim[0] = 2304;
  output_72->dim[1] = 2;
  output_72->dim[2] = 16;
  output_72->dim[3] = 2;
  output_72->dim_count = 4;
  memcpy(output_72->qinfo, params_base + 349832, sizeof(struct csinn_quant_info) * 1);
  struct csinn_reshape_params *params_72 = csinn_alloc_params(sizeof(struct csinn_reshape_params), sess);
  params_72->shape = shape_72;
  params_72->shape_num = 4;
  params_72->base.name = "reshape_/layer_3/layer_3.1/Reshape_62";
  params_72->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_reshape_init(output_71, output_72, params_72);
  int32_t *permute_73 = malloc(4 * 4);
  permute_73[0] = 0;
  permute_73[1] = 2;
  permute_73[2] = 1;
  permute_73[3] = 3;
  struct csinn_tensor *output_73 = csinn_alloc_tensor(sess);
  output_73->name = "output_73";
  output_73->dtype = CSINN_DTYPE_FLOAT16;
  output_73->layout = CSINN_LAYOUT_NCHW;
  output_73->dim[0] = 2304;
  output_73->dim[1] = 16;
  output_73->dim[2] = 2;
  output_73->dim[3] = 2;
  output_73->dim_count = 4;
  memcpy(output_73->qinfo, params_base + 349856, sizeof(struct csinn_quant_info) * 1);
  struct csinn_transpose_params *params_73 = csinn_alloc_params(sizeof(struct csinn_transpose_params), sess);
  params_73->permute = permute_73;
  params_73->permute_num = 4;
  params_73->base.name = "transpose_/layer_3/layer_3.1/Transpose_63";
  params_73->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_transpose_init(output_72, output_73, params_73);
  int32_t *shape_74 = malloc(4 * 4);
  shape_74[0] = 1;
  shape_74[1] = 144;
  shape_74[2] = 256;
  shape_74[3] = 4;
  struct csinn_tensor *output_74 = csinn_alloc_tensor(sess);
  output_74->name = "output_74";
  output_74->dtype = CSINN_DTYPE_FLOAT16;
  output_74->layout = CSINN_LAYOUT_NCHW;
  output_74->dim[0] = 1;
  output_74->dim[1] = 144;
  output_74->dim[2] = 256;
  output_74->dim[3] = 4;
  output_74->dim_count = 4;
  memcpy(output_74->qinfo, params_base + 349880, sizeof(struct csinn_quant_info) * 1);
  struct csinn_reshape_params *params_74 = csinn_alloc_params(sizeof(struct csinn_reshape_params), sess);
  params_74->shape = shape_74;
  params_74->shape_num = 4;
  params_74->base.name = "reshape_/layer_3/layer_3.1/Reshape_1_64";
  params_74->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_reshape_init(output_73, output_74, params_74);
  int32_t *permute_75 = malloc(4 * 4);
  permute_75[0] = 0;
  permute_75[1] = 3;
  permute_75[2] = 2;
  permute_75[3] = 1;
  struct csinn_tensor *output_75 = csinn_alloc_tensor(sess);
  output_75->name = "output_75";
  output_75->dtype = CSINN_DTYPE_FLOAT16;
  output_75->layout = CSINN_LAYOUT_NCHW;
  output_75->dim[0] = 1;
  output_75->dim[1] = 4;
  output_75->dim[2] = 256;
  output_75->dim[3] = 144;
  output_75->dim_count = 4;
  memcpy(output_75->qinfo, params_base + 349904, sizeof(struct csinn_quant_info) * 1);
  struct csinn_transpose_params *params_75 = csinn_alloc_params(sizeof(struct csinn_transpose_params), sess);
  params_75->permute = permute_75;
  params_75->permute_num = 4;
  params_75->base.name = "transpose_/layer_3/layer_3.1/Transpose_1_65";
  params_75->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_transpose_init(output_74, output_75, params_75);
  int32_t *shape_76 = malloc(3 * 4);
  shape_76[0] = 4;
  shape_76[1] = 256;
  shape_76[2] = -1;
  struct csinn_tensor *output_76 = csinn_alloc_tensor(sess);
  output_76->name = "output_76";
  output_76->dtype = CSINN_DTYPE_FLOAT16;
  output_76->layout = CSINN_LAYOUT_NCW;
  output_76->dim[0] = 4;
  output_76->dim[1] = 256;
  output_76->dim[2] = 144;
  output_76->dim_count = 3;
  memcpy(output_76->qinfo, params_base + 349928, sizeof(struct csinn_quant_info) * 1);
  struct csinn_reshape_params *params_76 = csinn_alloc_params(sizeof(struct csinn_reshape_params), sess);
  params_76->shape = shape_76;
  params_76->shape_num = 3;
  params_76->base.name = "reshape_/layer_3/layer_3.1/Reshape_2_66";
  params_76->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_reshape_init(output_75, output_76, params_76);
  struct csinn_tensor *output_77 = csinn_alloc_tensor(sess);
  output_77->name = "output_77";
  output_77->dtype = CSINN_DTYPE_FLOAT16;
  output_77->layout = CSINN_LAYOUT_NCW;
  output_77->dim[0] = 4;
  output_77->dim[1] = 256;
  output_77->dim[2] = 144;
  output_77->dim_count = 3;
  memcpy(output_77->qinfo, params_base + 349952, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *gamma_77 = csinn_alloc_tensor(sess);
  gamma_77->name = "gamma_77";
  gamma_77->data = params_base + 350000;
  gamma_77->is_const = 1;
  gamma_77->dtype = CSINN_DTYPE_FLOAT16;
  gamma_77->layout = CSINN_LAYOUT_O;
  gamma_77->dim[0] = 144;
  gamma_77->dim_count = 1;
  memcpy(gamma_77->qinfo, params_base + 349976, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *beta_77 = csinn_alloc_tensor(sess);
  beta_77->name = "beta_77";
  beta_77->data = params_base + 350312;
  beta_77->is_const = 1;
  beta_77->dtype = CSINN_DTYPE_FLOAT16;
  beta_77->layout = CSINN_LAYOUT_O;
  beta_77->dim[0] = 144;
  beta_77->dim_count = 1;
  memcpy(beta_77->qinfo, params_base + 350288, sizeof(struct csinn_quant_info) * 1);
  struct csinn_layer_norm_params *params_77 = csinn_alloc_params(sizeof(struct csinn_layer_norm_params), sess);
  params_77->epsilon = 1e-05;
  params_77->axis = -1;
  params_77->center = true;
  params_77->scale = true;
  params_77->base.name = "layer_norm_67";
  params_77->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_layer_norm_init(output_76, output_77, gamma_77, beta_77, params_77);
  struct csinn_tensor *output_79 = csinn_alloc_tensor(sess);
  output_79->name = "output_79";
  output_79->dtype = CSINN_DTYPE_FLOAT16;
  output_79->layout = CSINN_LAYOUT_NCW;
  output_79->dim[0] = 4;
  output_79->dim[1] = 256;
  output_79->dim[2] = 432;
  output_79->dim_count = 3;
  memcpy(output_79->qinfo, params_base + 350600, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *data_b_79 = csinn_alloc_tensor(sess);
  data_b_79->name = "data_b_79";
  data_b_79->data = params_base + 350648;
  data_b_79->is_const = 1;
  data_b_79->dtype = CSINN_DTYPE_INT8;
  data_b_79->layout = CSINN_LAYOUT_OIW;
  data_b_79->dim[0] = 1;
  data_b_79->dim[1] = 144;
  data_b_79->dim[2] = 432;
  data_b_79->dim_count = 3;
  memcpy(data_b_79->qinfo, params_base + 350624, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_79 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_79->trans_a = false;
  params_79->trans_b = false;
  params_79->base.name = "batch_matmul_/layer_3/layer_3.1/global_rep.0/pre_norm_mha.1/qkv_proj/MatMul_68";
  params_79->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_77, data_b_79, output_79, params_79);
  struct csinn_tensor *output_81 = csinn_alloc_tensor(sess);
  output_81->name = "output_81";
  output_81->dtype = CSINN_DTYPE_FLOAT16;
  output_81->layout = CSINN_LAYOUT_NCW;
  output_81->dim[0] = 4;
  output_81->dim[1] = 256;
  output_81->dim[2] = 432;
  output_81->dim_count = 3;
  memcpy(output_81->qinfo, params_base + 412856, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *rhs_81 = csinn_alloc_tensor(sess);
  rhs_81->name = "rhs_81";
  rhs_81->data = params_base + 412904;
  rhs_81->is_const = 1;
  rhs_81->dtype = CSINN_DTYPE_FLOAT16;
  rhs_81->layout = CSINN_LAYOUT_OIW;
  rhs_81->dim[0] = 1;
  rhs_81->dim[1] = 1;
  rhs_81->dim[2] = 432;
  rhs_81->dim_count = 3;
  memcpy(rhs_81->qinfo, params_base + 412880, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_81 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_81->base.name = "add_/layer_3/layer_3.1/global_rep.0/pre_norm_mha.1/qkv_proj/Add_70";
  params_81->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_79, rhs_81, output_81, params_81);
  int32_t *shape_83 = malloc(5 * 4);
  shape_83[0] = 4;
  shape_83[1] = 256;
  shape_83[2] = 3;
  shape_83[3] = 4;
  shape_83[4] = -1;
  struct csinn_tensor *output_83 = csinn_alloc_tensor(sess);
  output_83->name = "output_83";
  output_83->dtype = CSINN_DTYPE_FLOAT16;
  output_83->layout = CSINN_LAYOUT_NCDHW;
  output_83->dim[0] = 4;
  output_83->dim[1] = 256;
  output_83->dim[2] = 3;
  output_83->dim[3] = 4;
  output_83->dim[4] = 36;
  output_83->dim_count = 5;
  memcpy(output_83->qinfo, params_base + 413768, sizeof(struct csinn_quant_info) * 1);
  struct csinn_reshape_params *params_83 = csinn_alloc_params(sizeof(struct csinn_reshape_params), sess);
  params_83->shape = shape_83;
  params_83->shape_num = 5;
  params_83->base.name = "reshape_/layer_3/layer_3.1/global_rep.0/pre_norm_mha.1/Reshape_71";
  params_83->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_reshape_init(output_81, output_83, params_83);
  int32_t *permute_84 = malloc(5 * 4);
  permute_84[0] = 0;
  permute_84[1] = 3;
  permute_84[2] = 2;
  permute_84[3] = 1;
  permute_84[4] = 4;
  struct csinn_tensor *output_84 = csinn_alloc_tensor(sess);
  output_84->name = "output_84";
  output_84->dtype = CSINN_DTYPE_FLOAT16;
  output_84->layout = CSINN_LAYOUT_NCDHW;
  output_84->dim[0] = 4;
  output_84->dim[1] = 4;
  output_84->dim[2] = 3;
  output_84->dim[3] = 256;
  output_84->dim[4] = 36;
  output_84->dim_count = 5;
  memcpy(output_84->qinfo, params_base + 413792, sizeof(struct csinn_quant_info) * 1);
  struct csinn_transpose_params *params_84 = csinn_alloc_params(sizeof(struct csinn_transpose_params), sess);
  params_84->permute = permute_84;
  params_84->permute_num = 5;
  params_84->base.name = "transpose_/layer_3/layer_3.1/global_rep.0/pre_norm_mha.1/Transpose_72";
  params_84->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_transpose_init(output_83, output_84, params_84);
  struct csinn_tensor *output_85 = csinn_alloc_tensor(sess);
  output_85->name = "output_85";
  output_85->dtype = CSINN_DTYPE_FLOAT16;
  output_85->layout = CSINN_LAYOUT_NCHW;
  output_85->dim[0] = 4;
  output_85->dim[1] = 4;
  output_85->dim[2] = 256;
  output_85->dim[3] = 36;
  output_85->dim_count = 4;
  memcpy(output_85->qinfo, params_base + 413816, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *indices_85 = csinn_alloc_tensor(sess);
  indices_85->name = "indices_85";
  indices_85->data = params_base + 413864;
  indices_85->is_const = 1;
  indices_85->dtype = CSINN_DTYPE_INT64;
  indices_85->layout = CSINN_LAYOUT_O;
  indices_85->dim[0] = 1;
  indices_85->dim_count = 1;
  memcpy(indices_85->qinfo, params_base + 413840, sizeof(struct csinn_quant_info) * 1);
  struct csinn_gather_params *params_85 = csinn_alloc_params(sizeof(struct csinn_gather_params), sess);
  params_85->axis = 2;
  params_85->base.name = "take_/layer_3/layer_3.1/global_rep.0/pre_norm_mha.1/Gather_73";
  params_85->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_gather_init(output_84, indices_85, output_85, params_85);
  struct csinn_tensor *output_87 = csinn_alloc_tensor(sess);
  output_87->name = "output_87";
  output_87->dtype = CSINN_DTYPE_FLOAT16;
  output_87->layout = CSINN_LAYOUT_NCHW;
  output_87->dim[0] = 4;
  output_87->dim[1] = 4;
  output_87->dim[2] = 256;
  output_87->dim[3] = 36;
  output_87->dim_count = 4;
  memcpy(output_87->qinfo, params_base + 413872, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *rhs_87 = csinn_alloc_tensor(sess);
  rhs_87->name = "rhs_87";
  rhs_87->data = params_base + 413920;
  rhs_87->is_const = 1;
  rhs_87->dtype = CSINN_DTYPE_FLOAT16;
  rhs_87->layout = CSINN_LAYOUT_OIHW;
  rhs_87->dim[0] = 1;
  rhs_87->dim[1] = 1;
  rhs_87->dim[2] = 1;
  rhs_87->dim[3] = 1;
  rhs_87->dim_count = 4;
  memcpy(rhs_87->qinfo, params_base + 413896, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_87 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_87->base.name = "multiply_/layer_3/layer_3.1/global_rep.0/pre_norm_mha.1/Mul_74";
  params_87->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_mul_init(output_85, rhs_87, output_87, params_87);
  struct csinn_tensor *output_90 = csinn_alloc_tensor(sess);
  output_90->name = "output_90";
  output_90->dtype = CSINN_DTYPE_FLOAT16;
  output_90->layout = CSINN_LAYOUT_NCHW;
  output_90->dim[0] = 4;
  output_90->dim[1] = 4;
  output_90->dim[2] = 256;
  output_90->dim[3] = 36;
  output_90->dim_count = 4;
  memcpy(output_90->qinfo, params_base + 413924, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *indices_90 = csinn_alloc_tensor(sess);
  indices_90->name = "indices_90";
  indices_90->data = params_base + 413972;
  indices_90->is_const = 1;
  indices_90->dtype = CSINN_DTYPE_INT64;
  indices_90->layout = CSINN_LAYOUT_O;
  indices_90->dim[0] = 1;
  indices_90->dim_count = 1;
  memcpy(indices_90->qinfo, params_base + 413948, sizeof(struct csinn_quant_info) * 1);
  struct csinn_gather_params *params_90 = csinn_alloc_params(sizeof(struct csinn_gather_params), sess);
  params_90->axis = 2;
  params_90->base.name = "take_/layer_3/layer_3.1/global_rep.0/pre_norm_mha.1/Gather_1_76";
  params_90->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_gather_init(output_84, indices_90, output_90, params_90);
  int32_t *permute_91 = malloc(4 * 4);
  permute_91[0] = 0;
  permute_91[1] = 1;
  permute_91[2] = 3;
  permute_91[3] = 2;
  struct csinn_tensor *output_91 = csinn_alloc_tensor(sess);
  output_91->name = "output_91";
  output_91->dtype = CSINN_DTYPE_FLOAT16;
  output_91->layout = CSINN_LAYOUT_NCHW;
  output_91->dim[0] = 4;
  output_91->dim[1] = 4;
  output_91->dim[2] = 36;
  output_91->dim[3] = 256;
  output_91->dim_count = 4;
  memcpy(output_91->qinfo, params_base + 413980, sizeof(struct csinn_quant_info) * 1);
  struct csinn_transpose_params *params_91 = csinn_alloc_params(sizeof(struct csinn_transpose_params), sess);
  params_91->permute = permute_91;
  params_91->permute_num = 4;
  params_91->base.name = "transpose_/layer_3/layer_3.1/global_rep.0/pre_norm_mha.1/Transpose_1_77";
  params_91->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_transpose_init(output_90, output_91, params_91);
  struct csinn_tensor *output_92 = csinn_alloc_tensor(sess);
  output_92->name = "output_92";
  output_92->dtype = CSINN_DTYPE_FLOAT16;
  output_92->layout = CSINN_LAYOUT_NCHW;
  output_92->dim[0] = 4;
  output_92->dim[1] = 4;
  output_92->dim[2] = 256;
  output_92->dim[3] = 256;
  output_92->dim_count = 4;
  memcpy(output_92->qinfo, params_base + 414004, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_92 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_92->trans_a = false;
  params_92->trans_b = false;
  params_92->base.name = "batch_matmul_/layer_3/layer_3.1/global_rep.0/pre_norm_mha.1/MatMul_79";
  params_92->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_87, output_91, output_92, params_92);
  struct csinn_tensor *output_93 = csinn_alloc_tensor(sess);
  output_93->name = "output_93";
  output_93->dtype = CSINN_DTYPE_FLOAT16;
  output_93->layout = CSINN_LAYOUT_NCHW;
  output_93->dim[0] = 4;
  output_93->dim[1] = 4;
  output_93->dim[2] = 256;
  output_93->dim[3] = 256;
  output_93->dim_count = 4;
  memcpy(output_93->qinfo, params_base + 414028, sizeof(struct csinn_quant_info) * 1);
  struct csinn_softmax_params *params_93 = csinn_alloc_params(sizeof(struct csinn_softmax_params), sess);
  params_93->axis = 3;
  params_93->base.name = "softmax_/layer_3/layer_3.1/global_rep.0/pre_norm_mha.1/softmax/Softmax_81";
  params_93->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_softmax_init(output_92, output_93, params_93);
  struct csinn_tensor *output_95 = csinn_alloc_tensor(sess);
  output_95->name = "output_95";
  output_95->dtype = CSINN_DTYPE_FLOAT16;
  output_95->layout = CSINN_LAYOUT_NCHW;
  output_95->dim[0] = 4;
  output_95->dim[1] = 4;
  output_95->dim[2] = 256;
  output_95->dim[3] = 36;
  output_95->dim_count = 4;
  memcpy(output_95->qinfo, params_base + 414052, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *indices_95 = csinn_alloc_tensor(sess);
  indices_95->name = "indices_95";
  indices_95->data = params_base + 414100;
  indices_95->is_const = 1;
  indices_95->dtype = CSINN_DTYPE_INT64;
  indices_95->layout = CSINN_LAYOUT_O;
  indices_95->dim[0] = 1;
  indices_95->dim_count = 1;
  memcpy(indices_95->qinfo, params_base + 414076, sizeof(struct csinn_quant_info) * 1);
  struct csinn_gather_params *params_95 = csinn_alloc_params(sizeof(struct csinn_gather_params), sess);
  params_95->axis = 2;
  params_95->base.name = "take_/layer_3/layer_3.1/global_rep.0/pre_norm_mha.1/Gather_2_83";
  params_95->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_gather_init(output_84, indices_95, output_95, params_95);
  struct csinn_tensor *output_96 = csinn_alloc_tensor(sess);
  output_96->name = "output_96";
  output_96->dtype = CSINN_DTYPE_FLOAT16;
  output_96->layout = CSINN_LAYOUT_NCHW;
  output_96->dim[0] = 4;
  output_96->dim[1] = 4;
  output_96->dim[2] = 256;
  output_96->dim[3] = 36;
  output_96->dim_count = 4;
  memcpy(output_96->qinfo, params_base + 414108, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_96 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_96->trans_a = false;
  params_96->trans_b = false;
  params_96->base.name = "batch_matmul_/layer_3/layer_3.1/global_rep.0/pre_norm_mha.1/MatMul_1_85";
  params_96->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_93, output_95, output_96, params_96);
  int32_t *permute_97 = malloc(4 * 4);
  permute_97[0] = 0;
  permute_97[1] = 2;
  permute_97[2] = 1;
  permute_97[3] = 3;
  struct csinn_tensor *output_97 = csinn_alloc_tensor(sess);
  output_97->name = "output_97";
  output_97->dtype = CSINN_DTYPE_FLOAT16;
  output_97->layout = CSINN_LAYOUT_NCHW;
  output_97->dim[0] = 4;
  output_97->dim[1] = 256;
  output_97->dim[2] = 4;
  output_97->dim[3] = 36;
  output_97->dim_count = 4;
  memcpy(output_97->qinfo, params_base + 414132, sizeof(struct csinn_quant_info) * 1);
  struct csinn_transpose_params *params_97 = csinn_alloc_params(sizeof(struct csinn_transpose_params), sess);
  params_97->permute = permute_97;
  params_97->permute_num = 4;
  params_97->base.name = "transpose_/layer_3/layer_3.1/global_rep.0/pre_norm_mha.1/Transpose_2_87";
  params_97->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_transpose_init(output_96, output_97, params_97);
  int32_t *shape_98 = malloc(3 * 4);
  shape_98[0] = 4;
  shape_98[1] = 256;
  shape_98[2] = -1;
  struct csinn_tensor *output_98 = csinn_alloc_tensor(sess);
  output_98->name = "output_98";
  output_98->dtype = CSINN_DTYPE_FLOAT16;
  output_98->layout = CSINN_LAYOUT_NCW;
  output_98->dim[0] = 4;
  output_98->dim[1] = 256;
  output_98->dim[2] = 144;
  output_98->dim_count = 3;
  memcpy(output_98->qinfo, params_base + 414156, sizeof(struct csinn_quant_info) * 1);
  struct csinn_reshape_params *params_98 = csinn_alloc_params(sizeof(struct csinn_reshape_params), sess);
  params_98->shape = shape_98;
  params_98->shape_num = 3;
  params_98->base.name = "reshape_/layer_3/layer_3.1/global_rep.0/pre_norm_mha.1/Reshape_1_88";
  params_98->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_reshape_init(output_97, output_98, params_98);
  struct csinn_tensor *output_100 = csinn_alloc_tensor(sess);
  output_100->name = "output_100";
  output_100->dtype = CSINN_DTYPE_FLOAT16;
  output_100->layout = CSINN_LAYOUT_NCW;
  output_100->dim[0] = 4;
  output_100->dim[1] = 256;
  output_100->dim[2] = 144;
  output_100->dim_count = 3;
  memcpy(output_100->qinfo, params_base + 414180, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *data_b_100 = csinn_alloc_tensor(sess);
  data_b_100->name = "data_b_100";
  data_b_100->data = params_base + 414228;
  data_b_100->is_const = 1;
  data_b_100->dtype = CSINN_DTYPE_INT8;
  data_b_100->layout = CSINN_LAYOUT_OIW;
  data_b_100->dim[0] = 1;
  data_b_100->dim[1] = 144;
  data_b_100->dim[2] = 144;
  data_b_100->dim_count = 3;
  memcpy(data_b_100->qinfo, params_base + 414204, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_100 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_100->trans_a = false;
  params_100->trans_b = false;
  params_100->base.name = "batch_matmul_/layer_3/layer_3.1/global_rep.0/pre_norm_mha.1/out_proj/MatMul_89";
  params_100->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_98, data_b_100, output_100, params_100);
  struct csinn_tensor *output_102 = csinn_alloc_tensor(sess);
  output_102->name = "output_102";
  output_102->dtype = CSINN_DTYPE_FLOAT16;
  output_102->layout = CSINN_LAYOUT_NCW;
  output_102->dim[0] = 4;
  output_102->dim[1] = 256;
  output_102->dim[2] = 144;
  output_102->dim_count = 3;
  memcpy(output_102->qinfo, params_base + 434964, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *rhs_102 = csinn_alloc_tensor(sess);
  rhs_102->name = "rhs_102";
  rhs_102->data = params_base + 435012;
  rhs_102->is_const = 1;
  rhs_102->dtype = CSINN_DTYPE_FLOAT16;
  rhs_102->layout = CSINN_LAYOUT_OIW;
  rhs_102->dim[0] = 1;
  rhs_102->dim[1] = 1;
  rhs_102->dim[2] = 144;
  rhs_102->dim_count = 3;
  memcpy(rhs_102->qinfo, params_base + 434988, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_102 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_102->base.name = "add_/layer_3/layer_3.1/global_rep.0/pre_norm_mha.1/out_proj/Add_91";
  params_102->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_100, rhs_102, output_102, params_102);
  struct csinn_tensor *output_105 = csinn_alloc_tensor(sess);
  output_105->name = "output_105";
  output_105->dtype = CSINN_DTYPE_FLOAT16;
  output_105->layout = CSINN_LAYOUT_NCW;
  output_105->dim[0] = 4;
  output_105->dim[1] = 256;
  output_105->dim[2] = 144;
  output_105->dim_count = 3;
  memcpy(output_105->qinfo, params_base + 435300, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_105 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_105->base.name = "add_/layer_3/layer_3.1/global_rep.0/Add_92";
  params_105->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_102, output_76, output_105, params_105);
  struct csinn_tensor *output_108 = csinn_alloc_tensor(sess);
  output_108->name = "output_108";
  output_108->dtype = CSINN_DTYPE_FLOAT16;
  output_108->layout = CSINN_LAYOUT_NCW;
  output_108->dim[0] = 4;
  output_108->dim[1] = 256;
  output_108->dim[2] = 144;
  output_108->dim_count = 3;
  memcpy(output_108->qinfo, params_base + 435324, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *gamma_108 = csinn_alloc_tensor(sess);
  gamma_108->name = "gamma_108";
  gamma_108->data = params_base + 435372;
  gamma_108->is_const = 1;
  gamma_108->dtype = CSINN_DTYPE_FLOAT16;
  gamma_108->layout = CSINN_LAYOUT_O;
  gamma_108->dim[0] = 144;
  gamma_108->dim_count = 1;
  memcpy(gamma_108->qinfo, params_base + 435348, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *beta_108 = csinn_alloc_tensor(sess);
  beta_108->name = "beta_108";
  beta_108->data = params_base + 435684;
  beta_108->is_const = 1;
  beta_108->dtype = CSINN_DTYPE_FLOAT16;
  beta_108->layout = CSINN_LAYOUT_O;
  beta_108->dim[0] = 144;
  beta_108->dim_count = 1;
  memcpy(beta_108->qinfo, params_base + 435660, sizeof(struct csinn_quant_info) * 1);
  struct csinn_layer_norm_params *params_108 = csinn_alloc_params(sizeof(struct csinn_layer_norm_params), sess);
  params_108->epsilon = 1e-05;
  params_108->axis = -1;
  params_108->center = true;
  params_108->scale = true;
  params_108->base.name = "layer_norm_93";
  params_108->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_layer_norm_init(output_105, output_108, gamma_108, beta_108, params_108);
  struct csinn_tensor *output_110 = csinn_alloc_tensor(sess);
  output_110->name = "output_110";
  output_110->dtype = CSINN_DTYPE_FLOAT16;
  output_110->layout = CSINN_LAYOUT_NCW;
  output_110->dim[0] = 4;
  output_110->dim[1] = 256;
  output_110->dim[2] = 288;
  output_110->dim_count = 3;
  memcpy(output_110->qinfo, params_base + 435972, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *data_b_110 = csinn_alloc_tensor(sess);
  data_b_110->name = "data_b_110";
  data_b_110->data = params_base + 436020;
  data_b_110->is_const = 1;
  data_b_110->dtype = CSINN_DTYPE_INT8;
  data_b_110->layout = CSINN_LAYOUT_OIW;
  data_b_110->dim[0] = 1;
  data_b_110->dim[1] = 144;
  data_b_110->dim[2] = 288;
  data_b_110->dim_count = 3;
  memcpy(data_b_110->qinfo, params_base + 435996, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_110 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_110->trans_a = false;
  params_110->trans_b = false;
  params_110->base.name = "batch_matmul_/layer_3/layer_3.1/global_rep.0/pre_norm_ffn/pre_norm_ffn.1/MatMul_94";
  params_110->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_108, data_b_110, output_110, params_110);
  struct csinn_tensor *output_112 = csinn_alloc_tensor(sess);
  output_112->name = "output_112";
  output_112->dtype = CSINN_DTYPE_FLOAT16;
  output_112->layout = CSINN_LAYOUT_NCW;
  output_112->dim[0] = 4;
  output_112->dim[1] = 256;
  output_112->dim[2] = 288;
  output_112->dim_count = 3;
  memcpy(output_112->qinfo, params_base + 477492, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *rhs_112 = csinn_alloc_tensor(sess);
  rhs_112->name = "rhs_112";
  rhs_112->data = params_base + 477540;
  rhs_112->is_const = 1;
  rhs_112->dtype = CSINN_DTYPE_FLOAT16;
  rhs_112->layout = CSINN_LAYOUT_OIW;
  rhs_112->dim[0] = 1;
  rhs_112->dim[1] = 1;
  rhs_112->dim[2] = 288;
  rhs_112->dim_count = 3;
  memcpy(rhs_112->qinfo, params_base + 477516, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_112 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_112->base.name = "add_/layer_3/layer_3.1/global_rep.0/pre_norm_ffn/pre_norm_ffn.1/Add_96";
  params_112->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_110, rhs_112, output_112, params_112);
  struct csinn_tensor *output_115 = csinn_alloc_tensor(sess);
  output_115->name = "output_115";
  output_115->dtype = CSINN_DTYPE_FLOAT16;
  output_115->layout = CSINN_LAYOUT_NCW;
  output_115->dim[0] = 4;
  output_115->dim[1] = 256;
  output_115->dim[2] = 288;
  output_115->dim_count = 3;
  memcpy(output_115->qinfo, params_base + 478116, sizeof(struct csinn_quant_info) * 1);
  struct csinn_sigmoid_params *params_115 = csinn_alloc_params(sizeof(struct csinn_sigmoid_params), sess);
  params_115->base.name = "sigmoid_/layer_3/layer_3.1/global_rep.0/pre_norm_ffn/pre_norm_ffn.2/Sigmoid_97";
  params_115->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_sigmoid_init(output_112, output_115, params_115);
  struct csinn_tensor *output_116 = csinn_alloc_tensor(sess);
  output_116->name = "output_116";
  output_116->dtype = CSINN_DTYPE_FLOAT16;
  output_116->layout = CSINN_LAYOUT_NCW;
  output_116->dim[0] = 4;
  output_116->dim[1] = 256;
  output_116->dim[2] = 288;
  output_116->dim_count = 3;
  memcpy(output_116->qinfo, params_base + 478140, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_116 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_116->base.name = "multiply_/layer_3/layer_3.1/global_rep.0/pre_norm_ffn/pre_norm_ffn.2/Mul_98";
  params_116->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_mul_init(output_112, output_115, output_116, params_116);
  struct csinn_tensor *output_119 = csinn_alloc_tensor(sess);
  output_119->name = "output_119";
  output_119->dtype = CSINN_DTYPE_FLOAT16;
  output_119->layout = CSINN_LAYOUT_NCW;
  output_119->dim[0] = 4;
  output_119->dim[1] = 256;
  output_119->dim[2] = 144;
  output_119->dim_count = 3;
  memcpy(output_119->qinfo, params_base + 478164, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *data_b_119 = csinn_alloc_tensor(sess);
  data_b_119->name = "data_b_119";
  data_b_119->data = params_base + 478212;
  data_b_119->is_const = 1;
  data_b_119->dtype = CSINN_DTYPE_INT8;
  data_b_119->layout = CSINN_LAYOUT_OIW;
  data_b_119->dim[0] = 1;
  data_b_119->dim[1] = 288;
  data_b_119->dim[2] = 144;
  data_b_119->dim_count = 3;
  memcpy(data_b_119->qinfo, params_base + 478188, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_119 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_119->trans_a = false;
  params_119->trans_b = false;
  params_119->base.name = "batch_matmul_/layer_3/layer_3.1/global_rep.0/pre_norm_ffn/pre_norm_ffn.4/MatMul_99";
  params_119->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_116, data_b_119, output_119, params_119);
  struct csinn_tensor *output_121 = csinn_alloc_tensor(sess);
  output_121->name = "output_121";
  output_121->dtype = CSINN_DTYPE_FLOAT16;
  output_121->layout = CSINN_LAYOUT_NCW;
  output_121->dim[0] = 4;
  output_121->dim[1] = 256;
  output_121->dim[2] = 144;
  output_121->dim_count = 3;
  memcpy(output_121->qinfo, params_base + 519684, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *rhs_121 = csinn_alloc_tensor(sess);
  rhs_121->name = "rhs_121";
  rhs_121->data = params_base + 519732;
  rhs_121->is_const = 1;
  rhs_121->dtype = CSINN_DTYPE_FLOAT16;
  rhs_121->layout = CSINN_LAYOUT_OIW;
  rhs_121->dim[0] = 1;
  rhs_121->dim[1] = 1;
  rhs_121->dim[2] = 144;
  rhs_121->dim_count = 3;
  memcpy(rhs_121->qinfo, params_base + 519708, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_121 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_121->base.name = "add_/layer_3/layer_3.1/global_rep.0/pre_norm_ffn/pre_norm_ffn.4/Add_101";
  params_121->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_119, rhs_121, output_121, params_121);
  struct csinn_tensor *output_123 = csinn_alloc_tensor(sess);
  output_123->name = "output_123";
  output_123->dtype = CSINN_DTYPE_FLOAT16;
  output_123->layout = CSINN_LAYOUT_NCW;
  output_123->dim[0] = 4;
  output_123->dim[1] = 256;
  output_123->dim[2] = 144;
  output_123->dim_count = 3;
  memcpy(output_123->qinfo, params_base + 520020, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_123 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_123->base.name = "add_/layer_3/layer_3.1/global_rep.0/Add_1_102";
  params_123->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_105, output_121, output_123, params_123);
  struct csinn_tensor *output_125 = csinn_alloc_tensor(sess);
  output_125->name = "output_125";
  output_125->dtype = CSINN_DTYPE_FLOAT16;
  output_125->layout = CSINN_LAYOUT_NCW;
  output_125->dim[0] = 4;
  output_125->dim[1] = 256;
  output_125->dim[2] = 144;
  output_125->dim_count = 3;
  memcpy(output_125->qinfo, params_base + 520044, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *gamma_125 = csinn_alloc_tensor(sess);
  gamma_125->name = "gamma_125";
  gamma_125->data = params_base + 520092;
  gamma_125->is_const = 1;
  gamma_125->dtype = CSINN_DTYPE_FLOAT16;
  gamma_125->layout = CSINN_LAYOUT_O;
  gamma_125->dim[0] = 144;
  gamma_125->dim_count = 1;
  memcpy(gamma_125->qinfo, params_base + 520068, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *beta_125 = csinn_alloc_tensor(sess);
  beta_125->name = "beta_125";
  beta_125->data = params_base + 520404;
  beta_125->is_const = 1;
  beta_125->dtype = CSINN_DTYPE_FLOAT16;
  beta_125->layout = CSINN_LAYOUT_O;
  beta_125->dim[0] = 144;
  beta_125->dim_count = 1;
  memcpy(beta_125->qinfo, params_base + 520380, sizeof(struct csinn_quant_info) * 1);
  struct csinn_layer_norm_params *params_125 = csinn_alloc_params(sizeof(struct csinn_layer_norm_params), sess);
  params_125->epsilon = 1e-05;
  params_125->axis = -1;
  params_125->center = true;
  params_125->scale = true;
  params_125->base.name = "layer_norm_103";
  params_125->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_layer_norm_init(output_123, output_125, gamma_125, beta_125, params_125);
  struct csinn_tensor *output_127 = csinn_alloc_tensor(sess);
  output_127->name = "output_127";
  output_127->dtype = CSINN_DTYPE_FLOAT16;
  output_127->layout = CSINN_LAYOUT_NCW;
  output_127->dim[0] = 4;
  output_127->dim[1] = 256;
  output_127->dim[2] = 432;
  output_127->dim_count = 3;
  memcpy(output_127->qinfo, params_base + 520692, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *data_b_127 = csinn_alloc_tensor(sess);
  data_b_127->name = "data_b_127";
  data_b_127->data = params_base + 520740;
  data_b_127->is_const = 1;
  data_b_127->dtype = CSINN_DTYPE_INT8;
  data_b_127->layout = CSINN_LAYOUT_OIW;
  data_b_127->dim[0] = 1;
  data_b_127->dim[1] = 144;
  data_b_127->dim[2] = 432;
  data_b_127->dim_count = 3;
  memcpy(data_b_127->qinfo, params_base + 520716, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_127 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_127->trans_a = false;
  params_127->trans_b = false;
  params_127->base.name = "batch_matmul_/layer_3/layer_3.1/global_rep.1/pre_norm_mha.1/qkv_proj/MatMul_104";
  params_127->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_125, data_b_127, output_127, params_127);
  struct csinn_tensor *output_129 = csinn_alloc_tensor(sess);
  output_129->name = "output_129";
  output_129->dtype = CSINN_DTYPE_FLOAT16;
  output_129->layout = CSINN_LAYOUT_NCW;
  output_129->dim[0] = 4;
  output_129->dim[1] = 256;
  output_129->dim[2] = 432;
  output_129->dim_count = 3;
  memcpy(output_129->qinfo, params_base + 582948, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *rhs_129 = csinn_alloc_tensor(sess);
  rhs_129->name = "rhs_129";
  rhs_129->data = params_base + 582996;
  rhs_129->is_const = 1;
  rhs_129->dtype = CSINN_DTYPE_FLOAT16;
  rhs_129->layout = CSINN_LAYOUT_OIW;
  rhs_129->dim[0] = 1;
  rhs_129->dim[1] = 1;
  rhs_129->dim[2] = 432;
  rhs_129->dim_count = 3;
  memcpy(rhs_129->qinfo, params_base + 582972, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_129 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_129->base.name = "add_/layer_3/layer_3.1/global_rep.1/pre_norm_mha.1/qkv_proj/Add_106";
  params_129->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_127, rhs_129, output_129, params_129);
  int32_t *shape_131 = malloc(5 * 4);
  shape_131[0] = 4;
  shape_131[1] = 256;
  shape_131[2] = 3;
  shape_131[3] = 4;
  shape_131[4] = -1;
  struct csinn_tensor *output_131 = csinn_alloc_tensor(sess);
  output_131->name = "output_131";
  output_131->dtype = CSINN_DTYPE_FLOAT16;
  output_131->layout = CSINN_LAYOUT_NCDHW;
  output_131->dim[0] = 4;
  output_131->dim[1] = 256;
  output_131->dim[2] = 3;
  output_131->dim[3] = 4;
  output_131->dim[4] = 36;
  output_131->dim_count = 5;
  memcpy(output_131->qinfo, params_base + 583860, sizeof(struct csinn_quant_info) * 1);
  struct csinn_reshape_params *params_131 = csinn_alloc_params(sizeof(struct csinn_reshape_params), sess);
  params_131->shape = shape_131;
  params_131->shape_num = 5;
  params_131->base.name = "reshape_/layer_3/layer_3.1/global_rep.1/pre_norm_mha.1/Reshape_107";
  params_131->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_reshape_init(output_129, output_131, params_131);
  int32_t *permute_132 = malloc(5 * 4);
  permute_132[0] = 0;
  permute_132[1] = 3;
  permute_132[2] = 2;
  permute_132[3] = 1;
  permute_132[4] = 4;
  struct csinn_tensor *output_132 = csinn_alloc_tensor(sess);
  output_132->name = "output_132";
  output_132->dtype = CSINN_DTYPE_FLOAT16;
  output_132->layout = CSINN_LAYOUT_NCDHW;
  output_132->dim[0] = 4;
  output_132->dim[1] = 4;
  output_132->dim[2] = 3;
  output_132->dim[3] = 256;
  output_132->dim[4] = 36;
  output_132->dim_count = 5;
  memcpy(output_132->qinfo, params_base + 583884, sizeof(struct csinn_quant_info) * 1);
  struct csinn_transpose_params *params_132 = csinn_alloc_params(sizeof(struct csinn_transpose_params), sess);
  params_132->permute = permute_132;
  params_132->permute_num = 5;
  params_132->base.name = "transpose_/layer_3/layer_3.1/global_rep.1/pre_norm_mha.1/Transpose_108";
  params_132->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_transpose_init(output_131, output_132, params_132);
  struct csinn_tensor *output_133 = csinn_alloc_tensor(sess);
  output_133->name = "output_133";
  output_133->dtype = CSINN_DTYPE_FLOAT16;
  output_133->layout = CSINN_LAYOUT_NCHW;
  output_133->dim[0] = 4;
  output_133->dim[1] = 4;
  output_133->dim[2] = 256;
  output_133->dim[3] = 36;
  output_133->dim_count = 4;
  memcpy(output_133->qinfo, params_base + 583908, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *indices_133 = csinn_alloc_tensor(sess);
  indices_133->name = "indices_133";
  indices_133->data = params_base + 583956;
  indices_133->is_const = 1;
  indices_133->dtype = CSINN_DTYPE_INT64;
  indices_133->layout = CSINN_LAYOUT_O;
  indices_133->dim[0] = 1;
  indices_133->dim_count = 1;
  memcpy(indices_133->qinfo, params_base + 583932, sizeof(struct csinn_quant_info) * 1);
  struct csinn_gather_params *params_133 = csinn_alloc_params(sizeof(struct csinn_gather_params), sess);
  params_133->axis = 2;
  params_133->base.name = "take_/layer_3/layer_3.1/global_rep.1/pre_norm_mha.1/Gather_109";
  params_133->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_gather_init(output_132, indices_133, output_133, params_133);
  struct csinn_tensor *output_135 = csinn_alloc_tensor(sess);
  output_135->name = "output_135";
  output_135->dtype = CSINN_DTYPE_FLOAT16;
  output_135->layout = CSINN_LAYOUT_NCHW;
  output_135->dim[0] = 4;
  output_135->dim[1] = 4;
  output_135->dim[2] = 256;
  output_135->dim[3] = 36;
  output_135->dim_count = 4;
  memcpy(output_135->qinfo, params_base + 583964, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *rhs_135 = csinn_alloc_tensor(sess);
  rhs_135->name = "rhs_135";
  rhs_135->data = params_base + 584012;
  rhs_135->is_const = 1;
  rhs_135->dtype = CSINN_DTYPE_FLOAT16;
  rhs_135->layout = CSINN_LAYOUT_OIHW;
  rhs_135->dim[0] = 1;
  rhs_135->dim[1] = 1;
  rhs_135->dim[2] = 1;
  rhs_135->dim[3] = 1;
  rhs_135->dim_count = 4;
  memcpy(rhs_135->qinfo, params_base + 583988, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_135 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_135->base.name = "multiply_/layer_3/layer_3.1/global_rep.1/pre_norm_mha.1/Mul_110";
  params_135->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_mul_init(output_133, rhs_135, output_135, params_135);
  struct csinn_tensor *output_138 = csinn_alloc_tensor(sess);
  output_138->name = "output_138";
  output_138->dtype = CSINN_DTYPE_FLOAT16;
  output_138->layout = CSINN_LAYOUT_NCHW;
  output_138->dim[0] = 4;
  output_138->dim[1] = 4;
  output_138->dim[2] = 256;
  output_138->dim[3] = 36;
  output_138->dim_count = 4;
  memcpy(output_138->qinfo, params_base + 584016, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *indices_138 = csinn_alloc_tensor(sess);
  indices_138->name = "indices_138";
  indices_138->data = params_base + 584064;
  indices_138->is_const = 1;
  indices_138->dtype = CSINN_DTYPE_INT64;
  indices_138->layout = CSINN_LAYOUT_O;
  indices_138->dim[0] = 1;
  indices_138->dim_count = 1;
  memcpy(indices_138->qinfo, params_base + 584040, sizeof(struct csinn_quant_info) * 1);
  struct csinn_gather_params *params_138 = csinn_alloc_params(sizeof(struct csinn_gather_params), sess);
  params_138->axis = 2;
  params_138->base.name = "take_/layer_3/layer_3.1/global_rep.1/pre_norm_mha.1/Gather_1_112";
  params_138->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_gather_init(output_132, indices_138, output_138, params_138);
  int32_t *permute_139 = malloc(4 * 4);
  permute_139[0] = 0;
  permute_139[1] = 1;
  permute_139[2] = 3;
  permute_139[3] = 2;
  struct csinn_tensor *output_139 = csinn_alloc_tensor(sess);
  output_139->name = "output_139";
  output_139->dtype = CSINN_DTYPE_FLOAT16;
  output_139->layout = CSINN_LAYOUT_NCHW;
  output_139->dim[0] = 4;
  output_139->dim[1] = 4;
  output_139->dim[2] = 36;
  output_139->dim[3] = 256;
  output_139->dim_count = 4;
  memcpy(output_139->qinfo, params_base + 584072, sizeof(struct csinn_quant_info) * 1);
  struct csinn_transpose_params *params_139 = csinn_alloc_params(sizeof(struct csinn_transpose_params), sess);
  params_139->permute = permute_139;
  params_139->permute_num = 4;
  params_139->base.name = "transpose_/layer_3/layer_3.1/global_rep.1/pre_norm_mha.1/Transpose_1_113";
  params_139->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_transpose_init(output_138, output_139, params_139);
  struct csinn_tensor *output_140 = csinn_alloc_tensor(sess);
  output_140->name = "output_140";
  output_140->dtype = CSINN_DTYPE_FLOAT16;
  output_140->layout = CSINN_LAYOUT_NCHW;
  output_140->dim[0] = 4;
  output_140->dim[1] = 4;
  output_140->dim[2] = 256;
  output_140->dim[3] = 256;
  output_140->dim_count = 4;
  memcpy(output_140->qinfo, params_base + 584096, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_140 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_140->trans_a = false;
  params_140->trans_b = false;
  params_140->base.name = "batch_matmul_/layer_3/layer_3.1/global_rep.1/pre_norm_mha.1/MatMul_115";
  params_140->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_135, output_139, output_140, params_140);
  struct csinn_tensor *output_141 = csinn_alloc_tensor(sess);
  output_141->name = "output_141";
  output_141->dtype = CSINN_DTYPE_FLOAT16;
  output_141->layout = CSINN_LAYOUT_NCHW;
  output_141->dim[0] = 4;
  output_141->dim[1] = 4;
  output_141->dim[2] = 256;
  output_141->dim[3] = 256;
  output_141->dim_count = 4;
  memcpy(output_141->qinfo, params_base + 584120, sizeof(struct csinn_quant_info) * 1);
  struct csinn_softmax_params *params_141 = csinn_alloc_params(sizeof(struct csinn_softmax_params), sess);
  params_141->axis = 3;
  params_141->base.name = "softmax_/layer_3/layer_3.1/global_rep.1/pre_norm_mha.1/softmax/Softmax_117";
  params_141->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_softmax_init(output_140, output_141, params_141);
  struct csinn_tensor *output_143 = csinn_alloc_tensor(sess);
  output_143->name = "output_143";
  output_143->dtype = CSINN_DTYPE_FLOAT16;
  output_143->layout = CSINN_LAYOUT_NCHW;
  output_143->dim[0] = 4;
  output_143->dim[1] = 4;
  output_143->dim[2] = 256;
  output_143->dim[3] = 36;
  output_143->dim_count = 4;
  memcpy(output_143->qinfo, params_base + 584144, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *indices_143 = csinn_alloc_tensor(sess);
  indices_143->name = "indices_143";
  indices_143->data = params_base + 584192;
  indices_143->is_const = 1;
  indices_143->dtype = CSINN_DTYPE_INT64;
  indices_143->layout = CSINN_LAYOUT_O;
  indices_143->dim[0] = 1;
  indices_143->dim_count = 1;
  memcpy(indices_143->qinfo, params_base + 584168, sizeof(struct csinn_quant_info) * 1);
  struct csinn_gather_params *params_143 = csinn_alloc_params(sizeof(struct csinn_gather_params), sess);
  params_143->axis = 2;
  params_143->base.name = "take_/layer_3/layer_3.1/global_rep.1/pre_norm_mha.1/Gather_2_119";
  params_143->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_gather_init(output_132, indices_143, output_143, params_143);
  struct csinn_tensor *output_144 = csinn_alloc_tensor(sess);
  output_144->name = "output_144";
  output_144->dtype = CSINN_DTYPE_FLOAT16;
  output_144->layout = CSINN_LAYOUT_NCHW;
  output_144->dim[0] = 4;
  output_144->dim[1] = 4;
  output_144->dim[2] = 256;
  output_144->dim[3] = 36;
  output_144->dim_count = 4;
  memcpy(output_144->qinfo, params_base + 584200, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_144 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_144->trans_a = false;
  params_144->trans_b = false;
  params_144->base.name = "batch_matmul_/layer_3/layer_3.1/global_rep.1/pre_norm_mha.1/MatMul_1_121";
  params_144->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_141, output_143, output_144, params_144);
  int32_t *permute_145 = malloc(4 * 4);
  permute_145[0] = 0;
  permute_145[1] = 2;
  permute_145[2] = 1;
  permute_145[3] = 3;
  struct csinn_tensor *output_145 = csinn_alloc_tensor(sess);
  output_145->name = "output_145";
  output_145->dtype = CSINN_DTYPE_FLOAT16;
  output_145->layout = CSINN_LAYOUT_NCHW;
  output_145->dim[0] = 4;
  output_145->dim[1] = 256;
  output_145->dim[2] = 4;
  output_145->dim[3] = 36;
  output_145->dim_count = 4;
  memcpy(output_145->qinfo, params_base + 584224, sizeof(struct csinn_quant_info) * 1);
  struct csinn_transpose_params *params_145 = csinn_alloc_params(sizeof(struct csinn_transpose_params), sess);
  params_145->permute = permute_145;
  params_145->permute_num = 4;
  params_145->base.name = "transpose_/layer_3/layer_3.1/global_rep.1/pre_norm_mha.1/Transpose_2_123";
  params_145->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_transpose_init(output_144, output_145, params_145);
  int32_t *shape_146 = malloc(3 * 4);
  shape_146[0] = 4;
  shape_146[1] = 256;
  shape_146[2] = -1;
  struct csinn_tensor *output_146 = csinn_alloc_tensor(sess);
  output_146->name = "output_146";
  output_146->dtype = CSINN_DTYPE_FLOAT16;
  output_146->layout = CSINN_LAYOUT_NCW;
  output_146->dim[0] = 4;
  output_146->dim[1] = 256;
  output_146->dim[2] = 144;
  output_146->dim_count = 3;
  memcpy(output_146->qinfo, params_base + 584248, sizeof(struct csinn_quant_info) * 1);
  struct csinn_reshape_params *params_146 = csinn_alloc_params(sizeof(struct csinn_reshape_params), sess);
  params_146->shape = shape_146;
  params_146->shape_num = 3;
  params_146->base.name = "reshape_/layer_3/layer_3.1/global_rep.1/pre_norm_mha.1/Reshape_1_124";
  params_146->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_reshape_init(output_145, output_146, params_146);
  struct csinn_tensor *output_148 = csinn_alloc_tensor(sess);
  output_148->name = "output_148";
  output_148->dtype = CSINN_DTYPE_FLOAT16;
  output_148->layout = CSINN_LAYOUT_NCW;
  output_148->dim[0] = 4;
  output_148->dim[1] = 256;
  output_148->dim[2] = 144;
  output_148->dim_count = 3;
  memcpy(output_148->qinfo, params_base + 584272, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *data_b_148 = csinn_alloc_tensor(sess);
  data_b_148->name = "data_b_148";
  data_b_148->data = params_base + 584320;
  data_b_148->is_const = 1;
  data_b_148->dtype = CSINN_DTYPE_INT8;
  data_b_148->layout = CSINN_LAYOUT_OIW;
  data_b_148->dim[0] = 1;
  data_b_148->dim[1] = 144;
  data_b_148->dim[2] = 144;
  data_b_148->dim_count = 3;
  memcpy(data_b_148->qinfo, params_base + 584296, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_148 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_148->trans_a = false;
  params_148->trans_b = false;
  params_148->base.name = "batch_matmul_/layer_3/layer_3.1/global_rep.1/pre_norm_mha.1/out_proj/MatMul_125";
  params_148->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_146, data_b_148, output_148, params_148);
  struct csinn_tensor *output_150 = csinn_alloc_tensor(sess);
  output_150->name = "output_150";
  output_150->dtype = CSINN_DTYPE_FLOAT16;
  output_150->layout = CSINN_LAYOUT_NCW;
  output_150->dim[0] = 4;
  output_150->dim[1] = 256;
  output_150->dim[2] = 144;
  output_150->dim_count = 3;
  memcpy(output_150->qinfo, params_base + 605056, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *rhs_150 = csinn_alloc_tensor(sess);
  rhs_150->name = "rhs_150";
  rhs_150->data = params_base + 605104;
  rhs_150->is_const = 1;
  rhs_150->dtype = CSINN_DTYPE_FLOAT16;
  rhs_150->layout = CSINN_LAYOUT_OIW;
  rhs_150->dim[0] = 1;
  rhs_150->dim[1] = 1;
  rhs_150->dim[2] = 144;
  rhs_150->dim_count = 3;
  memcpy(rhs_150->qinfo, params_base + 605080, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_150 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_150->base.name = "add_/layer_3/layer_3.1/global_rep.1/pre_norm_mha.1/out_proj/Add_127";
  params_150->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_148, rhs_150, output_150, params_150);
  struct csinn_tensor *output_153 = csinn_alloc_tensor(sess);
  output_153->name = "output_153";
  output_153->dtype = CSINN_DTYPE_FLOAT16;
  output_153->layout = CSINN_LAYOUT_NCW;
  output_153->dim[0] = 4;
  output_153->dim[1] = 256;
  output_153->dim[2] = 144;
  output_153->dim_count = 3;
  memcpy(output_153->qinfo, params_base + 605392, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_153 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_153->base.name = "add_/layer_3/layer_3.1/global_rep.1/Add_128";
  params_153->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_150, output_123, output_153, params_153);
  struct csinn_tensor *output_156 = csinn_alloc_tensor(sess);
  output_156->name = "output_156";
  output_156->dtype = CSINN_DTYPE_FLOAT16;
  output_156->layout = CSINN_LAYOUT_NCW;
  output_156->dim[0] = 4;
  output_156->dim[1] = 256;
  output_156->dim[2] = 144;
  output_156->dim_count = 3;
  memcpy(output_156->qinfo, params_base + 605416, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *gamma_156 = csinn_alloc_tensor(sess);
  gamma_156->name = "gamma_156";
  gamma_156->data = params_base + 605464;
  gamma_156->is_const = 1;
  gamma_156->dtype = CSINN_DTYPE_FLOAT16;
  gamma_156->layout = CSINN_LAYOUT_O;
  gamma_156->dim[0] = 144;
  gamma_156->dim_count = 1;
  memcpy(gamma_156->qinfo, params_base + 605440, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *beta_156 = csinn_alloc_tensor(sess);
  beta_156->name = "beta_156";
  beta_156->data = params_base + 605776;
  beta_156->is_const = 1;
  beta_156->dtype = CSINN_DTYPE_FLOAT16;
  beta_156->layout = CSINN_LAYOUT_O;
  beta_156->dim[0] = 144;
  beta_156->dim_count = 1;
  memcpy(beta_156->qinfo, params_base + 605752, sizeof(struct csinn_quant_info) * 1);
  struct csinn_layer_norm_params *params_156 = csinn_alloc_params(sizeof(struct csinn_layer_norm_params), sess);
  params_156->epsilon = 1e-05;
  params_156->axis = -1;
  params_156->center = true;
  params_156->scale = true;
  params_156->base.name = "layer_norm_129";
  params_156->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_layer_norm_init(output_153, output_156, gamma_156, beta_156, params_156);
  struct csinn_tensor *output_158 = csinn_alloc_tensor(sess);
  output_158->name = "output_158";
  output_158->dtype = CSINN_DTYPE_FLOAT16;
  output_158->layout = CSINN_LAYOUT_NCW;
  output_158->dim[0] = 4;
  output_158->dim[1] = 256;
  output_158->dim[2] = 288;
  output_158->dim_count = 3;
  memcpy(output_158->qinfo, params_base + 606064, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *data_b_158 = csinn_alloc_tensor(sess);
  data_b_158->name = "data_b_158";
  data_b_158->data = params_base + 606112;
  data_b_158->is_const = 1;
  data_b_158->dtype = CSINN_DTYPE_INT8;
  data_b_158->layout = CSINN_LAYOUT_OIW;
  data_b_158->dim[0] = 1;
  data_b_158->dim[1] = 144;
  data_b_158->dim[2] = 288;
  data_b_158->dim_count = 3;
  memcpy(data_b_158->qinfo, params_base + 606088, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_158 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_158->trans_a = false;
  params_158->trans_b = false;
  params_158->base.name = "batch_matmul_/layer_3/layer_3.1/global_rep.1/pre_norm_ffn/pre_norm_ffn.1/MatMul_130";
  params_158->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_156, data_b_158, output_158, params_158);
  struct csinn_tensor *output_160 = csinn_alloc_tensor(sess);
  output_160->name = "output_160";
  output_160->dtype = CSINN_DTYPE_FLOAT16;
  output_160->layout = CSINN_LAYOUT_NCW;
  output_160->dim[0] = 4;
  output_160->dim[1] = 256;
  output_160->dim[2] = 288;
  output_160->dim_count = 3;
  memcpy(output_160->qinfo, params_base + 647584, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *rhs_160 = csinn_alloc_tensor(sess);
  rhs_160->name = "rhs_160";
  rhs_160->data = params_base + 647632;
  rhs_160->is_const = 1;
  rhs_160->dtype = CSINN_DTYPE_FLOAT16;
  rhs_160->layout = CSINN_LAYOUT_OIW;
  rhs_160->dim[0] = 1;
  rhs_160->dim[1] = 1;
  rhs_160->dim[2] = 288;
  rhs_160->dim_count = 3;
  memcpy(rhs_160->qinfo, params_base + 647608, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_160 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_160->base.name = "add_/layer_3/layer_3.1/global_rep.1/pre_norm_ffn/pre_norm_ffn.1/Add_132";
  params_160->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_158, rhs_160, output_160, params_160);
  struct csinn_tensor *output_163 = csinn_alloc_tensor(sess);
  output_163->name = "output_163";
  output_163->dtype = CSINN_DTYPE_FLOAT16;
  output_163->layout = CSINN_LAYOUT_NCW;
  output_163->dim[0] = 4;
  output_163->dim[1] = 256;
  output_163->dim[2] = 288;
  output_163->dim_count = 3;
  memcpy(output_163->qinfo, params_base + 648208, sizeof(struct csinn_quant_info) * 1);
  struct csinn_sigmoid_params *params_163 = csinn_alloc_params(sizeof(struct csinn_sigmoid_params), sess);
  params_163->base.name = "sigmoid_/layer_3/layer_3.1/global_rep.1/pre_norm_ffn/pre_norm_ffn.2/Sigmoid_133";
  params_163->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_sigmoid_init(output_160, output_163, params_163);
  struct csinn_tensor *output_164 = csinn_alloc_tensor(sess);
  output_164->name = "output_164";
  output_164->dtype = CSINN_DTYPE_FLOAT16;
  output_164->layout = CSINN_LAYOUT_NCW;
  output_164->dim[0] = 4;
  output_164->dim[1] = 256;
  output_164->dim[2] = 288;
  output_164->dim_count = 3;
  memcpy(output_164->qinfo, params_base + 648232, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_164 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_164->base.name = "multiply_/layer_3/layer_3.1/global_rep.1/pre_norm_ffn/pre_norm_ffn.2/Mul_134";
  params_164->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_mul_init(output_160, output_163, output_164, params_164);
  struct csinn_tensor *output_167 = csinn_alloc_tensor(sess);
  output_167->name = "output_167";
  output_167->dtype = CSINN_DTYPE_FLOAT16;
  output_167->layout = CSINN_LAYOUT_NCW;
  output_167->dim[0] = 4;
  output_167->dim[1] = 256;
  output_167->dim[2] = 144;
  output_167->dim_count = 3;
  memcpy(output_167->qinfo, params_base + 648256, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *data_b_167 = csinn_alloc_tensor(sess);
  data_b_167->name = "data_b_167";
  data_b_167->data = params_base + 648304;
  data_b_167->is_const = 1;
  data_b_167->dtype = CSINN_DTYPE_INT8;
  data_b_167->layout = CSINN_LAYOUT_OIW;
  data_b_167->dim[0] = 1;
  data_b_167->dim[1] = 288;
  data_b_167->dim[2] = 144;
  data_b_167->dim_count = 3;
  memcpy(data_b_167->qinfo, params_base + 648280, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_167 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_167->trans_a = false;
  params_167->trans_b = false;
  params_167->base.name = "batch_matmul_/layer_3/layer_3.1/global_rep.1/pre_norm_ffn/pre_norm_ffn.4/MatMul_135";
  params_167->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_164, data_b_167, output_167, params_167);
  struct csinn_tensor *output_169 = csinn_alloc_tensor(sess);
  output_169->name = "output_169";
  output_169->dtype = CSINN_DTYPE_FLOAT16;
  output_169->layout = CSINN_LAYOUT_NCW;
  output_169->dim[0] = 4;
  output_169->dim[1] = 256;
  output_169->dim[2] = 144;
  output_169->dim_count = 3;
  memcpy(output_169->qinfo, params_base + 689776, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *rhs_169 = csinn_alloc_tensor(sess);
  rhs_169->name = "rhs_169";
  rhs_169->data = params_base + 689824;
  rhs_169->is_const = 1;
  rhs_169->dtype = CSINN_DTYPE_FLOAT16;
  rhs_169->layout = CSINN_LAYOUT_OIW;
  rhs_169->dim[0] = 1;
  rhs_169->dim[1] = 1;
  rhs_169->dim[2] = 144;
  rhs_169->dim_count = 3;
  memcpy(rhs_169->qinfo, params_base + 689800, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_169 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_169->base.name = "add_/layer_3/layer_3.1/global_rep.1/pre_norm_ffn/pre_norm_ffn.4/Add_137";
  params_169->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_167, rhs_169, output_169, params_169);
  struct csinn_tensor *output_171 = csinn_alloc_tensor(sess);
  output_171->name = "output_171";
  output_171->dtype = CSINN_DTYPE_FLOAT16;
  output_171->layout = CSINN_LAYOUT_NCW;
  output_171->dim[0] = 4;
  output_171->dim[1] = 256;
  output_171->dim[2] = 144;
  output_171->dim_count = 3;
  memcpy(output_171->qinfo, params_base + 690112, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_171 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_171->base.name = "add_/layer_3/layer_3.1/global_rep.1/Add_1_138";
  params_171->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_153, output_169, output_171, params_171);
  struct csinn_tensor *output_173 = csinn_alloc_tensor(sess);
  output_173->name = "output_173";
  output_173->dtype = CSINN_DTYPE_FLOAT16;
  output_173->layout = CSINN_LAYOUT_NCW;
  output_173->dim[0] = 4;
  output_173->dim[1] = 256;
  output_173->dim[2] = 144;
  output_173->dim_count = 3;
  memcpy(output_173->qinfo, params_base + 690136, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *gamma_173 = csinn_alloc_tensor(sess);
  gamma_173->name = "gamma_173";
  gamma_173->data = params_base + 690184;
  gamma_173->is_const = 1;
  gamma_173->dtype = CSINN_DTYPE_FLOAT16;
  gamma_173->layout = CSINN_LAYOUT_O;
  gamma_173->dim[0] = 144;
  gamma_173->dim_count = 1;
  memcpy(gamma_173->qinfo, params_base + 690160, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *beta_173 = csinn_alloc_tensor(sess);
  beta_173->name = "beta_173";
  beta_173->data = params_base + 690496;
  beta_173->is_const = 1;
  beta_173->dtype = CSINN_DTYPE_FLOAT16;
  beta_173->layout = CSINN_LAYOUT_O;
  beta_173->dim[0] = 144;
  beta_173->dim_count = 1;
  memcpy(beta_173->qinfo, params_base + 690472, sizeof(struct csinn_quant_info) * 1);
  struct csinn_layer_norm_params *params_173 = csinn_alloc_params(sizeof(struct csinn_layer_norm_params), sess);
  params_173->epsilon = 1e-05;
  params_173->axis = -1;
  params_173->center = true;
  params_173->scale = true;
  params_173->base.name = "layer_norm_139";
  params_173->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_layer_norm_init(output_171, output_173, gamma_173, beta_173, params_173);
  int32_t *shape_174 = malloc(4 * 4);
  shape_174[0] = 1;
  shape_174[1] = 4;
  shape_174[2] = 256;
  shape_174[3] = -1;
  struct csinn_tensor *output_174 = csinn_alloc_tensor(sess);
  output_174->name = "output_174";
  output_174->dtype = CSINN_DTYPE_FLOAT16;
  output_174->layout = CSINN_LAYOUT_NCHW;
  output_174->dim[0] = 1;
  output_174->dim[1] = 4;
  output_174->dim[2] = 256;
  output_174->dim[3] = 144;
  output_174->dim_count = 4;
  memcpy(output_174->qinfo, params_base + 690784, sizeof(struct csinn_quant_info) * 1);
  struct csinn_reshape_params *params_174 = csinn_alloc_params(sizeof(struct csinn_reshape_params), sess);
  params_174->shape = shape_174;
  params_174->shape_num = 4;
  params_174->base.name = "reshape_/layer_3/layer_3.1/Reshape_3_140";
  params_174->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_reshape_init(output_173, output_174, params_174);
  int32_t *permute_175 = malloc(4 * 4);
  permute_175[0] = 0;
  permute_175[1] = 3;
  permute_175[2] = 2;
  permute_175[3] = 1;
  struct csinn_tensor *output_175 = csinn_alloc_tensor(sess);
  output_175->name = "output_175";
  output_175->dtype = CSINN_DTYPE_FLOAT16;
  output_175->layout = CSINN_LAYOUT_NCHW;
  output_175->dim[0] = 1;
  output_175->dim[1] = 144;
  output_175->dim[2] = 256;
  output_175->dim[3] = 4;
  output_175->dim_count = 4;
  memcpy(output_175->qinfo, params_base + 690808, sizeof(struct csinn_quant_info) * 1);
  struct csinn_transpose_params *params_175 = csinn_alloc_params(sizeof(struct csinn_transpose_params), sess);
  params_175->permute = permute_175;
  params_175->permute_num = 4;
  params_175->base.name = "transpose_/layer_3/layer_3.1/Transpose_2_141";
  params_175->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_transpose_init(output_174, output_175, params_175);
  int32_t *shape_176 = malloc(4 * 4);
  shape_176[0] = 2304;
  shape_176[1] = 16;
  shape_176[2] = 2;
  shape_176[3] = 2;
  struct csinn_tensor *output_176 = csinn_alloc_tensor(sess);
  output_176->name = "output_176";
  output_176->dtype = CSINN_DTYPE_FLOAT16;
  output_176->layout = CSINN_LAYOUT_NCHW;
  output_176->dim[0] = 2304;
  output_176->dim[1] = 16;
  output_176->dim[2] = 2;
  output_176->dim[3] = 2;
  output_176->dim_count = 4;
  memcpy(output_176->qinfo, params_base + 690832, sizeof(struct csinn_quant_info) * 1);
  struct csinn_reshape_params *params_176 = csinn_alloc_params(sizeof(struct csinn_reshape_params), sess);
  params_176->shape = shape_176;
  params_176->shape_num = 4;
  params_176->base.name = "reshape_/layer_3/layer_3.1/Reshape_4_142";
  params_176->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_reshape_init(output_175, output_176, params_176);
  int32_t *permute_177 = malloc(4 * 4);
  permute_177[0] = 0;
  permute_177[1] = 2;
  permute_177[2] = 1;
  permute_177[3] = 3;
  struct csinn_tensor *output_177 = csinn_alloc_tensor(sess);
  output_177->name = "output_177";
  output_177->dtype = CSINN_DTYPE_FLOAT16;
  output_177->layout = CSINN_LAYOUT_NCHW;
  output_177->dim[0] = 2304;
  output_177->dim[1] = 2;
  output_177->dim[2] = 16;
  output_177->dim[3] = 2;
  output_177->dim_count = 4;
  memcpy(output_177->qinfo, params_base + 690856, sizeof(struct csinn_quant_info) * 1);
  struct csinn_transpose_params *params_177 = csinn_alloc_params(sizeof(struct csinn_transpose_params), sess);
  params_177->permute = permute_177;
  params_177->permute_num = 4;
  params_177->base.name = "transpose_/layer_3/layer_3.1/Transpose_3_143";
  params_177->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_transpose_init(output_176, output_177, params_177);
  int32_t *shape_178 = malloc(4 * 4);
  shape_178[0] = 1;
  shape_178[1] = 144;
  shape_178[2] = 32;
  shape_178[3] = 32;
  struct csinn_tensor *output_178 = csinn_alloc_tensor(sess);
  output_178->name = "output_178";
  output_178->dtype = CSINN_DTYPE_FLOAT16;
  output_178->layout = CSINN_LAYOUT_NCHW;
  output_178->dim[0] = 1;
  output_178->dim[1] = 144;
  output_178->dim[2] = 32;
  output_178->dim[3] = 32;
  output_178->dim_count = 4;
  memcpy(output_178->qinfo, params_base + 690880, sizeof(struct csinn_quant_info) * 1);
  struct csinn_reshape_params *params_178 = csinn_alloc_params(sizeof(struct csinn_reshape_params), sess);
  params_178->shape = shape_178;
  params_178->shape_num = 4;
  params_178->base.name = "reshape_/layer_3/layer_3.1/Reshape_5_144";
  params_178->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_reshape_init(output_177, output_178, params_178);
  struct csinn_tensor *output_179 = csinn_alloc_tensor(sess);
  output_179->name = "output_179";
  output_179->dtype = CSINN_DTYPE_FLOAT16;
  output_179->layout = CSINN_LAYOUT_NCHW;
  output_179->dim[0] = 1;
  output_179->dim[1] = 96;
  output_179->dim[2] = 32;
  output_179->dim[3] = 32;
  output_179->dim_count = 4;
  memcpy(output_179->qinfo, params_base + 690904, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_179 = csinn_alloc_tensor(sess);
  kernel_179->name = "kernel_179";
  kernel_179->data = params_base + 693232;
  kernel_179->is_const = 1;
  kernel_179->dtype = CSINN_DTYPE_INT8;
  kernel_179->layout = CSINN_LAYOUT_OIHW;
  kernel_179->dim[0] = 96;
  kernel_179->dim[1] = 144;
  kernel_179->dim[2] = 1;
  kernel_179->dim[3] = 1;
  kernel_179->dim_count = 4;
  csinn_realloc_quant_info(kernel_179, 96);
  memcpy(kernel_179->qinfo, params_base + 690928, sizeof(struct csinn_quant_info) * 96);
  struct csinn_tensor *bias_179 = csinn_alloc_tensor(sess);
  bias_179->name = "bias_179";
  bias_179->data = params_base + 709360;
  bias_179->is_const = 1;
  bias_179->dtype = CSINN_DTYPE_FLOAT16;
  bias_179->layout = CSINN_LAYOUT_O;
  bias_179->dim[0] = 96;
  bias_179->dim_count = 1;
  csinn_realloc_quant_info(bias_179, 96);
  memcpy(bias_179->qinfo, params_base + 707056, sizeof(struct csinn_quant_info) * 96);
  struct csinn_conv2d_params *params_179 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_179->group = 1;
  params_179->stride_height = 1;
  params_179->stride_width = 1;
  params_179->dilation_height = 1;
  params_179->dilation_width = 1;
  params_179->conv_extra.kernel_tm = NULL;
  params_179->conv_extra.conv_mode = CSINN_DIRECT;
  params_179->pad_top = 0;
  params_179->pad_left = 0;
  params_179->pad_down = 0;
  params_179->pad_right = 0;
  params_179->base.name = "conv2d_/layer_3/layer_3.1/conv_proj/block/conv/Conv_145_fuse_bias_add_/layer_3/layer_3.1/conv_proj/block/conv/Conv_146";
  params_179->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_178, output_179, kernel_179, bias_179, params_179);
  struct csinn_tensor *output_181 = csinn_alloc_tensor(sess);
  output_181->name = "output_181";
  output_181->dtype = CSINN_DTYPE_FLOAT16;
  output_181->layout = CSINN_LAYOUT_NCHW;
  output_181->dim[0] = 1;
  output_181->dim[1] = 96;
  output_181->dim[2] = 32;
  output_181->dim[3] = 32;
  output_181->dim_count = 4;
  memcpy(output_181->qinfo, params_base + 709552, sizeof(struct csinn_quant_info) * 1);
  struct csinn_sigmoid_params *params_181 = csinn_alloc_params(sizeof(struct csinn_sigmoid_params), sess);
  params_181->base.name = "sigmoid_/layer_3/layer_3.1/conv_proj/block/act/Sigmoid_147";
  params_181->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_sigmoid_init(output_179, output_181, params_181);
  struct csinn_tensor *output_182 = csinn_alloc_tensor(sess);
  output_182->name = "output_182";
  output_182->dtype = CSINN_DTYPE_FLOAT16;
  output_182->layout = CSINN_LAYOUT_NCHW;
  output_182->dim[0] = 1;
  output_182->dim[1] = 96;
  output_182->dim[2] = 32;
  output_182->dim[3] = 32;
  output_182->dim_count = 4;
  memcpy(output_182->qinfo, params_base + 709576, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_182 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_182->base.name = "multiply_/layer_3/layer_3.1/conv_proj/block/act/Mul_148";
  params_182->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_mul_init(output_179, output_181, output_182, params_182);
  struct csinn_tensor *input_184_concat[2];
  struct csinn_tensor *output_184 = csinn_alloc_tensor(sess);
  output_184->name = "output_184";
  output_184->dtype = CSINN_DTYPE_FLOAT16;
  output_184->layout = CSINN_LAYOUT_NCHW;
  output_184->dim[0] = 1;
  output_184->dim[1] = 192;
  output_184->dim[2] = 32;
  output_184->dim[3] = 32;
  output_184->dim_count = 4;
  memcpy(output_184->qinfo, params_base + 709600, sizeof(struct csinn_quant_info) * 1);
  struct csinn_concat_params *params_184 = csinn_alloc_params(sizeof(struct csinn_concat_params), sess);
  params_184->inputs_count = 2;
  params_184->axis = 1;
  params_184->base.name = "concatenate_/layer_3/layer_3.1/Concat_149";
  params_184->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_concat_init(input_184_concat, output_184, params_184);
  struct csinn_tensor *output_185 = csinn_alloc_tensor(sess);
  output_185->name = "output_185";
  output_185->dtype = CSINN_DTYPE_FLOAT16;
  output_185->layout = CSINN_LAYOUT_NCHW;
  output_185->dim[0] = 1;
  output_185->dim[1] = 96;
  output_185->dim[2] = 32;
  output_185->dim[3] = 32;
  output_185->dim_count = 4;
  memcpy(output_185->qinfo, params_base + 709624, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_185 = csinn_alloc_tensor(sess);
  kernel_185->name = "kernel_185";
  kernel_185->data = params_base + 711952;
  kernel_185->is_const = 1;
  kernel_185->dtype = CSINN_DTYPE_INT8;
  kernel_185->layout = CSINN_LAYOUT_OIHW;
  kernel_185->dim[0] = 96;
  kernel_185->dim[1] = 192;
  kernel_185->dim[2] = 3;
  kernel_185->dim[3] = 3;
  kernel_185->dim_count = 4;
  csinn_realloc_quant_info(kernel_185, 96);
  memcpy(kernel_185->qinfo, params_base + 709648, sizeof(struct csinn_quant_info) * 96);
  struct csinn_tensor *bias_185 = csinn_alloc_tensor(sess);
  bias_185->name = "bias_185";
  bias_185->data = params_base + 880144;
  bias_185->is_const = 1;
  bias_185->dtype = CSINN_DTYPE_FLOAT16;
  bias_185->layout = CSINN_LAYOUT_O;
  bias_185->dim[0] = 96;
  bias_185->dim_count = 1;
  csinn_realloc_quant_info(bias_185, 96);
  memcpy(bias_185->qinfo, params_base + 877840, sizeof(struct csinn_quant_info) * 96);
  struct csinn_conv2d_params *params_185 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_185->group = 1;
  params_185->stride_height = 1;
  params_185->stride_width = 1;
  params_185->dilation_height = 1;
  params_185->dilation_width = 1;
  params_185->conv_extra.kernel_tm = NULL;
  params_185->conv_extra.conv_mode = CSINN_DIRECT;
  params_185->pad_top = 1;
  params_185->pad_left = 1;
  params_185->pad_down = 1;
  params_185->pad_right = 1;
  params_185->base.name = "conv2d_/layer_3/layer_3.1/fusion/block/conv/Conv_150_fuse_bias_add_/layer_3/layer_3.1/fusion/block/conv/Conv_151";
  params_185->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_184, output_185, kernel_185, bias_185, params_185);
  struct csinn_tensor *output_187 = csinn_alloc_tensor(sess);
  output_187->name = "output_187";
  output_187->dtype = CSINN_DTYPE_FLOAT16;
  output_187->layout = CSINN_LAYOUT_NCHW;
  output_187->dim[0] = 1;
  output_187->dim[1] = 96;
  output_187->dim[2] = 32;
  output_187->dim[3] = 32;
  output_187->dim_count = 4;
  memcpy(output_187->qinfo, params_base + 880336, sizeof(struct csinn_quant_info) * 1);
  struct csinn_sigmoid_params *params_187 = csinn_alloc_params(sizeof(struct csinn_sigmoid_params), sess);
  params_187->base.name = "sigmoid_/layer_3/layer_3.1/fusion/block/act/Sigmoid_152";
  params_187->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_sigmoid_init(output_185, output_187, params_187);
  struct csinn_tensor *output_188 = csinn_alloc_tensor(sess);
  output_188->name = "output_188";
  output_188->dtype = CSINN_DTYPE_FLOAT16;
  output_188->layout = CSINN_LAYOUT_NCHW;
  output_188->dim[0] = 1;
  output_188->dim[1] = 96;
  output_188->dim[2] = 32;
  output_188->dim[3] = 32;
  output_188->dim_count = 4;
  memcpy(output_188->qinfo, params_base + 880360, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_188 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_188->base.name = "multiply_/layer_3/layer_3.1/fusion/block/act/Mul_153";
  params_188->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_mul_init(output_185, output_187, output_188, params_188);
  struct csinn_tensor *output_190 = csinn_alloc_tensor(sess);
  output_190->name = "output_190";
  output_190->dtype = CSINN_DTYPE_FLOAT16;
  output_190->layout = CSINN_LAYOUT_NCHW;
  output_190->dim[0] = 1;
  output_190->dim[1] = 384;
  output_190->dim[2] = 32;
  output_190->dim[3] = 32;
  output_190->dim_count = 4;
  memcpy(output_190->qinfo, params_base + 880384, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_190 = csinn_alloc_tensor(sess);
  kernel_190->name = "kernel_190";
  kernel_190->data = params_base + 889624;
  kernel_190->is_const = 1;
  kernel_190->dtype = CSINN_DTYPE_INT8;
  kernel_190->layout = CSINN_LAYOUT_OIHW;
  kernel_190->dim[0] = 384;
  kernel_190->dim[1] = 96;
  kernel_190->dim[2] = 1;
  kernel_190->dim[3] = 1;
  kernel_190->dim_count = 4;
  csinn_realloc_quant_info(kernel_190, 384);
  memcpy(kernel_190->qinfo, params_base + 880408, sizeof(struct csinn_quant_info) * 384);
  struct csinn_tensor *bias_190 = csinn_alloc_tensor(sess);
  bias_190->name = "bias_190";
  bias_190->data = params_base + 935704;
  bias_190->is_const = 1;
  bias_190->dtype = CSINN_DTYPE_FLOAT16;
  bias_190->layout = CSINN_LAYOUT_O;
  bias_190->dim[0] = 384;
  bias_190->dim_count = 1;
  csinn_realloc_quant_info(bias_190, 384);
  memcpy(bias_190->qinfo, params_base + 926488, sizeof(struct csinn_quant_info) * 384);
  struct csinn_conv2d_params *params_190 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_190->group = 1;
  params_190->stride_height = 1;
  params_190->stride_width = 1;
  params_190->dilation_height = 1;
  params_190->dilation_width = 1;
  params_190->conv_extra.kernel_tm = NULL;
  params_190->conv_extra.conv_mode = CSINN_DIRECT;
  params_190->pad_top = 0;
  params_190->pad_left = 0;
  params_190->pad_down = 0;
  params_190->pad_right = 0;
  params_190->base.name = "conv2d_/layer_4/layer_4.0/block/exp_1x1/block/conv/Conv_154_fuse_bias_add_/layer_4/layer_4.0/block/exp_1x1/block/conv/Conv_155";
  params_190->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_188, output_190, kernel_190, bias_190, params_190);
  struct csinn_tensor *output_192 = csinn_alloc_tensor(sess);
  output_192->name = "output_192";
  output_192->dtype = CSINN_DTYPE_FLOAT16;
  output_192->layout = CSINN_LAYOUT_NCHW;
  output_192->dim[0] = 1;
  output_192->dim[1] = 384;
  output_192->dim[2] = 32;
  output_192->dim[3] = 32;
  output_192->dim_count = 4;
  memcpy(output_192->qinfo, params_base + 936472, sizeof(struct csinn_quant_info) * 1);
  struct csinn_sigmoid_params *params_192 = csinn_alloc_params(sizeof(struct csinn_sigmoid_params), sess);
  params_192->base.name = "sigmoid_/layer_4/layer_4.0/block/exp_1x1/block/act/Sigmoid_156";
  params_192->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_sigmoid_init(output_190, output_192, params_192);
  struct csinn_tensor *output_193 = csinn_alloc_tensor(sess);
  output_193->name = "output_193";
  output_193->dtype = CSINN_DTYPE_FLOAT16;
  output_193->layout = CSINN_LAYOUT_NCHW;
  output_193->dim[0] = 1;
  output_193->dim[1] = 384;
  output_193->dim[2] = 32;
  output_193->dim[3] = 32;
  output_193->dim_count = 4;
  memcpy(output_193->qinfo, params_base + 936496, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_193 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_193->base.name = "multiply_/layer_4/layer_4.0/block/exp_1x1/block/act/Mul_157";
  params_193->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_mul_init(output_190, output_192, output_193, params_193);
  struct csinn_tensor *output_195 = csinn_alloc_tensor(sess);
  output_195->name = "output_195";
  output_195->dtype = CSINN_DTYPE_FLOAT16;
  output_195->layout = CSINN_LAYOUT_NCHW;
  output_195->dim[0] = 1;
  output_195->dim[1] = 384;
  output_195->dim[2] = 16;
  output_195->dim[3] = 16;
  output_195->dim_count = 4;
  memcpy(output_195->qinfo, params_base + 936520, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_195 = csinn_alloc_tensor(sess);
  kernel_195->name = "kernel_195";
  kernel_195->data = params_base + 945760;
  kernel_195->is_const = 1;
  kernel_195->dtype = CSINN_DTYPE_INT8;
  kernel_195->layout = CSINN_LAYOUT_OIHW;
  kernel_195->dim[0] = 384;
  kernel_195->dim[1] = 1;
  kernel_195->dim[2] = 3;
  kernel_195->dim[3] = 3;
  kernel_195->dim_count = 4;
  csinn_realloc_quant_info(kernel_195, 384);
  memcpy(kernel_195->qinfo, params_base + 936544, sizeof(struct csinn_quant_info) * 384);
  struct csinn_tensor *bias_195 = csinn_alloc_tensor(sess);
  bias_195->name = "bias_195";
  bias_195->data = params_base + 958432;
  bias_195->is_const = 1;
  bias_195->dtype = CSINN_DTYPE_FLOAT16;
  bias_195->layout = CSINN_LAYOUT_O;
  bias_195->dim[0] = 384;
  bias_195->dim_count = 1;
  csinn_realloc_quant_info(bias_195, 384);
  memcpy(bias_195->qinfo, params_base + 949216, sizeof(struct csinn_quant_info) * 384);
  struct csinn_conv2d_params *params_195 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_195->group = 384;
  params_195->stride_height = 2;
  params_195->stride_width = 2;
  params_195->dilation_height = 1;
  params_195->dilation_width = 1;
  params_195->conv_extra.kernel_tm = NULL;
  params_195->conv_extra.conv_mode = CSINN_DIRECT;
  params_195->pad_top = 1;
  params_195->pad_left = 1;
  params_195->pad_down = 1;
  params_195->pad_right = 1;
  params_195->base.name = "conv2d_/layer_4/layer_4.0/block/conv_3x3/block/conv/Conv_158_fuse_bias_add_/layer_4/layer_4.0/block/conv_3x3/block/conv/Conv_159";
  params_195->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_193, output_195, kernel_195, bias_195, params_195);
  struct csinn_tensor *output_197 = csinn_alloc_tensor(sess);
  output_197->name = "output_197";
  output_197->dtype = CSINN_DTYPE_FLOAT16;
  output_197->layout = CSINN_LAYOUT_NCHW;
  output_197->dim[0] = 1;
  output_197->dim[1] = 384;
  output_197->dim[2] = 16;
  output_197->dim[3] = 16;
  output_197->dim_count = 4;
  memcpy(output_197->qinfo, params_base + 959200, sizeof(struct csinn_quant_info) * 1);
  struct csinn_sigmoid_params *params_197 = csinn_alloc_params(sizeof(struct csinn_sigmoid_params), sess);
  params_197->base.name = "sigmoid_/layer_4/layer_4.0/block/conv_3x3/block/act/Sigmoid_160";
  params_197->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_sigmoid_init(output_195, output_197, params_197);
  struct csinn_tensor *output_198 = csinn_alloc_tensor(sess);
  output_198->name = "output_198";
  output_198->dtype = CSINN_DTYPE_FLOAT16;
  output_198->layout = CSINN_LAYOUT_NCHW;
  output_198->dim[0] = 1;
  output_198->dim[1] = 384;
  output_198->dim[2] = 16;
  output_198->dim[3] = 16;
  output_198->dim_count = 4;
  memcpy(output_198->qinfo, params_base + 959224, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_198 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_198->base.name = "multiply_/layer_4/layer_4.0/block/conv_3x3/block/act/Mul_161";
  params_198->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_mul_init(output_195, output_197, output_198, params_198);
  struct csinn_tensor *output_200 = csinn_alloc_tensor(sess);
  output_200->name = "output_200";
  output_200->dtype = CSINN_DTYPE_FLOAT16;
  output_200->layout = CSINN_LAYOUT_NCHW;
  output_200->dim[0] = 1;
  output_200->dim[1] = 128;
  output_200->dim[2] = 16;
  output_200->dim[3] = 16;
  output_200->dim_count = 4;
  memcpy(output_200->qinfo, params_base + 959248, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_200 = csinn_alloc_tensor(sess);
  kernel_200->name = "kernel_200";
  kernel_200->data = params_base + 962344;
  kernel_200->is_const = 1;
  kernel_200->dtype = CSINN_DTYPE_INT8;
  kernel_200->layout = CSINN_LAYOUT_OIHW;
  kernel_200->dim[0] = 128;
  kernel_200->dim[1] = 384;
  kernel_200->dim[2] = 1;
  kernel_200->dim[3] = 1;
  kernel_200->dim_count = 4;
  csinn_realloc_quant_info(kernel_200, 128);
  memcpy(kernel_200->qinfo, params_base + 959272, sizeof(struct csinn_quant_info) * 128);
  struct csinn_tensor *bias_200 = csinn_alloc_tensor(sess);
  bias_200->name = "bias_200";
  bias_200->data = params_base + 1014568;
  bias_200->is_const = 1;
  bias_200->dtype = CSINN_DTYPE_FLOAT16;
  bias_200->layout = CSINN_LAYOUT_O;
  bias_200->dim[0] = 128;
  bias_200->dim_count = 1;
  csinn_realloc_quant_info(bias_200, 128);
  memcpy(bias_200->qinfo, params_base + 1011496, sizeof(struct csinn_quant_info) * 128);
  struct csinn_conv2d_params *params_200 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_200->group = 1;
  params_200->stride_height = 1;
  params_200->stride_width = 1;
  params_200->dilation_height = 1;
  params_200->dilation_width = 1;
  params_200->conv_extra.kernel_tm = NULL;
  params_200->conv_extra.conv_mode = CSINN_DIRECT;
  params_200->pad_top = 0;
  params_200->pad_left = 0;
  params_200->pad_down = 0;
  params_200->pad_right = 0;
  params_200->base.name = "conv2d_/layer_4/layer_4.0/block/red_1x1/block/conv/Conv_162_fuse_bias_add_/layer_4/layer_4.0/block/red_1x1/block/conv/Conv_163";
  params_200->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_198, output_200, kernel_200, bias_200, params_200);
  struct csinn_tensor *output_201 = csinn_alloc_tensor(sess);
  output_201->name = "output_201";
  output_201->dtype = CSINN_DTYPE_FLOAT16;
  output_201->layout = CSINN_LAYOUT_NCHW;
  output_201->dim[0] = 1;
  output_201->dim[1] = 128;
  output_201->dim[2] = 16;
  output_201->dim[3] = 16;
  output_201->dim_count = 4;
  memcpy(output_201->qinfo, params_base + 1014824, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_201 = csinn_alloc_tensor(sess);
  kernel_201->name = "kernel_201";
  kernel_201->data = params_base + 1017920;
  kernel_201->is_const = 1;
  kernel_201->dtype = CSINN_DTYPE_INT8;
  kernel_201->layout = CSINN_LAYOUT_OIHW;
  kernel_201->dim[0] = 128;
  kernel_201->dim[1] = 128;
  kernel_201->dim[2] = 3;
  kernel_201->dim[3] = 3;
  kernel_201->dim_count = 4;
  csinn_realloc_quant_info(kernel_201, 128);
  memcpy(kernel_201->qinfo, params_base + 1014848, sizeof(struct csinn_quant_info) * 128);
  struct csinn_tensor *bias_201 = csinn_alloc_tensor(sess);
  bias_201->name = "bias_201";
  bias_201->data = params_base + 1168448;
  bias_201->is_const = 1;
  bias_201->dtype = CSINN_DTYPE_FLOAT16;
  bias_201->layout = CSINN_LAYOUT_O;
  bias_201->dim[0] = 128;
  bias_201->dim_count = 1;
  csinn_realloc_quant_info(bias_201, 128);
  memcpy(bias_201->qinfo, params_base + 1165376, sizeof(struct csinn_quant_info) * 128);
  struct csinn_conv2d_params *params_201 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_201->group = 1;
  params_201->stride_height = 1;
  params_201->stride_width = 1;
  params_201->dilation_height = 1;
  params_201->dilation_width = 1;
  params_201->conv_extra.kernel_tm = NULL;
  params_201->conv_extra.conv_mode = CSINN_DIRECT;
  params_201->pad_top = 1;
  params_201->pad_left = 1;
  params_201->pad_down = 1;
  params_201->pad_right = 1;
  params_201->base.name = "conv2d_/layer_4/layer_4.1/local_rep/conv_3x3/block/conv/Conv_164_fuse_bias_add_/layer_4/layer_4.1/local_rep/conv_3x3/block/conv/Conv_165";
  params_201->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_200, output_201, kernel_201, bias_201, params_201);
  struct csinn_tensor *output_203 = csinn_alloc_tensor(sess);
  output_203->name = "output_203";
  output_203->dtype = CSINN_DTYPE_FLOAT16;
  output_203->layout = CSINN_LAYOUT_NCHW;
  output_203->dim[0] = 1;
  output_203->dim[1] = 128;
  output_203->dim[2] = 16;
  output_203->dim[3] = 16;
  output_203->dim_count = 4;
  memcpy(output_203->qinfo, params_base + 1168704, sizeof(struct csinn_quant_info) * 1);
  struct csinn_sigmoid_params *params_203 = csinn_alloc_params(sizeof(struct csinn_sigmoid_params), sess);
  params_203->base.name = "sigmoid_/layer_4/layer_4.1/local_rep/conv_3x3/block/act/Sigmoid_166";
  params_203->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_sigmoid_init(output_201, output_203, params_203);
  struct csinn_tensor *output_204 = csinn_alloc_tensor(sess);
  output_204->name = "output_204";
  output_204->dtype = CSINN_DTYPE_FLOAT16;
  output_204->layout = CSINN_LAYOUT_NCHW;
  output_204->dim[0] = 1;
  output_204->dim[1] = 128;
  output_204->dim[2] = 16;
  output_204->dim[3] = 16;
  output_204->dim_count = 4;
  memcpy(output_204->qinfo, params_base + 1168728, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_204 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_204->base.name = "multiply_/layer_4/layer_4.1/local_rep/conv_3x3/block/act/Mul_167";
  params_204->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_mul_init(output_201, output_203, output_204, params_204);
  struct csinn_tensor *bias_206 = csinn_alloc_tensor(sess);
  bias_206->data = NULL;
  bias_206->name = "bias_206";
  bias_206->is_const = 1;
  bias_206->dim_count = 0;
  struct csinn_tensor *output_206 = csinn_alloc_tensor(sess);
  output_206->name = "output_206";
  output_206->dtype = CSINN_DTYPE_FLOAT16;
  output_206->layout = CSINN_LAYOUT_NCHW;
  output_206->dim[0] = 1;
  output_206->dim[1] = 192;
  output_206->dim[2] = 16;
  output_206->dim[3] = 16;
  output_206->dim_count = 4;
  memcpy(output_206->qinfo, params_base + 1168752, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_206 = csinn_alloc_tensor(sess);
  kernel_206->name = "kernel_206";
  kernel_206->data = params_base + 1173384;
  kernel_206->is_const = 1;
  kernel_206->dtype = CSINN_DTYPE_INT8;
  kernel_206->layout = CSINN_LAYOUT_OIHW;
  kernel_206->dim[0] = 192;
  kernel_206->dim[1] = 128;
  kernel_206->dim[2] = 1;
  kernel_206->dim[3] = 1;
  kernel_206->dim_count = 4;
  csinn_realloc_quant_info(kernel_206, 192);
  memcpy(kernel_206->qinfo, params_base + 1168776, sizeof(struct csinn_quant_info) * 192);
  struct csinn_conv2d_params *params_206 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_206->group = 1;
  params_206->stride_height = 1;
  params_206->stride_width = 1;
  params_206->dilation_height = 1;
  params_206->dilation_width = 1;
  params_206->conv_extra.kernel_tm = NULL;
  params_206->conv_extra.conv_mode = CSINN_DIRECT;
  params_206->pad_top = 0;
  params_206->pad_left = 0;
  params_206->pad_down = 0;
  params_206->pad_right = 0;
  params_206->base.name = "conv2d_/layer_4/layer_4.1/local_rep/conv_1x1/block/conv/Conv_168";
  params_206->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_204, output_206, kernel_206, bias_206, params_206);
  int32_t *shape_207 = malloc(4 * 4);
  shape_207[0] = 1536;
  shape_207[1] = 2;
  shape_207[2] = 8;
  shape_207[3] = 2;
  struct csinn_tensor *output_207 = csinn_alloc_tensor(sess);
  output_207->name = "output_207";
  output_207->dtype = CSINN_DTYPE_FLOAT16;
  output_207->layout = CSINN_LAYOUT_NCHW;
  output_207->dim[0] = 1536;
  output_207->dim[1] = 2;
  output_207->dim[2] = 8;
  output_207->dim[3] = 2;
  output_207->dim_count = 4;
  memcpy(output_207->qinfo, params_base + 1197960, sizeof(struct csinn_quant_info) * 1);
  struct csinn_reshape_params *params_207 = csinn_alloc_params(sizeof(struct csinn_reshape_params), sess);
  params_207->shape = shape_207;
  params_207->shape_num = 4;
  params_207->base.name = "reshape_/layer_4/layer_4.1/Reshape_169";
  params_207->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_reshape_init(output_206, output_207, params_207);
  int32_t *permute_208 = malloc(4 * 4);
  permute_208[0] = 0;
  permute_208[1] = 2;
  permute_208[2] = 1;
  permute_208[3] = 3;
  struct csinn_tensor *output_208 = csinn_alloc_tensor(sess);
  output_208->name = "output_208";
  output_208->dtype = CSINN_DTYPE_FLOAT16;
  output_208->layout = CSINN_LAYOUT_NCHW;
  output_208->dim[0] = 1536;
  output_208->dim[1] = 8;
  output_208->dim[2] = 2;
  output_208->dim[3] = 2;
  output_208->dim_count = 4;
  memcpy(output_208->qinfo, params_base + 1197984, sizeof(struct csinn_quant_info) * 1);
  struct csinn_transpose_params *params_208 = csinn_alloc_params(sizeof(struct csinn_transpose_params), sess);
  params_208->permute = permute_208;
  params_208->permute_num = 4;
  params_208->base.name = "transpose_/layer_4/layer_4.1/Transpose_170";
  params_208->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_transpose_init(output_207, output_208, params_208);
  int32_t *shape_209 = malloc(4 * 4);
  shape_209[0] = 1;
  shape_209[1] = 192;
  shape_209[2] = 64;
  shape_209[3] = 4;
  struct csinn_tensor *output_209 = csinn_alloc_tensor(sess);
  output_209->name = "output_209";
  output_209->dtype = CSINN_DTYPE_FLOAT16;
  output_209->layout = CSINN_LAYOUT_NCHW;
  output_209->dim[0] = 1;
  output_209->dim[1] = 192;
  output_209->dim[2] = 64;
  output_209->dim[3] = 4;
  output_209->dim_count = 4;
  memcpy(output_209->qinfo, params_base + 1198008, sizeof(struct csinn_quant_info) * 1);
  struct csinn_reshape_params *params_209 = csinn_alloc_params(sizeof(struct csinn_reshape_params), sess);
  params_209->shape = shape_209;
  params_209->shape_num = 4;
  params_209->base.name = "reshape_/layer_4/layer_4.1/Reshape_1_171";
  params_209->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_reshape_init(output_208, output_209, params_209);
  int32_t *permute_210 = malloc(4 * 4);
  permute_210[0] = 0;
  permute_210[1] = 3;
  permute_210[2] = 2;
  permute_210[3] = 1;
  struct csinn_tensor *output_210 = csinn_alloc_tensor(sess);
  output_210->name = "output_210";
  output_210->dtype = CSINN_DTYPE_FLOAT16;
  output_210->layout = CSINN_LAYOUT_NCHW;
  output_210->dim[0] = 1;
  output_210->dim[1] = 4;
  output_210->dim[2] = 64;
  output_210->dim[3] = 192;
  output_210->dim_count = 4;
  memcpy(output_210->qinfo, params_base + 1198032, sizeof(struct csinn_quant_info) * 1);
  struct csinn_transpose_params *params_210 = csinn_alloc_params(sizeof(struct csinn_transpose_params), sess);
  params_210->permute = permute_210;
  params_210->permute_num = 4;
  params_210->base.name = "transpose_/layer_4/layer_4.1/Transpose_1_172";
  params_210->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_transpose_init(output_209, output_210, params_210);
  int32_t *shape_211 = malloc(3 * 4);
  shape_211[0] = 4;
  shape_211[1] = 64;
  shape_211[2] = -1;
  struct csinn_tensor *output_211 = csinn_alloc_tensor(sess);
  output_211->name = "output_211";
  output_211->dtype = CSINN_DTYPE_FLOAT16;
  output_211->layout = CSINN_LAYOUT_NCW;
  output_211->dim[0] = 4;
  output_211->dim[1] = 64;
  output_211->dim[2] = 192;
  output_211->dim_count = 3;
  memcpy(output_211->qinfo, params_base + 1198056, sizeof(struct csinn_quant_info) * 1);
  struct csinn_reshape_params *params_211 = csinn_alloc_params(sizeof(struct csinn_reshape_params), sess);
  params_211->shape = shape_211;
  params_211->shape_num = 3;
  params_211->base.name = "reshape_/layer_4/layer_4.1/Reshape_2_173";
  params_211->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_reshape_init(output_210, output_211, params_211);
  struct csinn_tensor *output_212 = csinn_alloc_tensor(sess);
  output_212->name = "output_212";
  output_212->dtype = CSINN_DTYPE_FLOAT16;
  output_212->layout = CSINN_LAYOUT_NCW;
  output_212->dim[0] = 4;
  output_212->dim[1] = 64;
  output_212->dim[2] = 192;
  output_212->dim_count = 3;
  memcpy(output_212->qinfo, params_base + 1198080, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *gamma_212 = csinn_alloc_tensor(sess);
  gamma_212->name = "gamma_212";
  gamma_212->data = params_base + 1198128;
  gamma_212->is_const = 1;
  gamma_212->dtype = CSINN_DTYPE_FLOAT16;
  gamma_212->layout = CSINN_LAYOUT_O;
  gamma_212->dim[0] = 192;
  gamma_212->dim_count = 1;
  memcpy(gamma_212->qinfo, params_base + 1198104, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *beta_212 = csinn_alloc_tensor(sess);
  beta_212->name = "beta_212";
  beta_212->data = params_base + 1198536;
  beta_212->is_const = 1;
  beta_212->dtype = CSINN_DTYPE_FLOAT16;
  beta_212->layout = CSINN_LAYOUT_O;
  beta_212->dim[0] = 192;
  beta_212->dim_count = 1;
  memcpy(beta_212->qinfo, params_base + 1198512, sizeof(struct csinn_quant_info) * 1);
  struct csinn_layer_norm_params *params_212 = csinn_alloc_params(sizeof(struct csinn_layer_norm_params), sess);
  params_212->epsilon = 1e-05;
  params_212->axis = -1;
  params_212->center = true;
  params_212->scale = true;
  params_212->base.name = "layer_norm_174";
  params_212->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_layer_norm_init(output_211, output_212, gamma_212, beta_212, params_212);
  struct csinn_tensor *output_214 = csinn_alloc_tensor(sess);
  output_214->name = "output_214";
  output_214->dtype = CSINN_DTYPE_FLOAT16;
  output_214->layout = CSINN_LAYOUT_NCW;
  output_214->dim[0] = 4;
  output_214->dim[1] = 64;
  output_214->dim[2] = 576;
  output_214->dim_count = 3;
  memcpy(output_214->qinfo, params_base + 1198920, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *data_b_214 = csinn_alloc_tensor(sess);
  data_b_214->name = "data_b_214";
  data_b_214->data = params_base + 1198968;
  data_b_214->is_const = 1;
  data_b_214->dtype = CSINN_DTYPE_INT8;
  data_b_214->layout = CSINN_LAYOUT_OIW;
  data_b_214->dim[0] = 1;
  data_b_214->dim[1] = 192;
  data_b_214->dim[2] = 576;
  data_b_214->dim_count = 3;
  memcpy(data_b_214->qinfo, params_base + 1198944, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_214 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_214->trans_a = false;
  params_214->trans_b = false;
  params_214->base.name = "batch_matmul_/layer_4/layer_4.1/global_rep.0/pre_norm_mha.1/qkv_proj/MatMul_175";
  params_214->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_212, data_b_214, output_214, params_214);
  struct csinn_tensor *output_216 = csinn_alloc_tensor(sess);
  output_216->name = "output_216";
  output_216->dtype = CSINN_DTYPE_FLOAT16;
  output_216->layout = CSINN_LAYOUT_NCW;
  output_216->dim[0] = 4;
  output_216->dim[1] = 64;
  output_216->dim[2] = 576;
  output_216->dim_count = 3;
  memcpy(output_216->qinfo, params_base + 1309560, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *rhs_216 = csinn_alloc_tensor(sess);
  rhs_216->name = "rhs_216";
  rhs_216->data = params_base + 1309608;
  rhs_216->is_const = 1;
  rhs_216->dtype = CSINN_DTYPE_FLOAT16;
  rhs_216->layout = CSINN_LAYOUT_OIW;
  rhs_216->dim[0] = 1;
  rhs_216->dim[1] = 1;
  rhs_216->dim[2] = 576;
  rhs_216->dim_count = 3;
  memcpy(rhs_216->qinfo, params_base + 1309584, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_216 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_216->base.name = "add_/layer_4/layer_4.1/global_rep.0/pre_norm_mha.1/qkv_proj/Add_177";
  params_216->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_214, rhs_216, output_216, params_216);
  int32_t *shape_218 = malloc(5 * 4);
  shape_218[0] = 4;
  shape_218[1] = 64;
  shape_218[2] = 3;
  shape_218[3] = 4;
  shape_218[4] = -1;
  struct csinn_tensor *output_218 = csinn_alloc_tensor(sess);
  output_218->name = "output_218";
  output_218->dtype = CSINN_DTYPE_FLOAT16;
  output_218->layout = CSINN_LAYOUT_NCDHW;
  output_218->dim[0] = 4;
  output_218->dim[1] = 64;
  output_218->dim[2] = 3;
  output_218->dim[3] = 4;
  output_218->dim[4] = 48;
  output_218->dim_count = 5;
  memcpy(output_218->qinfo, params_base + 1310760, sizeof(struct csinn_quant_info) * 1);
  struct csinn_reshape_params *params_218 = csinn_alloc_params(sizeof(struct csinn_reshape_params), sess);
  params_218->shape = shape_218;
  params_218->shape_num = 5;
  params_218->base.name = "reshape_/layer_4/layer_4.1/global_rep.0/pre_norm_mha.1/Reshape_178";
  params_218->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_reshape_init(output_216, output_218, params_218);
  int32_t *permute_219 = malloc(5 * 4);
  permute_219[0] = 0;
  permute_219[1] = 3;
  permute_219[2] = 2;
  permute_219[3] = 1;
  permute_219[4] = 4;
  struct csinn_tensor *output_219 = csinn_alloc_tensor(sess);
  output_219->name = "output_219";
  output_219->dtype = CSINN_DTYPE_FLOAT16;
  output_219->layout = CSINN_LAYOUT_NCDHW;
  output_219->dim[0] = 4;
  output_219->dim[1] = 4;
  output_219->dim[2] = 3;
  output_219->dim[3] = 64;
  output_219->dim[4] = 48;
  output_219->dim_count = 5;
  memcpy(output_219->qinfo, params_base + 1310784, sizeof(struct csinn_quant_info) * 1);
  struct csinn_transpose_params *params_219 = csinn_alloc_params(sizeof(struct csinn_transpose_params), sess);
  params_219->permute = permute_219;
  params_219->permute_num = 5;
  params_219->base.name = "transpose_/layer_4/layer_4.1/global_rep.0/pre_norm_mha.1/Transpose_179";
  params_219->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_transpose_init(output_218, output_219, params_219);
  struct csinn_tensor *output_220 = csinn_alloc_tensor(sess);
  output_220->name = "output_220";
  output_220->dtype = CSINN_DTYPE_FLOAT16;
  output_220->layout = CSINN_LAYOUT_NCHW;
  output_220->dim[0] = 4;
  output_220->dim[1] = 4;
  output_220->dim[2] = 64;
  output_220->dim[3] = 48;
  output_220->dim_count = 4;
  memcpy(output_220->qinfo, params_base + 1310808, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *indices_220 = csinn_alloc_tensor(sess);
  indices_220->name = "indices_220";
  indices_220->data = params_base + 1310856;
  indices_220->is_const = 1;
  indices_220->dtype = CSINN_DTYPE_INT64;
  indices_220->layout = CSINN_LAYOUT_O;
  indices_220->dim[0] = 1;
  indices_220->dim_count = 1;
  memcpy(indices_220->qinfo, params_base + 1310832, sizeof(struct csinn_quant_info) * 1);
  struct csinn_gather_params *params_220 = csinn_alloc_params(sizeof(struct csinn_gather_params), sess);
  params_220->axis = 2;
  params_220->base.name = "take_/layer_4/layer_4.1/global_rep.0/pre_norm_mha.1/Gather_180";
  params_220->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_gather_init(output_219, indices_220, output_220, params_220);
  struct csinn_tensor *output_222 = csinn_alloc_tensor(sess);
  output_222->name = "output_222";
  output_222->dtype = CSINN_DTYPE_FLOAT16;
  output_222->layout = CSINN_LAYOUT_NCHW;
  output_222->dim[0] = 4;
  output_222->dim[1] = 4;
  output_222->dim[2] = 64;
  output_222->dim[3] = 48;
  output_222->dim_count = 4;
  memcpy(output_222->qinfo, params_base + 1310864, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *rhs_222 = csinn_alloc_tensor(sess);
  rhs_222->name = "rhs_222";
  rhs_222->data = params_base + 1310912;
  rhs_222->is_const = 1;
  rhs_222->dtype = CSINN_DTYPE_FLOAT16;
  rhs_222->layout = CSINN_LAYOUT_OIHW;
  rhs_222->dim[0] = 1;
  rhs_222->dim[1] = 1;
  rhs_222->dim[2] = 1;
  rhs_222->dim[3] = 1;
  rhs_222->dim_count = 4;
  memcpy(rhs_222->qinfo, params_base + 1310888, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_222 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_222->base.name = "multiply_/layer_4/layer_4.1/global_rep.0/pre_norm_mha.1/Mul_181";
  params_222->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_mul_init(output_220, rhs_222, output_222, params_222);
  struct csinn_tensor *output_225 = csinn_alloc_tensor(sess);
  output_225->name = "output_225";
  output_225->dtype = CSINN_DTYPE_FLOAT16;
  output_225->layout = CSINN_LAYOUT_NCHW;
  output_225->dim[0] = 4;
  output_225->dim[1] = 4;
  output_225->dim[2] = 64;
  output_225->dim[3] = 48;
  output_225->dim_count = 4;
  memcpy(output_225->qinfo, params_base + 1310916, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *indices_225 = csinn_alloc_tensor(sess);
  indices_225->name = "indices_225";
  indices_225->data = params_base + 1310964;
  indices_225->is_const = 1;
  indices_225->dtype = CSINN_DTYPE_INT64;
  indices_225->layout = CSINN_LAYOUT_O;
  indices_225->dim[0] = 1;
  indices_225->dim_count = 1;
  memcpy(indices_225->qinfo, params_base + 1310940, sizeof(struct csinn_quant_info) * 1);
  struct csinn_gather_params *params_225 = csinn_alloc_params(sizeof(struct csinn_gather_params), sess);
  params_225->axis = 2;
  params_225->base.name = "take_/layer_4/layer_4.1/global_rep.0/pre_norm_mha.1/Gather_1_183";
  params_225->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_gather_init(output_219, indices_225, output_225, params_225);
  int32_t *permute_226 = malloc(4 * 4);
  permute_226[0] = 0;
  permute_226[1] = 1;
  permute_226[2] = 3;
  permute_226[3] = 2;
  struct csinn_tensor *output_226 = csinn_alloc_tensor(sess);
  output_226->name = "output_226";
  output_226->dtype = CSINN_DTYPE_FLOAT16;
  output_226->layout = CSINN_LAYOUT_NCHW;
  output_226->dim[0] = 4;
  output_226->dim[1] = 4;
  output_226->dim[2] = 48;
  output_226->dim[3] = 64;
  output_226->dim_count = 4;
  memcpy(output_226->qinfo, params_base + 1310972, sizeof(struct csinn_quant_info) * 1);
  struct csinn_transpose_params *params_226 = csinn_alloc_params(sizeof(struct csinn_transpose_params), sess);
  params_226->permute = permute_226;
  params_226->permute_num = 4;
  params_226->base.name = "transpose_/layer_4/layer_4.1/global_rep.0/pre_norm_mha.1/Transpose_1_184";
  params_226->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_transpose_init(output_225, output_226, params_226);
  struct csinn_tensor *output_227 = csinn_alloc_tensor(sess);
  output_227->name = "output_227";
  output_227->dtype = CSINN_DTYPE_FLOAT16;
  output_227->layout = CSINN_LAYOUT_NCHW;
  output_227->dim[0] = 4;
  output_227->dim[1] = 4;
  output_227->dim[2] = 64;
  output_227->dim[3] = 64;
  output_227->dim_count = 4;
  memcpy(output_227->qinfo, params_base + 1310996, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_227 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_227->trans_a = false;
  params_227->trans_b = false;
  params_227->base.name = "batch_matmul_/layer_4/layer_4.1/global_rep.0/pre_norm_mha.1/MatMul_186";
  params_227->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_222, output_226, output_227, params_227);
  struct csinn_tensor *output_228 = csinn_alloc_tensor(sess);
  output_228->name = "output_228";
  output_228->dtype = CSINN_DTYPE_FLOAT16;
  output_228->layout = CSINN_LAYOUT_NCHW;
  output_228->dim[0] = 4;
  output_228->dim[1] = 4;
  output_228->dim[2] = 64;
  output_228->dim[3] = 64;
  output_228->dim_count = 4;
  memcpy(output_228->qinfo, params_base + 1311020, sizeof(struct csinn_quant_info) * 1);
  struct csinn_softmax_params *params_228 = csinn_alloc_params(sizeof(struct csinn_softmax_params), sess);
  params_228->axis = 3;
  params_228->base.name = "softmax_/layer_4/layer_4.1/global_rep.0/pre_norm_mha.1/softmax/Softmax_188";
  params_228->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_softmax_init(output_227, output_228, params_228);
  struct csinn_tensor *output_230 = csinn_alloc_tensor(sess);
  output_230->name = "output_230";
  output_230->dtype = CSINN_DTYPE_FLOAT16;
  output_230->layout = CSINN_LAYOUT_NCHW;
  output_230->dim[0] = 4;
  output_230->dim[1] = 4;
  output_230->dim[2] = 64;
  output_230->dim[3] = 48;
  output_230->dim_count = 4;
  memcpy(output_230->qinfo, params_base + 1311044, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *indices_230 = csinn_alloc_tensor(sess);
  indices_230->name = "indices_230";
  indices_230->data = params_base + 1311092;
  indices_230->is_const = 1;
  indices_230->dtype = CSINN_DTYPE_INT64;
  indices_230->layout = CSINN_LAYOUT_O;
  indices_230->dim[0] = 1;
  indices_230->dim_count = 1;
  memcpy(indices_230->qinfo, params_base + 1311068, sizeof(struct csinn_quant_info) * 1);
  struct csinn_gather_params *params_230 = csinn_alloc_params(sizeof(struct csinn_gather_params), sess);
  params_230->axis = 2;
  params_230->base.name = "take_/layer_4/layer_4.1/global_rep.0/pre_norm_mha.1/Gather_2_190";
  params_230->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_gather_init(output_219, indices_230, output_230, params_230);
  struct csinn_tensor *output_231 = csinn_alloc_tensor(sess);
  output_231->name = "output_231";
  output_231->dtype = CSINN_DTYPE_FLOAT16;
  output_231->layout = CSINN_LAYOUT_NCHW;
  output_231->dim[0] = 4;
  output_231->dim[1] = 4;
  output_231->dim[2] = 64;
  output_231->dim[3] = 48;
  output_231->dim_count = 4;
  memcpy(output_231->qinfo, params_base + 1311100, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_231 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_231->trans_a = false;
  params_231->trans_b = false;
  params_231->base.name = "batch_matmul_/layer_4/layer_4.1/global_rep.0/pre_norm_mha.1/MatMul_1_192";
  params_231->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_228, output_230, output_231, params_231);
  int32_t *permute_232 = malloc(4 * 4);
  permute_232[0] = 0;
  permute_232[1] = 2;
  permute_232[2] = 1;
  permute_232[3] = 3;
  struct csinn_tensor *output_232 = csinn_alloc_tensor(sess);
  output_232->name = "output_232";
  output_232->dtype = CSINN_DTYPE_FLOAT16;
  output_232->layout = CSINN_LAYOUT_NCHW;
  output_232->dim[0] = 4;
  output_232->dim[1] = 64;
  output_232->dim[2] = 4;
  output_232->dim[3] = 48;
  output_232->dim_count = 4;
  memcpy(output_232->qinfo, params_base + 1311124, sizeof(struct csinn_quant_info) * 1);
  struct csinn_transpose_params *params_232 = csinn_alloc_params(sizeof(struct csinn_transpose_params), sess);
  params_232->permute = permute_232;
  params_232->permute_num = 4;
  params_232->base.name = "transpose_/layer_4/layer_4.1/global_rep.0/pre_norm_mha.1/Transpose_2_194";
  params_232->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_transpose_init(output_231, output_232, params_232);
  int32_t *shape_233 = malloc(3 * 4);
  shape_233[0] = 4;
  shape_233[1] = 64;
  shape_233[2] = -1;
  struct csinn_tensor *output_233 = csinn_alloc_tensor(sess);
  output_233->name = "output_233";
  output_233->dtype = CSINN_DTYPE_FLOAT16;
  output_233->layout = CSINN_LAYOUT_NCW;
  output_233->dim[0] = 4;
  output_233->dim[1] = 64;
  output_233->dim[2] = 192;
  output_233->dim_count = 3;
  memcpy(output_233->qinfo, params_base + 1311148, sizeof(struct csinn_quant_info) * 1);
  struct csinn_reshape_params *params_233 = csinn_alloc_params(sizeof(struct csinn_reshape_params), sess);
  params_233->shape = shape_233;
  params_233->shape_num = 3;
  params_233->base.name = "reshape_/layer_4/layer_4.1/global_rep.0/pre_norm_mha.1/Reshape_1_195";
  params_233->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_reshape_init(output_232, output_233, params_233);
  struct csinn_tensor *output_235 = csinn_alloc_tensor(sess);
  output_235->name = "output_235";
  output_235->dtype = CSINN_DTYPE_FLOAT16;
  output_235->layout = CSINN_LAYOUT_NCW;
  output_235->dim[0] = 4;
  output_235->dim[1] = 64;
  output_235->dim[2] = 192;
  output_235->dim_count = 3;
  memcpy(output_235->qinfo, params_base + 1311172, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *data_b_235 = csinn_alloc_tensor(sess);
  data_b_235->name = "data_b_235";
  data_b_235->data = params_base + 1311220;
  data_b_235->is_const = 1;
  data_b_235->dtype = CSINN_DTYPE_INT8;
  data_b_235->layout = CSINN_LAYOUT_OIW;
  data_b_235->dim[0] = 1;
  data_b_235->dim[1] = 192;
  data_b_235->dim[2] = 192;
  data_b_235->dim_count = 3;
  memcpy(data_b_235->qinfo, params_base + 1311196, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_235 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_235->trans_a = false;
  params_235->trans_b = false;
  params_235->base.name = "batch_matmul_/layer_4/layer_4.1/global_rep.0/pre_norm_mha.1/out_proj/MatMul_196";
  params_235->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_233, data_b_235, output_235, params_235);
  struct csinn_tensor *output_237 = csinn_alloc_tensor(sess);
  output_237->name = "output_237";
  output_237->dtype = CSINN_DTYPE_FLOAT16;
  output_237->layout = CSINN_LAYOUT_NCW;
  output_237->dim[0] = 4;
  output_237->dim[1] = 64;
  output_237->dim[2] = 192;
  output_237->dim_count = 3;
  memcpy(output_237->qinfo, params_base + 1348084, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *rhs_237 = csinn_alloc_tensor(sess);
  rhs_237->name = "rhs_237";
  rhs_237->data = params_base + 1348132;
  rhs_237->is_const = 1;
  rhs_237->dtype = CSINN_DTYPE_FLOAT16;
  rhs_237->layout = CSINN_LAYOUT_OIW;
  rhs_237->dim[0] = 1;
  rhs_237->dim[1] = 1;
  rhs_237->dim[2] = 192;
  rhs_237->dim_count = 3;
  memcpy(rhs_237->qinfo, params_base + 1348108, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_237 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_237->base.name = "add_/layer_4/layer_4.1/global_rep.0/pre_norm_mha.1/out_proj/Add_198";
  params_237->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_235, rhs_237, output_237, params_237);
  struct csinn_tensor *output_240 = csinn_alloc_tensor(sess);
  output_240->name = "output_240";
  output_240->dtype = CSINN_DTYPE_FLOAT16;
  output_240->layout = CSINN_LAYOUT_NCW;
  output_240->dim[0] = 4;
  output_240->dim[1] = 64;
  output_240->dim[2] = 192;
  output_240->dim_count = 3;
  memcpy(output_240->qinfo, params_base + 1348516, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_240 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_240->base.name = "add_/layer_4/layer_4.1/global_rep.0/Add_199";
  params_240->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_237, output_211, output_240, params_240);
  struct csinn_tensor *output_243 = csinn_alloc_tensor(sess);
  output_243->name = "output_243";
  output_243->dtype = CSINN_DTYPE_FLOAT16;
  output_243->layout = CSINN_LAYOUT_NCW;
  output_243->dim[0] = 4;
  output_243->dim[1] = 64;
  output_243->dim[2] = 192;
  output_243->dim_count = 3;
  memcpy(output_243->qinfo, params_base + 1348540, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *gamma_243 = csinn_alloc_tensor(sess);
  gamma_243->name = "gamma_243";
  gamma_243->data = params_base + 1348588;
  gamma_243->is_const = 1;
  gamma_243->dtype = CSINN_DTYPE_FLOAT16;
  gamma_243->layout = CSINN_LAYOUT_O;
  gamma_243->dim[0] = 192;
  gamma_243->dim_count = 1;
  memcpy(gamma_243->qinfo, params_base + 1348564, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *beta_243 = csinn_alloc_tensor(sess);
  beta_243->name = "beta_243";
  beta_243->data = params_base + 1348996;
  beta_243->is_const = 1;
  beta_243->dtype = CSINN_DTYPE_FLOAT16;
  beta_243->layout = CSINN_LAYOUT_O;
  beta_243->dim[0] = 192;
  beta_243->dim_count = 1;
  memcpy(beta_243->qinfo, params_base + 1348972, sizeof(struct csinn_quant_info) * 1);
  struct csinn_layer_norm_params *params_243 = csinn_alloc_params(sizeof(struct csinn_layer_norm_params), sess);
  params_243->epsilon = 1e-05;
  params_243->axis = -1;
  params_243->center = true;
  params_243->scale = true;
  params_243->base.name = "layer_norm_200";
  params_243->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_layer_norm_init(output_240, output_243, gamma_243, beta_243, params_243);
  struct csinn_tensor *output_245 = csinn_alloc_tensor(sess);
  output_245->name = "output_245";
  output_245->dtype = CSINN_DTYPE_FLOAT16;
  output_245->layout = CSINN_LAYOUT_NCW;
  output_245->dim[0] = 4;
  output_245->dim[1] = 64;
  output_245->dim[2] = 384;
  output_245->dim_count = 3;
  memcpy(output_245->qinfo, params_base + 1349380, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *data_b_245 = csinn_alloc_tensor(sess);
  data_b_245->name = "data_b_245";
  data_b_245->data = params_base + 1349428;
  data_b_245->is_const = 1;
  data_b_245->dtype = CSINN_DTYPE_INT8;
  data_b_245->layout = CSINN_LAYOUT_OIW;
  data_b_245->dim[0] = 1;
  data_b_245->dim[1] = 192;
  data_b_245->dim[2] = 384;
  data_b_245->dim_count = 3;
  memcpy(data_b_245->qinfo, params_base + 1349404, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_245 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_245->trans_a = false;
  params_245->trans_b = false;
  params_245->base.name = "batch_matmul_/layer_4/layer_4.1/global_rep.0/pre_norm_ffn/pre_norm_ffn.1/MatMul_201";
  params_245->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_243, data_b_245, output_245, params_245);
  struct csinn_tensor *output_247 = csinn_alloc_tensor(sess);
  output_247->name = "output_247";
  output_247->dtype = CSINN_DTYPE_FLOAT16;
  output_247->layout = CSINN_LAYOUT_NCW;
  output_247->dim[0] = 4;
  output_247->dim[1] = 64;
  output_247->dim[2] = 384;
  output_247->dim_count = 3;
  memcpy(output_247->qinfo, params_base + 1423156, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *rhs_247 = csinn_alloc_tensor(sess);
  rhs_247->name = "rhs_247";
  rhs_247->data = params_base + 1423204;
  rhs_247->is_const = 1;
  rhs_247->dtype = CSINN_DTYPE_FLOAT16;
  rhs_247->layout = CSINN_LAYOUT_OIW;
  rhs_247->dim[0] = 1;
  rhs_247->dim[1] = 1;
  rhs_247->dim[2] = 384;
  rhs_247->dim_count = 3;
  memcpy(rhs_247->qinfo, params_base + 1423180, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_247 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_247->base.name = "add_/layer_4/layer_4.1/global_rep.0/pre_norm_ffn/pre_norm_ffn.1/Add_203";
  params_247->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_245, rhs_247, output_247, params_247);
  struct csinn_tensor *output_250 = csinn_alloc_tensor(sess);
  output_250->name = "output_250";
  output_250->dtype = CSINN_DTYPE_FLOAT16;
  output_250->layout = CSINN_LAYOUT_NCW;
  output_250->dim[0] = 4;
  output_250->dim[1] = 64;
  output_250->dim[2] = 384;
  output_250->dim_count = 3;
  memcpy(output_250->qinfo, params_base + 1423972, sizeof(struct csinn_quant_info) * 1);
  struct csinn_sigmoid_params *params_250 = csinn_alloc_params(sizeof(struct csinn_sigmoid_params), sess);
  params_250->base.name = "sigmoid_/layer_4/layer_4.1/global_rep.0/pre_norm_ffn/pre_norm_ffn.2/Sigmoid_204";
  params_250->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_sigmoid_init(output_247, output_250, params_250);
  struct csinn_tensor *output_251 = csinn_alloc_tensor(sess);
  output_251->name = "output_251";
  output_251->dtype = CSINN_DTYPE_FLOAT16;
  output_251->layout = CSINN_LAYOUT_NCW;
  output_251->dim[0] = 4;
  output_251->dim[1] = 64;
  output_251->dim[2] = 384;
  output_251->dim_count = 3;
  memcpy(output_251->qinfo, params_base + 1423996, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_251 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_251->base.name = "multiply_/layer_4/layer_4.1/global_rep.0/pre_norm_ffn/pre_norm_ffn.2/Mul_205";
  params_251->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_mul_init(output_247, output_250, output_251, params_251);
  struct csinn_tensor *output_254 = csinn_alloc_tensor(sess);
  output_254->name = "output_254";
  output_254->dtype = CSINN_DTYPE_FLOAT16;
  output_254->layout = CSINN_LAYOUT_NCW;
  output_254->dim[0] = 4;
  output_254->dim[1] = 64;
  output_254->dim[2] = 192;
  output_254->dim_count = 3;
  memcpy(output_254->qinfo, params_base + 1424020, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *data_b_254 = csinn_alloc_tensor(sess);
  data_b_254->name = "data_b_254";
  data_b_254->data = params_base + 1424068;
  data_b_254->is_const = 1;
  data_b_254->dtype = CSINN_DTYPE_INT8;
  data_b_254->layout = CSINN_LAYOUT_OIW;
  data_b_254->dim[0] = 1;
  data_b_254->dim[1] = 384;
  data_b_254->dim[2] = 192;
  data_b_254->dim_count = 3;
  memcpy(data_b_254->qinfo, params_base + 1424044, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_254 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_254->trans_a = false;
  params_254->trans_b = false;
  params_254->base.name = "batch_matmul_/layer_4/layer_4.1/global_rep.0/pre_norm_ffn/pre_norm_ffn.4/MatMul_206";
  params_254->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_251, data_b_254, output_254, params_254);
  struct csinn_tensor *output_256 = csinn_alloc_tensor(sess);
  output_256->name = "output_256";
  output_256->dtype = CSINN_DTYPE_FLOAT16;
  output_256->layout = CSINN_LAYOUT_NCW;
  output_256->dim[0] = 4;
  output_256->dim[1] = 64;
  output_256->dim[2] = 192;
  output_256->dim_count = 3;
  memcpy(output_256->qinfo, params_base + 1497796, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *rhs_256 = csinn_alloc_tensor(sess);
  rhs_256->name = "rhs_256";
  rhs_256->data = params_base + 1497844;
  rhs_256->is_const = 1;
  rhs_256->dtype = CSINN_DTYPE_FLOAT16;
  rhs_256->layout = CSINN_LAYOUT_OIW;
  rhs_256->dim[0] = 1;
  rhs_256->dim[1] = 1;
  rhs_256->dim[2] = 192;
  rhs_256->dim_count = 3;
  memcpy(rhs_256->qinfo, params_base + 1497820, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_256 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_256->base.name = "add_/layer_4/layer_4.1/global_rep.0/pre_norm_ffn/pre_norm_ffn.4/Add_208";
  params_256->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_254, rhs_256, output_256, params_256);
  struct csinn_tensor *output_258 = csinn_alloc_tensor(sess);
  output_258->name = "output_258";
  output_258->dtype = CSINN_DTYPE_FLOAT16;
  output_258->layout = CSINN_LAYOUT_NCW;
  output_258->dim[0] = 4;
  output_258->dim[1] = 64;
  output_258->dim[2] = 192;
  output_258->dim_count = 3;
  memcpy(output_258->qinfo, params_base + 1498228, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_258 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_258->base.name = "add_/layer_4/layer_4.1/global_rep.0/Add_1_209";
  params_258->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_240, output_256, output_258, params_258);
  struct csinn_tensor *output_260 = csinn_alloc_tensor(sess);
  output_260->name = "output_260";
  output_260->dtype = CSINN_DTYPE_FLOAT16;
  output_260->layout = CSINN_LAYOUT_NCW;
  output_260->dim[0] = 4;
  output_260->dim[1] = 64;
  output_260->dim[2] = 192;
  output_260->dim_count = 3;
  memcpy(output_260->qinfo, params_base + 1498252, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *gamma_260 = csinn_alloc_tensor(sess);
  gamma_260->name = "gamma_260";
  gamma_260->data = params_base + 1498300;
  gamma_260->is_const = 1;
  gamma_260->dtype = CSINN_DTYPE_FLOAT16;
  gamma_260->layout = CSINN_LAYOUT_O;
  gamma_260->dim[0] = 192;
  gamma_260->dim_count = 1;
  memcpy(gamma_260->qinfo, params_base + 1498276, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *beta_260 = csinn_alloc_tensor(sess);
  beta_260->name = "beta_260";
  beta_260->data = params_base + 1498708;
  beta_260->is_const = 1;
  beta_260->dtype = CSINN_DTYPE_FLOAT16;
  beta_260->layout = CSINN_LAYOUT_O;
  beta_260->dim[0] = 192;
  beta_260->dim_count = 1;
  memcpy(beta_260->qinfo, params_base + 1498684, sizeof(struct csinn_quant_info) * 1);
  struct csinn_layer_norm_params *params_260 = csinn_alloc_params(sizeof(struct csinn_layer_norm_params), sess);
  params_260->epsilon = 1e-05;
  params_260->axis = -1;
  params_260->center = true;
  params_260->scale = true;
  params_260->base.name = "layer_norm_210";
  params_260->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_layer_norm_init(output_258, output_260, gamma_260, beta_260, params_260);
  struct csinn_tensor *output_262 = csinn_alloc_tensor(sess);
  output_262->name = "output_262";
  output_262->dtype = CSINN_DTYPE_FLOAT16;
  output_262->layout = CSINN_LAYOUT_NCW;
  output_262->dim[0] = 4;
  output_262->dim[1] = 64;
  output_262->dim[2] = 576;
  output_262->dim_count = 3;
  memcpy(output_262->qinfo, params_base + 1499092, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *data_b_262 = csinn_alloc_tensor(sess);
  data_b_262->name = "data_b_262";
  data_b_262->data = params_base + 1499140;
  data_b_262->is_const = 1;
  data_b_262->dtype = CSINN_DTYPE_INT8;
  data_b_262->layout = CSINN_LAYOUT_OIW;
  data_b_262->dim[0] = 1;
  data_b_262->dim[1] = 192;
  data_b_262->dim[2] = 576;
  data_b_262->dim_count = 3;
  memcpy(data_b_262->qinfo, params_base + 1499116, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_262 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_262->trans_a = false;
  params_262->trans_b = false;
  params_262->base.name = "batch_matmul_/layer_4/layer_4.1/global_rep.1/pre_norm_mha.1/qkv_proj/MatMul_211";
  params_262->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_260, data_b_262, output_262, params_262);
  struct csinn_tensor *output_264 = csinn_alloc_tensor(sess);
  output_264->name = "output_264";
  output_264->dtype = CSINN_DTYPE_FLOAT16;
  output_264->layout = CSINN_LAYOUT_NCW;
  output_264->dim[0] = 4;
  output_264->dim[1] = 64;
  output_264->dim[2] = 576;
  output_264->dim_count = 3;
  memcpy(output_264->qinfo, params_base + 1609732, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *rhs_264 = csinn_alloc_tensor(sess);
  rhs_264->name = "rhs_264";
  rhs_264->data = params_base + 1609780;
  rhs_264->is_const = 1;
  rhs_264->dtype = CSINN_DTYPE_FLOAT16;
  rhs_264->layout = CSINN_LAYOUT_OIW;
  rhs_264->dim[0] = 1;
  rhs_264->dim[1] = 1;
  rhs_264->dim[2] = 576;
  rhs_264->dim_count = 3;
  memcpy(rhs_264->qinfo, params_base + 1609756, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_264 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_264->base.name = "add_/layer_4/layer_4.1/global_rep.1/pre_norm_mha.1/qkv_proj/Add_213";
  params_264->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_262, rhs_264, output_264, params_264);
  int32_t *shape_266 = malloc(5 * 4);
  shape_266[0] = 4;
  shape_266[1] = 64;
  shape_266[2] = 3;
  shape_266[3] = 4;
  shape_266[4] = -1;
  struct csinn_tensor *output_266 = csinn_alloc_tensor(sess);
  output_266->name = "output_266";
  output_266->dtype = CSINN_DTYPE_FLOAT16;
  output_266->layout = CSINN_LAYOUT_NCDHW;
  output_266->dim[0] = 4;
  output_266->dim[1] = 64;
  output_266->dim[2] = 3;
  output_266->dim[3] = 4;
  output_266->dim[4] = 48;
  output_266->dim_count = 5;
  memcpy(output_266->qinfo, params_base + 1610932, sizeof(struct csinn_quant_info) * 1);
  struct csinn_reshape_params *params_266 = csinn_alloc_params(sizeof(struct csinn_reshape_params), sess);
  params_266->shape = shape_266;
  params_266->shape_num = 5;
  params_266->base.name = "reshape_/layer_4/layer_4.1/global_rep.1/pre_norm_mha.1/Reshape_214";
  params_266->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_reshape_init(output_264, output_266, params_266);
  int32_t *permute_267 = malloc(5 * 4);
  permute_267[0] = 0;
  permute_267[1] = 3;
  permute_267[2] = 2;
  permute_267[3] = 1;
  permute_267[4] = 4;
  struct csinn_tensor *output_267 = csinn_alloc_tensor(sess);
  output_267->name = "output_267";
  output_267->dtype = CSINN_DTYPE_FLOAT16;
  output_267->layout = CSINN_LAYOUT_NCDHW;
  output_267->dim[0] = 4;
  output_267->dim[1] = 4;
  output_267->dim[2] = 3;
  output_267->dim[3] = 64;
  output_267->dim[4] = 48;
  output_267->dim_count = 5;
  memcpy(output_267->qinfo, params_base + 1610956, sizeof(struct csinn_quant_info) * 1);
  struct csinn_transpose_params *params_267 = csinn_alloc_params(sizeof(struct csinn_transpose_params), sess);
  params_267->permute = permute_267;
  params_267->permute_num = 5;
  params_267->base.name = "transpose_/layer_4/layer_4.1/global_rep.1/pre_norm_mha.1/Transpose_215";
  params_267->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_transpose_init(output_266, output_267, params_267);
  struct csinn_tensor *output_268 = csinn_alloc_tensor(sess);
  output_268->name = "output_268";
  output_268->dtype = CSINN_DTYPE_FLOAT16;
  output_268->layout = CSINN_LAYOUT_NCHW;
  output_268->dim[0] = 4;
  output_268->dim[1] = 4;
  output_268->dim[2] = 64;
  output_268->dim[3] = 48;
  output_268->dim_count = 4;
  memcpy(output_268->qinfo, params_base + 1610980, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *indices_268 = csinn_alloc_tensor(sess);
  indices_268->name = "indices_268";
  indices_268->data = params_base + 1611028;
  indices_268->is_const = 1;
  indices_268->dtype = CSINN_DTYPE_INT64;
  indices_268->layout = CSINN_LAYOUT_O;
  indices_268->dim[0] = 1;
  indices_268->dim_count = 1;
  memcpy(indices_268->qinfo, params_base + 1611004, sizeof(struct csinn_quant_info) * 1);
  struct csinn_gather_params *params_268 = csinn_alloc_params(sizeof(struct csinn_gather_params), sess);
  params_268->axis = 2;
  params_268->base.name = "take_/layer_4/layer_4.1/global_rep.1/pre_norm_mha.1/Gather_216";
  params_268->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_gather_init(output_267, indices_268, output_268, params_268);
  struct csinn_tensor *output_270 = csinn_alloc_tensor(sess);
  output_270->name = "output_270";
  output_270->dtype = CSINN_DTYPE_FLOAT16;
  output_270->layout = CSINN_LAYOUT_NCHW;
  output_270->dim[0] = 4;
  output_270->dim[1] = 4;
  output_270->dim[2] = 64;
  output_270->dim[3] = 48;
  output_270->dim_count = 4;
  memcpy(output_270->qinfo, params_base + 1611036, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *rhs_270 = csinn_alloc_tensor(sess);
  rhs_270->name = "rhs_270";
  rhs_270->data = params_base + 1611084;
  rhs_270->is_const = 1;
  rhs_270->dtype = CSINN_DTYPE_FLOAT16;
  rhs_270->layout = CSINN_LAYOUT_OIHW;
  rhs_270->dim[0] = 1;
  rhs_270->dim[1] = 1;
  rhs_270->dim[2] = 1;
  rhs_270->dim[3] = 1;
  rhs_270->dim_count = 4;
  memcpy(rhs_270->qinfo, params_base + 1611060, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_270 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_270->base.name = "multiply_/layer_4/layer_4.1/global_rep.1/pre_norm_mha.1/Mul_217";
  params_270->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_mul_init(output_268, rhs_270, output_270, params_270);
  struct csinn_tensor *output_273 = csinn_alloc_tensor(sess);
  output_273->name = "output_273";
  output_273->dtype = CSINN_DTYPE_FLOAT16;
  output_273->layout = CSINN_LAYOUT_NCHW;
  output_273->dim[0] = 4;
  output_273->dim[1] = 4;
  output_273->dim[2] = 64;
  output_273->dim[3] = 48;
  output_273->dim_count = 4;
  memcpy(output_273->qinfo, params_base + 1611088, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *indices_273 = csinn_alloc_tensor(sess);
  indices_273->name = "indices_273";
  indices_273->data = params_base + 1611136;
  indices_273->is_const = 1;
  indices_273->dtype = CSINN_DTYPE_INT64;
  indices_273->layout = CSINN_LAYOUT_O;
  indices_273->dim[0] = 1;
  indices_273->dim_count = 1;
  memcpy(indices_273->qinfo, params_base + 1611112, sizeof(struct csinn_quant_info) * 1);
  struct csinn_gather_params *params_273 = csinn_alloc_params(sizeof(struct csinn_gather_params), sess);
  params_273->axis = 2;
  params_273->base.name = "take_/layer_4/layer_4.1/global_rep.1/pre_norm_mha.1/Gather_1_219";
  params_273->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_gather_init(output_267, indices_273, output_273, params_273);
  int32_t *permute_274 = malloc(4 * 4);
  permute_274[0] = 0;
  permute_274[1] = 1;
  permute_274[2] = 3;
  permute_274[3] = 2;
  struct csinn_tensor *output_274 = csinn_alloc_tensor(sess);
  output_274->name = "output_274";
  output_274->dtype = CSINN_DTYPE_FLOAT16;
  output_274->layout = CSINN_LAYOUT_NCHW;
  output_274->dim[0] = 4;
  output_274->dim[1] = 4;
  output_274->dim[2] = 48;
  output_274->dim[3] = 64;
  output_274->dim_count = 4;
  memcpy(output_274->qinfo, params_base + 1611144, sizeof(struct csinn_quant_info) * 1);
  struct csinn_transpose_params *params_274 = csinn_alloc_params(sizeof(struct csinn_transpose_params), sess);
  params_274->permute = permute_274;
  params_274->permute_num = 4;
  params_274->base.name = "transpose_/layer_4/layer_4.1/global_rep.1/pre_norm_mha.1/Transpose_1_220";
  params_274->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_transpose_init(output_273, output_274, params_274);
  struct csinn_tensor *output_275 = csinn_alloc_tensor(sess);
  output_275->name = "output_275";
  output_275->dtype = CSINN_DTYPE_FLOAT16;
  output_275->layout = CSINN_LAYOUT_NCHW;
  output_275->dim[0] = 4;
  output_275->dim[1] = 4;
  output_275->dim[2] = 64;
  output_275->dim[3] = 64;
  output_275->dim_count = 4;
  memcpy(output_275->qinfo, params_base + 1611168, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_275 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_275->trans_a = false;
  params_275->trans_b = false;
  params_275->base.name = "batch_matmul_/layer_4/layer_4.1/global_rep.1/pre_norm_mha.1/MatMul_222";
  params_275->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_270, output_274, output_275, params_275);
  struct csinn_tensor *output_276 = csinn_alloc_tensor(sess);
  output_276->name = "output_276";
  output_276->dtype = CSINN_DTYPE_FLOAT16;
  output_276->layout = CSINN_LAYOUT_NCHW;
  output_276->dim[0] = 4;
  output_276->dim[1] = 4;
  output_276->dim[2] = 64;
  output_276->dim[3] = 64;
  output_276->dim_count = 4;
  memcpy(output_276->qinfo, params_base + 1611192, sizeof(struct csinn_quant_info) * 1);
  struct csinn_softmax_params *params_276 = csinn_alloc_params(sizeof(struct csinn_softmax_params), sess);
  params_276->axis = 3;
  params_276->base.name = "softmax_/layer_4/layer_4.1/global_rep.1/pre_norm_mha.1/softmax/Softmax_224";
  params_276->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_softmax_init(output_275, output_276, params_276);
  struct csinn_tensor *output_278 = csinn_alloc_tensor(sess);
  output_278->name = "output_278";
  output_278->dtype = CSINN_DTYPE_FLOAT16;
  output_278->layout = CSINN_LAYOUT_NCHW;
  output_278->dim[0] = 4;
  output_278->dim[1] = 4;
  output_278->dim[2] = 64;
  output_278->dim[3] = 48;
  output_278->dim_count = 4;
  memcpy(output_278->qinfo, params_base + 1611216, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *indices_278 = csinn_alloc_tensor(sess);
  indices_278->name = "indices_278";
  indices_278->data = params_base + 1611264;
  indices_278->is_const = 1;
  indices_278->dtype = CSINN_DTYPE_INT64;
  indices_278->layout = CSINN_LAYOUT_O;
  indices_278->dim[0] = 1;
  indices_278->dim_count = 1;
  memcpy(indices_278->qinfo, params_base + 1611240, sizeof(struct csinn_quant_info) * 1);
  struct csinn_gather_params *params_278 = csinn_alloc_params(sizeof(struct csinn_gather_params), sess);
  params_278->axis = 2;
  params_278->base.name = "take_/layer_4/layer_4.1/global_rep.1/pre_norm_mha.1/Gather_2_226";
  params_278->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_gather_init(output_267, indices_278, output_278, params_278);
  struct csinn_tensor *output_279 = csinn_alloc_tensor(sess);
  output_279->name = "output_279";
  output_279->dtype = CSINN_DTYPE_FLOAT16;
  output_279->layout = CSINN_LAYOUT_NCHW;
  output_279->dim[0] = 4;
  output_279->dim[1] = 4;
  output_279->dim[2] = 64;
  output_279->dim[3] = 48;
  output_279->dim_count = 4;
  memcpy(output_279->qinfo, params_base + 1611272, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_279 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_279->trans_a = false;
  params_279->trans_b = false;
  params_279->base.name = "batch_matmul_/layer_4/layer_4.1/global_rep.1/pre_norm_mha.1/MatMul_1_228";
  params_279->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_276, output_278, output_279, params_279);
  int32_t *permute_280 = malloc(4 * 4);
  permute_280[0] = 0;
  permute_280[1] = 2;
  permute_280[2] = 1;
  permute_280[3] = 3;
  struct csinn_tensor *output_280 = csinn_alloc_tensor(sess);
  output_280->name = "output_280";
  output_280->dtype = CSINN_DTYPE_FLOAT16;
  output_280->layout = CSINN_LAYOUT_NCHW;
  output_280->dim[0] = 4;
  output_280->dim[1] = 64;
  output_280->dim[2] = 4;
  output_280->dim[3] = 48;
  output_280->dim_count = 4;
  memcpy(output_280->qinfo, params_base + 1611296, sizeof(struct csinn_quant_info) * 1);
  struct csinn_transpose_params *params_280 = csinn_alloc_params(sizeof(struct csinn_transpose_params), sess);
  params_280->permute = permute_280;
  params_280->permute_num = 4;
  params_280->base.name = "transpose_/layer_4/layer_4.1/global_rep.1/pre_norm_mha.1/Transpose_2_230";
  params_280->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_transpose_init(output_279, output_280, params_280);
  int32_t *shape_281 = malloc(3 * 4);
  shape_281[0] = 4;
  shape_281[1] = 64;
  shape_281[2] = -1;
  struct csinn_tensor *output_281 = csinn_alloc_tensor(sess);
  output_281->name = "output_281";
  output_281->dtype = CSINN_DTYPE_FLOAT16;
  output_281->layout = CSINN_LAYOUT_NCW;
  output_281->dim[0] = 4;
  output_281->dim[1] = 64;
  output_281->dim[2] = 192;
  output_281->dim_count = 3;
  memcpy(output_281->qinfo, params_base + 1611320, sizeof(struct csinn_quant_info) * 1);
  struct csinn_reshape_params *params_281 = csinn_alloc_params(sizeof(struct csinn_reshape_params), sess);
  params_281->shape = shape_281;
  params_281->shape_num = 3;
  params_281->base.name = "reshape_/layer_4/layer_4.1/global_rep.1/pre_norm_mha.1/Reshape_1_231";
  params_281->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_reshape_init(output_280, output_281, params_281);
  struct csinn_tensor *output_283 = csinn_alloc_tensor(sess);
  output_283->name = "output_283";
  output_283->dtype = CSINN_DTYPE_FLOAT16;
  output_283->layout = CSINN_LAYOUT_NCW;
  output_283->dim[0] = 4;
  output_283->dim[1] = 64;
  output_283->dim[2] = 192;
  output_283->dim_count = 3;
  memcpy(output_283->qinfo, params_base + 1611344, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *data_b_283 = csinn_alloc_tensor(sess);
  data_b_283->name = "data_b_283";
  data_b_283->data = params_base + 1611392;
  data_b_283->is_const = 1;
  data_b_283->dtype = CSINN_DTYPE_INT8;
  data_b_283->layout = CSINN_LAYOUT_OIW;
  data_b_283->dim[0] = 1;
  data_b_283->dim[1] = 192;
  data_b_283->dim[2] = 192;
  data_b_283->dim_count = 3;
  memcpy(data_b_283->qinfo, params_base + 1611368, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_283 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_283->trans_a = false;
  params_283->trans_b = false;
  params_283->base.name = "batch_matmul_/layer_4/layer_4.1/global_rep.1/pre_norm_mha.1/out_proj/MatMul_232";
  params_283->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_281, data_b_283, output_283, params_283);
  struct csinn_tensor *output_285 = csinn_alloc_tensor(sess);
  output_285->name = "output_285";
  output_285->dtype = CSINN_DTYPE_FLOAT16;
  output_285->layout = CSINN_LAYOUT_NCW;
  output_285->dim[0] = 4;
  output_285->dim[1] = 64;
  output_285->dim[2] = 192;
  output_285->dim_count = 3;
  memcpy(output_285->qinfo, params_base + 1648256, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *rhs_285 = csinn_alloc_tensor(sess);
  rhs_285->name = "rhs_285";
  rhs_285->data = params_base + 1648304;
  rhs_285->is_const = 1;
  rhs_285->dtype = CSINN_DTYPE_FLOAT16;
  rhs_285->layout = CSINN_LAYOUT_OIW;
  rhs_285->dim[0] = 1;
  rhs_285->dim[1] = 1;
  rhs_285->dim[2] = 192;
  rhs_285->dim_count = 3;
  memcpy(rhs_285->qinfo, params_base + 1648280, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_285 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_285->base.name = "add_/layer_4/layer_4.1/global_rep.1/pre_norm_mha.1/out_proj/Add_234";
  params_285->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_283, rhs_285, output_285, params_285);
  struct csinn_tensor *output_288 = csinn_alloc_tensor(sess);
  output_288->name = "output_288";
  output_288->dtype = CSINN_DTYPE_FLOAT16;
  output_288->layout = CSINN_LAYOUT_NCW;
  output_288->dim[0] = 4;
  output_288->dim[1] = 64;
  output_288->dim[2] = 192;
  output_288->dim_count = 3;
  memcpy(output_288->qinfo, params_base + 1648688, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_288 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_288->base.name = "add_/layer_4/layer_4.1/global_rep.1/Add_235";
  params_288->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_285, output_258, output_288, params_288);
  struct csinn_tensor *output_291 = csinn_alloc_tensor(sess);
  output_291->name = "output_291";
  output_291->dtype = CSINN_DTYPE_FLOAT16;
  output_291->layout = CSINN_LAYOUT_NCW;
  output_291->dim[0] = 4;
  output_291->dim[1] = 64;
  output_291->dim[2] = 192;
  output_291->dim_count = 3;
  memcpy(output_291->qinfo, params_base + 1648712, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *gamma_291 = csinn_alloc_tensor(sess);
  gamma_291->name = "gamma_291";
  gamma_291->data = params_base + 1648760;
  gamma_291->is_const = 1;
  gamma_291->dtype = CSINN_DTYPE_FLOAT16;
  gamma_291->layout = CSINN_LAYOUT_O;
  gamma_291->dim[0] = 192;
  gamma_291->dim_count = 1;
  memcpy(gamma_291->qinfo, params_base + 1648736, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *beta_291 = csinn_alloc_tensor(sess);
  beta_291->name = "beta_291";
  beta_291->data = params_base + 1649168;
  beta_291->is_const = 1;
  beta_291->dtype = CSINN_DTYPE_FLOAT16;
  beta_291->layout = CSINN_LAYOUT_O;
  beta_291->dim[0] = 192;
  beta_291->dim_count = 1;
  memcpy(beta_291->qinfo, params_base + 1649144, sizeof(struct csinn_quant_info) * 1);
  struct csinn_layer_norm_params *params_291 = csinn_alloc_params(sizeof(struct csinn_layer_norm_params), sess);
  params_291->epsilon = 1e-05;
  params_291->axis = -1;
  params_291->center = true;
  params_291->scale = true;
  params_291->base.name = "layer_norm_236";
  params_291->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_layer_norm_init(output_288, output_291, gamma_291, beta_291, params_291);
  struct csinn_tensor *output_293 = csinn_alloc_tensor(sess);
  output_293->name = "output_293";
  output_293->dtype = CSINN_DTYPE_FLOAT16;
  output_293->layout = CSINN_LAYOUT_NCW;
  output_293->dim[0] = 4;
  output_293->dim[1] = 64;
  output_293->dim[2] = 384;
  output_293->dim_count = 3;
  memcpy(output_293->qinfo, params_base + 1649552, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *data_b_293 = csinn_alloc_tensor(sess);
  data_b_293->name = "data_b_293";
  data_b_293->data = params_base + 1649600;
  data_b_293->is_const = 1;
  data_b_293->dtype = CSINN_DTYPE_INT8;
  data_b_293->layout = CSINN_LAYOUT_OIW;
  data_b_293->dim[0] = 1;
  data_b_293->dim[1] = 192;
  data_b_293->dim[2] = 384;
  data_b_293->dim_count = 3;
  memcpy(data_b_293->qinfo, params_base + 1649576, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_293 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_293->trans_a = false;
  params_293->trans_b = false;
  params_293->base.name = "batch_matmul_/layer_4/layer_4.1/global_rep.1/pre_norm_ffn/pre_norm_ffn.1/MatMul_237";
  params_293->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_291, data_b_293, output_293, params_293);
  struct csinn_tensor *output_295 = csinn_alloc_tensor(sess);
  output_295->name = "output_295";
  output_295->dtype = CSINN_DTYPE_FLOAT16;
  output_295->layout = CSINN_LAYOUT_NCW;
  output_295->dim[0] = 4;
  output_295->dim[1] = 64;
  output_295->dim[2] = 384;
  output_295->dim_count = 3;
  memcpy(output_295->qinfo, params_base + 1723328, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *rhs_295 = csinn_alloc_tensor(sess);
  rhs_295->name = "rhs_295";
  rhs_295->data = params_base + 1723376;
  rhs_295->is_const = 1;
  rhs_295->dtype = CSINN_DTYPE_FLOAT16;
  rhs_295->layout = CSINN_LAYOUT_OIW;
  rhs_295->dim[0] = 1;
  rhs_295->dim[1] = 1;
  rhs_295->dim[2] = 384;
  rhs_295->dim_count = 3;
  memcpy(rhs_295->qinfo, params_base + 1723352, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_295 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_295->base.name = "add_/layer_4/layer_4.1/global_rep.1/pre_norm_ffn/pre_norm_ffn.1/Add_239";
  params_295->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_293, rhs_295, output_295, params_295);
  struct csinn_tensor *output_298 = csinn_alloc_tensor(sess);
  output_298->name = "output_298";
  output_298->dtype = CSINN_DTYPE_FLOAT16;
  output_298->layout = CSINN_LAYOUT_NCW;
  output_298->dim[0] = 4;
  output_298->dim[1] = 64;
  output_298->dim[2] = 384;
  output_298->dim_count = 3;
  memcpy(output_298->qinfo, params_base + 1724144, sizeof(struct csinn_quant_info) * 1);
  struct csinn_sigmoid_params *params_298 = csinn_alloc_params(sizeof(struct csinn_sigmoid_params), sess);
  params_298->base.name = "sigmoid_/layer_4/layer_4.1/global_rep.1/pre_norm_ffn/pre_norm_ffn.2/Sigmoid_240";
  params_298->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_sigmoid_init(output_295, output_298, params_298);
  struct csinn_tensor *output_299 = csinn_alloc_tensor(sess);
  output_299->name = "output_299";
  output_299->dtype = CSINN_DTYPE_FLOAT16;
  output_299->layout = CSINN_LAYOUT_NCW;
  output_299->dim[0] = 4;
  output_299->dim[1] = 64;
  output_299->dim[2] = 384;
  output_299->dim_count = 3;
  memcpy(output_299->qinfo, params_base + 1724168, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_299 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_299->base.name = "multiply_/layer_4/layer_4.1/global_rep.1/pre_norm_ffn/pre_norm_ffn.2/Mul_241";
  params_299->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_mul_init(output_295, output_298, output_299, params_299);
  struct csinn_tensor *output_302 = csinn_alloc_tensor(sess);
  output_302->name = "output_302";
  output_302->dtype = CSINN_DTYPE_FLOAT16;
  output_302->layout = CSINN_LAYOUT_NCW;
  output_302->dim[0] = 4;
  output_302->dim[1] = 64;
  output_302->dim[2] = 192;
  output_302->dim_count = 3;
  memcpy(output_302->qinfo, params_base + 1724192, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *data_b_302 = csinn_alloc_tensor(sess);
  data_b_302->name = "data_b_302";
  data_b_302->data = params_base + 1724240;
  data_b_302->is_const = 1;
  data_b_302->dtype = CSINN_DTYPE_INT8;
  data_b_302->layout = CSINN_LAYOUT_OIW;
  data_b_302->dim[0] = 1;
  data_b_302->dim[1] = 384;
  data_b_302->dim[2] = 192;
  data_b_302->dim_count = 3;
  memcpy(data_b_302->qinfo, params_base + 1724216, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_302 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_302->trans_a = false;
  params_302->trans_b = false;
  params_302->base.name = "batch_matmul_/layer_4/layer_4.1/global_rep.1/pre_norm_ffn/pre_norm_ffn.4/MatMul_242";
  params_302->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_299, data_b_302, output_302, params_302);
  struct csinn_tensor *output_304 = csinn_alloc_tensor(sess);
  output_304->name = "output_304";
  output_304->dtype = CSINN_DTYPE_FLOAT16;
  output_304->layout = CSINN_LAYOUT_NCW;
  output_304->dim[0] = 4;
  output_304->dim[1] = 64;
  output_304->dim[2] = 192;
  output_304->dim_count = 3;
  memcpy(output_304->qinfo, params_base + 1797968, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *rhs_304 = csinn_alloc_tensor(sess);
  rhs_304->name = "rhs_304";
  rhs_304->data = params_base + 1798016;
  rhs_304->is_const = 1;
  rhs_304->dtype = CSINN_DTYPE_FLOAT16;
  rhs_304->layout = CSINN_LAYOUT_OIW;
  rhs_304->dim[0] = 1;
  rhs_304->dim[1] = 1;
  rhs_304->dim[2] = 192;
  rhs_304->dim_count = 3;
  memcpy(rhs_304->qinfo, params_base + 1797992, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_304 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_304->base.name = "add_/layer_4/layer_4.1/global_rep.1/pre_norm_ffn/pre_norm_ffn.4/Add_244";
  params_304->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_302, rhs_304, output_304, params_304);
  struct csinn_tensor *output_306 = csinn_alloc_tensor(sess);
  output_306->name = "output_306";
  output_306->dtype = CSINN_DTYPE_FLOAT16;
  output_306->layout = CSINN_LAYOUT_NCW;
  output_306->dim[0] = 4;
  output_306->dim[1] = 64;
  output_306->dim[2] = 192;
  output_306->dim_count = 3;
  memcpy(output_306->qinfo, params_base + 1798400, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_306 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_306->base.name = "add_/layer_4/layer_4.1/global_rep.1/Add_1_245";
  params_306->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_288, output_304, output_306, params_306);
  struct csinn_tensor *output_308 = csinn_alloc_tensor(sess);
  output_308->name = "output_308";
  output_308->dtype = CSINN_DTYPE_FLOAT16;
  output_308->layout = CSINN_LAYOUT_NCW;
  output_308->dim[0] = 4;
  output_308->dim[1] = 64;
  output_308->dim[2] = 192;
  output_308->dim_count = 3;
  memcpy(output_308->qinfo, params_base + 1798424, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *gamma_308 = csinn_alloc_tensor(sess);
  gamma_308->name = "gamma_308";
  gamma_308->data = params_base + 1798472;
  gamma_308->is_const = 1;
  gamma_308->dtype = CSINN_DTYPE_FLOAT16;
  gamma_308->layout = CSINN_LAYOUT_O;
  gamma_308->dim[0] = 192;
  gamma_308->dim_count = 1;
  memcpy(gamma_308->qinfo, params_base + 1798448, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *beta_308 = csinn_alloc_tensor(sess);
  beta_308->name = "beta_308";
  beta_308->data = params_base + 1798880;
  beta_308->is_const = 1;
  beta_308->dtype = CSINN_DTYPE_FLOAT16;
  beta_308->layout = CSINN_LAYOUT_O;
  beta_308->dim[0] = 192;
  beta_308->dim_count = 1;
  memcpy(beta_308->qinfo, params_base + 1798856, sizeof(struct csinn_quant_info) * 1);
  struct csinn_layer_norm_params *params_308 = csinn_alloc_params(sizeof(struct csinn_layer_norm_params), sess);
  params_308->epsilon = 1e-05;
  params_308->axis = -1;
  params_308->center = true;
  params_308->scale = true;
  params_308->base.name = "layer_norm_246";
  params_308->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_layer_norm_init(output_306, output_308, gamma_308, beta_308, params_308);
  struct csinn_tensor *output_310 = csinn_alloc_tensor(sess);
  output_310->name = "output_310";
  output_310->dtype = CSINN_DTYPE_FLOAT16;
  output_310->layout = CSINN_LAYOUT_NCW;
  output_310->dim[0] = 4;
  output_310->dim[1] = 64;
  output_310->dim[2] = 576;
  output_310->dim_count = 3;
  memcpy(output_310->qinfo, params_base + 1799264, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *data_b_310 = csinn_alloc_tensor(sess);
  data_b_310->name = "data_b_310";
  data_b_310->data = params_base + 1799312;
  data_b_310->is_const = 1;
  data_b_310->dtype = CSINN_DTYPE_INT8;
  data_b_310->layout = CSINN_LAYOUT_OIW;
  data_b_310->dim[0] = 1;
  data_b_310->dim[1] = 192;
  data_b_310->dim[2] = 576;
  data_b_310->dim_count = 3;
  memcpy(data_b_310->qinfo, params_base + 1799288, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_310 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_310->trans_a = false;
  params_310->trans_b = false;
  params_310->base.name = "batch_matmul_/layer_4/layer_4.1/global_rep.2/pre_norm_mha.1/qkv_proj/MatMul_247";
  params_310->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_308, data_b_310, output_310, params_310);
  struct csinn_tensor *output_312 = csinn_alloc_tensor(sess);
  output_312->name = "output_312";
  output_312->dtype = CSINN_DTYPE_FLOAT16;
  output_312->layout = CSINN_LAYOUT_NCW;
  output_312->dim[0] = 4;
  output_312->dim[1] = 64;
  output_312->dim[2] = 576;
  output_312->dim_count = 3;
  memcpy(output_312->qinfo, params_base + 1909904, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *rhs_312 = csinn_alloc_tensor(sess);
  rhs_312->name = "rhs_312";
  rhs_312->data = params_base + 1909952;
  rhs_312->is_const = 1;
  rhs_312->dtype = CSINN_DTYPE_FLOAT16;
  rhs_312->layout = CSINN_LAYOUT_OIW;
  rhs_312->dim[0] = 1;
  rhs_312->dim[1] = 1;
  rhs_312->dim[2] = 576;
  rhs_312->dim_count = 3;
  memcpy(rhs_312->qinfo, params_base + 1909928, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_312 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_312->base.name = "add_/layer_4/layer_4.1/global_rep.2/pre_norm_mha.1/qkv_proj/Add_249";
  params_312->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_310, rhs_312, output_312, params_312);
  int32_t *shape_314 = malloc(5 * 4);
  shape_314[0] = 4;
  shape_314[1] = 64;
  shape_314[2] = 3;
  shape_314[3] = 4;
  shape_314[4] = -1;
  struct csinn_tensor *output_314 = csinn_alloc_tensor(sess);
  output_314->name = "output_314";
  output_314->dtype = CSINN_DTYPE_FLOAT16;
  output_314->layout = CSINN_LAYOUT_NCDHW;
  output_314->dim[0] = 4;
  output_314->dim[1] = 64;
  output_314->dim[2] = 3;
  output_314->dim[3] = 4;
  output_314->dim[4] = 48;
  output_314->dim_count = 5;
  memcpy(output_314->qinfo, params_base + 1911104, sizeof(struct csinn_quant_info) * 1);
  struct csinn_reshape_params *params_314 = csinn_alloc_params(sizeof(struct csinn_reshape_params), sess);
  params_314->shape = shape_314;
  params_314->shape_num = 5;
  params_314->base.name = "reshape_/layer_4/layer_4.1/global_rep.2/pre_norm_mha.1/Reshape_250";
  params_314->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_reshape_init(output_312, output_314, params_314);
  int32_t *permute_315 = malloc(5 * 4);
  permute_315[0] = 0;
  permute_315[1] = 3;
  permute_315[2] = 2;
  permute_315[3] = 1;
  permute_315[4] = 4;
  struct csinn_tensor *output_315 = csinn_alloc_tensor(sess);
  output_315->name = "output_315";
  output_315->dtype = CSINN_DTYPE_FLOAT16;
  output_315->layout = CSINN_LAYOUT_NCDHW;
  output_315->dim[0] = 4;
  output_315->dim[1] = 4;
  output_315->dim[2] = 3;
  output_315->dim[3] = 64;
  output_315->dim[4] = 48;
  output_315->dim_count = 5;
  memcpy(output_315->qinfo, params_base + 1911128, sizeof(struct csinn_quant_info) * 1);
  struct csinn_transpose_params *params_315 = csinn_alloc_params(sizeof(struct csinn_transpose_params), sess);
  params_315->permute = permute_315;
  params_315->permute_num = 5;
  params_315->base.name = "transpose_/layer_4/layer_4.1/global_rep.2/pre_norm_mha.1/Transpose_251";
  params_315->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_transpose_init(output_314, output_315, params_315);
  struct csinn_tensor *output_316 = csinn_alloc_tensor(sess);
  output_316->name = "output_316";
  output_316->dtype = CSINN_DTYPE_FLOAT16;
  output_316->layout = CSINN_LAYOUT_NCHW;
  output_316->dim[0] = 4;
  output_316->dim[1] = 4;
  output_316->dim[2] = 64;
  output_316->dim[3] = 48;
  output_316->dim_count = 4;
  memcpy(output_316->qinfo, params_base + 1911152, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *indices_316 = csinn_alloc_tensor(sess);
  indices_316->name = "indices_316";
  indices_316->data = params_base + 1911200;
  indices_316->is_const = 1;
  indices_316->dtype = CSINN_DTYPE_INT64;
  indices_316->layout = CSINN_LAYOUT_O;
  indices_316->dim[0] = 1;
  indices_316->dim_count = 1;
  memcpy(indices_316->qinfo, params_base + 1911176, sizeof(struct csinn_quant_info) * 1);
  struct csinn_gather_params *params_316 = csinn_alloc_params(sizeof(struct csinn_gather_params), sess);
  params_316->axis = 2;
  params_316->base.name = "take_/layer_4/layer_4.1/global_rep.2/pre_norm_mha.1/Gather_252";
  params_316->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_gather_init(output_315, indices_316, output_316, params_316);
  struct csinn_tensor *output_318 = csinn_alloc_tensor(sess);
  output_318->name = "output_318";
  output_318->dtype = CSINN_DTYPE_FLOAT16;
  output_318->layout = CSINN_LAYOUT_NCHW;
  output_318->dim[0] = 4;
  output_318->dim[1] = 4;
  output_318->dim[2] = 64;
  output_318->dim[3] = 48;
  output_318->dim_count = 4;
  memcpy(output_318->qinfo, params_base + 1911208, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *rhs_318 = csinn_alloc_tensor(sess);
  rhs_318->name = "rhs_318";
  rhs_318->data = params_base + 1911256;
  rhs_318->is_const = 1;
  rhs_318->dtype = CSINN_DTYPE_FLOAT16;
  rhs_318->layout = CSINN_LAYOUT_OIHW;
  rhs_318->dim[0] = 1;
  rhs_318->dim[1] = 1;
  rhs_318->dim[2] = 1;
  rhs_318->dim[3] = 1;
  rhs_318->dim_count = 4;
  memcpy(rhs_318->qinfo, params_base + 1911232, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_318 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_318->base.name = "multiply_/layer_4/layer_4.1/global_rep.2/pre_norm_mha.1/Mul_253";
  params_318->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_mul_init(output_316, rhs_318, output_318, params_318);
  struct csinn_tensor *output_321 = csinn_alloc_tensor(sess);
  output_321->name = "output_321";
  output_321->dtype = CSINN_DTYPE_FLOAT16;
  output_321->layout = CSINN_LAYOUT_NCHW;
  output_321->dim[0] = 4;
  output_321->dim[1] = 4;
  output_321->dim[2] = 64;
  output_321->dim[3] = 48;
  output_321->dim_count = 4;
  memcpy(output_321->qinfo, params_base + 1911260, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *indices_321 = csinn_alloc_tensor(sess);
  indices_321->name = "indices_321";
  indices_321->data = params_base + 1911308;
  indices_321->is_const = 1;
  indices_321->dtype = CSINN_DTYPE_INT64;
  indices_321->layout = CSINN_LAYOUT_O;
  indices_321->dim[0] = 1;
  indices_321->dim_count = 1;
  memcpy(indices_321->qinfo, params_base + 1911284, sizeof(struct csinn_quant_info) * 1);
  struct csinn_gather_params *params_321 = csinn_alloc_params(sizeof(struct csinn_gather_params), sess);
  params_321->axis = 2;
  params_321->base.name = "take_/layer_4/layer_4.1/global_rep.2/pre_norm_mha.1/Gather_1_255";
  params_321->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_gather_init(output_315, indices_321, output_321, params_321);
  int32_t *permute_322 = malloc(4 * 4);
  permute_322[0] = 0;
  permute_322[1] = 1;
  permute_322[2] = 3;
  permute_322[3] = 2;
  struct csinn_tensor *output_322 = csinn_alloc_tensor(sess);
  output_322->name = "output_322";
  output_322->dtype = CSINN_DTYPE_FLOAT16;
  output_322->layout = CSINN_LAYOUT_NCHW;
  output_322->dim[0] = 4;
  output_322->dim[1] = 4;
  output_322->dim[2] = 48;
  output_322->dim[3] = 64;
  output_322->dim_count = 4;
  memcpy(output_322->qinfo, params_base + 1911316, sizeof(struct csinn_quant_info) * 1);
  struct csinn_transpose_params *params_322 = csinn_alloc_params(sizeof(struct csinn_transpose_params), sess);
  params_322->permute = permute_322;
  params_322->permute_num = 4;
  params_322->base.name = "transpose_/layer_4/layer_4.1/global_rep.2/pre_norm_mha.1/Transpose_1_256";
  params_322->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_transpose_init(output_321, output_322, params_322);
  struct csinn_tensor *output_323 = csinn_alloc_tensor(sess);
  output_323->name = "output_323";
  output_323->dtype = CSINN_DTYPE_FLOAT16;
  output_323->layout = CSINN_LAYOUT_NCHW;
  output_323->dim[0] = 4;
  output_323->dim[1] = 4;
  output_323->dim[2] = 64;
  output_323->dim[3] = 64;
  output_323->dim_count = 4;
  memcpy(output_323->qinfo, params_base + 1911340, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_323 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_323->trans_a = false;
  params_323->trans_b = false;
  params_323->base.name = "batch_matmul_/layer_4/layer_4.1/global_rep.2/pre_norm_mha.1/MatMul_258";
  params_323->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_318, output_322, output_323, params_323);
  struct csinn_tensor *output_324 = csinn_alloc_tensor(sess);
  output_324->name = "output_324";
  output_324->dtype = CSINN_DTYPE_FLOAT16;
  output_324->layout = CSINN_LAYOUT_NCHW;
  output_324->dim[0] = 4;
  output_324->dim[1] = 4;
  output_324->dim[2] = 64;
  output_324->dim[3] = 64;
  output_324->dim_count = 4;
  memcpy(output_324->qinfo, params_base + 1911364, sizeof(struct csinn_quant_info) * 1);
  struct csinn_softmax_params *params_324 = csinn_alloc_params(sizeof(struct csinn_softmax_params), sess);
  params_324->axis = 3;
  params_324->base.name = "softmax_/layer_4/layer_4.1/global_rep.2/pre_norm_mha.1/softmax/Softmax_260";
  params_324->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_softmax_init(output_323, output_324, params_324);
  struct csinn_tensor *output_326 = csinn_alloc_tensor(sess);
  output_326->name = "output_326";
  output_326->dtype = CSINN_DTYPE_FLOAT16;
  output_326->layout = CSINN_LAYOUT_NCHW;
  output_326->dim[0] = 4;
  output_326->dim[1] = 4;
  output_326->dim[2] = 64;
  output_326->dim[3] = 48;
  output_326->dim_count = 4;
  memcpy(output_326->qinfo, params_base + 1911388, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *indices_326 = csinn_alloc_tensor(sess);
  indices_326->name = "indices_326";
  indices_326->data = params_base + 1911436;
  indices_326->is_const = 1;
  indices_326->dtype = CSINN_DTYPE_INT64;
  indices_326->layout = CSINN_LAYOUT_O;
  indices_326->dim[0] = 1;
  indices_326->dim_count = 1;
  memcpy(indices_326->qinfo, params_base + 1911412, sizeof(struct csinn_quant_info) * 1);
  struct csinn_gather_params *params_326 = csinn_alloc_params(sizeof(struct csinn_gather_params), sess);
  params_326->axis = 2;
  params_326->base.name = "take_/layer_4/layer_4.1/global_rep.2/pre_norm_mha.1/Gather_2_262";
  params_326->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_gather_init(output_315, indices_326, output_326, params_326);
  struct csinn_tensor *output_327 = csinn_alloc_tensor(sess);
  output_327->name = "output_327";
  output_327->dtype = CSINN_DTYPE_FLOAT16;
  output_327->layout = CSINN_LAYOUT_NCHW;
  output_327->dim[0] = 4;
  output_327->dim[1] = 4;
  output_327->dim[2] = 64;
  output_327->dim[3] = 48;
  output_327->dim_count = 4;
  memcpy(output_327->qinfo, params_base + 1911444, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_327 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_327->trans_a = false;
  params_327->trans_b = false;
  params_327->base.name = "batch_matmul_/layer_4/layer_4.1/global_rep.2/pre_norm_mha.1/MatMul_1_264";
  params_327->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_324, output_326, output_327, params_327);
  int32_t *permute_328 = malloc(4 * 4);
  permute_328[0] = 0;
  permute_328[1] = 2;
  permute_328[2] = 1;
  permute_328[3] = 3;
  struct csinn_tensor *output_328 = csinn_alloc_tensor(sess);
  output_328->name = "output_328";
  output_328->dtype = CSINN_DTYPE_FLOAT16;
  output_328->layout = CSINN_LAYOUT_NCHW;
  output_328->dim[0] = 4;
  output_328->dim[1] = 64;
  output_328->dim[2] = 4;
  output_328->dim[3] = 48;
  output_328->dim_count = 4;
  memcpy(output_328->qinfo, params_base + 1911468, sizeof(struct csinn_quant_info) * 1);
  struct csinn_transpose_params *params_328 = csinn_alloc_params(sizeof(struct csinn_transpose_params), sess);
  params_328->permute = permute_328;
  params_328->permute_num = 4;
  params_328->base.name = "transpose_/layer_4/layer_4.1/global_rep.2/pre_norm_mha.1/Transpose_2_266";
  params_328->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_transpose_init(output_327, output_328, params_328);
  int32_t *shape_329 = malloc(3 * 4);
  shape_329[0] = 4;
  shape_329[1] = 64;
  shape_329[2] = -1;
  struct csinn_tensor *output_329 = csinn_alloc_tensor(sess);
  output_329->name = "output_329";
  output_329->dtype = CSINN_DTYPE_FLOAT16;
  output_329->layout = CSINN_LAYOUT_NCW;
  output_329->dim[0] = 4;
  output_329->dim[1] = 64;
  output_329->dim[2] = 192;
  output_329->dim_count = 3;
  memcpy(output_329->qinfo, params_base + 1911492, sizeof(struct csinn_quant_info) * 1);
  struct csinn_reshape_params *params_329 = csinn_alloc_params(sizeof(struct csinn_reshape_params), sess);
  params_329->shape = shape_329;
  params_329->shape_num = 3;
  params_329->base.name = "reshape_/layer_4/layer_4.1/global_rep.2/pre_norm_mha.1/Reshape_1_267";
  params_329->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_reshape_init(output_328, output_329, params_329);
  struct csinn_tensor *output_331 = csinn_alloc_tensor(sess);
  output_331->name = "output_331";
  output_331->dtype = CSINN_DTYPE_FLOAT16;
  output_331->layout = CSINN_LAYOUT_NCW;
  output_331->dim[0] = 4;
  output_331->dim[1] = 64;
  output_331->dim[2] = 192;
  output_331->dim_count = 3;
  memcpy(output_331->qinfo, params_base + 1911516, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *data_b_331 = csinn_alloc_tensor(sess);
  data_b_331->name = "data_b_331";
  data_b_331->data = params_base + 1911564;
  data_b_331->is_const = 1;
  data_b_331->dtype = CSINN_DTYPE_INT8;
  data_b_331->layout = CSINN_LAYOUT_OIW;
  data_b_331->dim[0] = 1;
  data_b_331->dim[1] = 192;
  data_b_331->dim[2] = 192;
  data_b_331->dim_count = 3;
  memcpy(data_b_331->qinfo, params_base + 1911540, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_331 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_331->trans_a = false;
  params_331->trans_b = false;
  params_331->base.name = "batch_matmul_/layer_4/layer_4.1/global_rep.2/pre_norm_mha.1/out_proj/MatMul_268";
  params_331->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_329, data_b_331, output_331, params_331);
  struct csinn_tensor *output_333 = csinn_alloc_tensor(sess);
  output_333->name = "output_333";
  output_333->dtype = CSINN_DTYPE_FLOAT16;
  output_333->layout = CSINN_LAYOUT_NCW;
  output_333->dim[0] = 4;
  output_333->dim[1] = 64;
  output_333->dim[2] = 192;
  output_333->dim_count = 3;
  memcpy(output_333->qinfo, params_base + 1948428, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *rhs_333 = csinn_alloc_tensor(sess);
  rhs_333->name = "rhs_333";
  rhs_333->data = params_base + 1948476;
  rhs_333->is_const = 1;
  rhs_333->dtype = CSINN_DTYPE_FLOAT16;
  rhs_333->layout = CSINN_LAYOUT_OIW;
  rhs_333->dim[0] = 1;
  rhs_333->dim[1] = 1;
  rhs_333->dim[2] = 192;
  rhs_333->dim_count = 3;
  memcpy(rhs_333->qinfo, params_base + 1948452, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_333 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_333->base.name = "add_/layer_4/layer_4.1/global_rep.2/pre_norm_mha.1/out_proj/Add_270";
  params_333->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_331, rhs_333, output_333, params_333);
  struct csinn_tensor *output_336 = csinn_alloc_tensor(sess);
  output_336->name = "output_336";
  output_336->dtype = CSINN_DTYPE_FLOAT16;
  output_336->layout = CSINN_LAYOUT_NCW;
  output_336->dim[0] = 4;
  output_336->dim[1] = 64;
  output_336->dim[2] = 192;
  output_336->dim_count = 3;
  memcpy(output_336->qinfo, params_base + 1948860, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_336 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_336->base.name = "add_/layer_4/layer_4.1/global_rep.2/Add_271";
  params_336->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_333, output_306, output_336, params_336);
  struct csinn_tensor *output_339 = csinn_alloc_tensor(sess);
  output_339->name = "output_339";
  output_339->dtype = CSINN_DTYPE_FLOAT16;
  output_339->layout = CSINN_LAYOUT_NCW;
  output_339->dim[0] = 4;
  output_339->dim[1] = 64;
  output_339->dim[2] = 192;
  output_339->dim_count = 3;
  memcpy(output_339->qinfo, params_base + 1948884, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *gamma_339 = csinn_alloc_tensor(sess);
  gamma_339->name = "gamma_339";
  gamma_339->data = params_base + 1948932;
  gamma_339->is_const = 1;
  gamma_339->dtype = CSINN_DTYPE_FLOAT16;
  gamma_339->layout = CSINN_LAYOUT_O;
  gamma_339->dim[0] = 192;
  gamma_339->dim_count = 1;
  memcpy(gamma_339->qinfo, params_base + 1948908, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *beta_339 = csinn_alloc_tensor(sess);
  beta_339->name = "beta_339";
  beta_339->data = params_base + 1949340;
  beta_339->is_const = 1;
  beta_339->dtype = CSINN_DTYPE_FLOAT16;
  beta_339->layout = CSINN_LAYOUT_O;
  beta_339->dim[0] = 192;
  beta_339->dim_count = 1;
  memcpy(beta_339->qinfo, params_base + 1949316, sizeof(struct csinn_quant_info) * 1);
  struct csinn_layer_norm_params *params_339 = csinn_alloc_params(sizeof(struct csinn_layer_norm_params), sess);
  params_339->epsilon = 1e-05;
  params_339->axis = -1;
  params_339->center = true;
  params_339->scale = true;
  params_339->base.name = "layer_norm_272";
  params_339->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_layer_norm_init(output_336, output_339, gamma_339, beta_339, params_339);
  struct csinn_tensor *output_341 = csinn_alloc_tensor(sess);
  output_341->name = "output_341";
  output_341->dtype = CSINN_DTYPE_FLOAT16;
  output_341->layout = CSINN_LAYOUT_NCW;
  output_341->dim[0] = 4;
  output_341->dim[1] = 64;
  output_341->dim[2] = 384;
  output_341->dim_count = 3;
  memcpy(output_341->qinfo, params_base + 1949724, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *data_b_341 = csinn_alloc_tensor(sess);
  data_b_341->name = "data_b_341";
  data_b_341->data = params_base + 1949772;
  data_b_341->is_const = 1;
  data_b_341->dtype = CSINN_DTYPE_INT8;
  data_b_341->layout = CSINN_LAYOUT_OIW;
  data_b_341->dim[0] = 1;
  data_b_341->dim[1] = 192;
  data_b_341->dim[2] = 384;
  data_b_341->dim_count = 3;
  memcpy(data_b_341->qinfo, params_base + 1949748, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_341 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_341->trans_a = false;
  params_341->trans_b = false;
  params_341->base.name = "batch_matmul_/layer_4/layer_4.1/global_rep.2/pre_norm_ffn/pre_norm_ffn.1/MatMul_273";
  params_341->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_339, data_b_341, output_341, params_341);
  struct csinn_tensor *output_343 = csinn_alloc_tensor(sess);
  output_343->name = "output_343";
  output_343->dtype = CSINN_DTYPE_FLOAT16;
  output_343->layout = CSINN_LAYOUT_NCW;
  output_343->dim[0] = 4;
  output_343->dim[1] = 64;
  output_343->dim[2] = 384;
  output_343->dim_count = 3;
  memcpy(output_343->qinfo, params_base + 2023500, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *rhs_343 = csinn_alloc_tensor(sess);
  rhs_343->name = "rhs_343";
  rhs_343->data = params_base + 2023548;
  rhs_343->is_const = 1;
  rhs_343->dtype = CSINN_DTYPE_FLOAT16;
  rhs_343->layout = CSINN_LAYOUT_OIW;
  rhs_343->dim[0] = 1;
  rhs_343->dim[1] = 1;
  rhs_343->dim[2] = 384;
  rhs_343->dim_count = 3;
  memcpy(rhs_343->qinfo, params_base + 2023524, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_343 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_343->base.name = "add_/layer_4/layer_4.1/global_rep.2/pre_norm_ffn/pre_norm_ffn.1/Add_275";
  params_343->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_341, rhs_343, output_343, params_343);
  struct csinn_tensor *output_346 = csinn_alloc_tensor(sess);
  output_346->name = "output_346";
  output_346->dtype = CSINN_DTYPE_FLOAT16;
  output_346->layout = CSINN_LAYOUT_NCW;
  output_346->dim[0] = 4;
  output_346->dim[1] = 64;
  output_346->dim[2] = 384;
  output_346->dim_count = 3;
  memcpy(output_346->qinfo, params_base + 2024316, sizeof(struct csinn_quant_info) * 1);
  struct csinn_sigmoid_params *params_346 = csinn_alloc_params(sizeof(struct csinn_sigmoid_params), sess);
  params_346->base.name = "sigmoid_/layer_4/layer_4.1/global_rep.2/pre_norm_ffn/pre_norm_ffn.2/Sigmoid_276";
  params_346->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_sigmoid_init(output_343, output_346, params_346);
  struct csinn_tensor *output_347 = csinn_alloc_tensor(sess);
  output_347->name = "output_347";
  output_347->dtype = CSINN_DTYPE_FLOAT16;
  output_347->layout = CSINN_LAYOUT_NCW;
  output_347->dim[0] = 4;
  output_347->dim[1] = 64;
  output_347->dim[2] = 384;
  output_347->dim_count = 3;
  memcpy(output_347->qinfo, params_base + 2024340, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_347 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_347->base.name = "multiply_/layer_4/layer_4.1/global_rep.2/pre_norm_ffn/pre_norm_ffn.2/Mul_277";
  params_347->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_mul_init(output_343, output_346, output_347, params_347);
  struct csinn_tensor *output_350 = csinn_alloc_tensor(sess);
  output_350->name = "output_350";
  output_350->dtype = CSINN_DTYPE_FLOAT16;
  output_350->layout = CSINN_LAYOUT_NCW;
  output_350->dim[0] = 4;
  output_350->dim[1] = 64;
  output_350->dim[2] = 192;
  output_350->dim_count = 3;
  memcpy(output_350->qinfo, params_base + 2024364, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *data_b_350 = csinn_alloc_tensor(sess);
  data_b_350->name = "data_b_350";
  data_b_350->data = params_base + 2024412;
  data_b_350->is_const = 1;
  data_b_350->dtype = CSINN_DTYPE_INT8;
  data_b_350->layout = CSINN_LAYOUT_OIW;
  data_b_350->dim[0] = 1;
  data_b_350->dim[1] = 384;
  data_b_350->dim[2] = 192;
  data_b_350->dim_count = 3;
  memcpy(data_b_350->qinfo, params_base + 2024388, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_350 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_350->trans_a = false;
  params_350->trans_b = false;
  params_350->base.name = "batch_matmul_/layer_4/layer_4.1/global_rep.2/pre_norm_ffn/pre_norm_ffn.4/MatMul_278";
  params_350->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_347, data_b_350, output_350, params_350);
  struct csinn_tensor *output_352 = csinn_alloc_tensor(sess);
  output_352->name = "output_352";
  output_352->dtype = CSINN_DTYPE_FLOAT16;
  output_352->layout = CSINN_LAYOUT_NCW;
  output_352->dim[0] = 4;
  output_352->dim[1] = 64;
  output_352->dim[2] = 192;
  output_352->dim_count = 3;
  memcpy(output_352->qinfo, params_base + 2098140, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *rhs_352 = csinn_alloc_tensor(sess);
  rhs_352->name = "rhs_352";
  rhs_352->data = params_base + 2098188;
  rhs_352->is_const = 1;
  rhs_352->dtype = CSINN_DTYPE_FLOAT16;
  rhs_352->layout = CSINN_LAYOUT_OIW;
  rhs_352->dim[0] = 1;
  rhs_352->dim[1] = 1;
  rhs_352->dim[2] = 192;
  rhs_352->dim_count = 3;
  memcpy(rhs_352->qinfo, params_base + 2098164, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_352 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_352->base.name = "add_/layer_4/layer_4.1/global_rep.2/pre_norm_ffn/pre_norm_ffn.4/Add_280";
  params_352->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_350, rhs_352, output_352, params_352);
  struct csinn_tensor *output_354 = csinn_alloc_tensor(sess);
  output_354->name = "output_354";
  output_354->dtype = CSINN_DTYPE_FLOAT16;
  output_354->layout = CSINN_LAYOUT_NCW;
  output_354->dim[0] = 4;
  output_354->dim[1] = 64;
  output_354->dim[2] = 192;
  output_354->dim_count = 3;
  memcpy(output_354->qinfo, params_base + 2098572, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_354 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_354->base.name = "add_/layer_4/layer_4.1/global_rep.2/Add_1_281";
  params_354->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_336, output_352, output_354, params_354);
  struct csinn_tensor *output_356 = csinn_alloc_tensor(sess);
  output_356->name = "output_356";
  output_356->dtype = CSINN_DTYPE_FLOAT16;
  output_356->layout = CSINN_LAYOUT_NCW;
  output_356->dim[0] = 4;
  output_356->dim[1] = 64;
  output_356->dim[2] = 192;
  output_356->dim_count = 3;
  memcpy(output_356->qinfo, params_base + 2098596, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *gamma_356 = csinn_alloc_tensor(sess);
  gamma_356->name = "gamma_356";
  gamma_356->data = params_base + 2098644;
  gamma_356->is_const = 1;
  gamma_356->dtype = CSINN_DTYPE_FLOAT16;
  gamma_356->layout = CSINN_LAYOUT_O;
  gamma_356->dim[0] = 192;
  gamma_356->dim_count = 1;
  memcpy(gamma_356->qinfo, params_base + 2098620, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *beta_356 = csinn_alloc_tensor(sess);
  beta_356->name = "beta_356";
  beta_356->data = params_base + 2099052;
  beta_356->is_const = 1;
  beta_356->dtype = CSINN_DTYPE_FLOAT16;
  beta_356->layout = CSINN_LAYOUT_O;
  beta_356->dim[0] = 192;
  beta_356->dim_count = 1;
  memcpy(beta_356->qinfo, params_base + 2099028, sizeof(struct csinn_quant_info) * 1);
  struct csinn_layer_norm_params *params_356 = csinn_alloc_params(sizeof(struct csinn_layer_norm_params), sess);
  params_356->epsilon = 1e-05;
  params_356->axis = -1;
  params_356->center = true;
  params_356->scale = true;
  params_356->base.name = "layer_norm_282";
  params_356->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_layer_norm_init(output_354, output_356, gamma_356, beta_356, params_356);
  struct csinn_tensor *output_358 = csinn_alloc_tensor(sess);
  output_358->name = "output_358";
  output_358->dtype = CSINN_DTYPE_FLOAT16;
  output_358->layout = CSINN_LAYOUT_NCW;
  output_358->dim[0] = 4;
  output_358->dim[1] = 64;
  output_358->dim[2] = 576;
  output_358->dim_count = 3;
  memcpy(output_358->qinfo, params_base + 2099436, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *data_b_358 = csinn_alloc_tensor(sess);
  data_b_358->name = "data_b_358";
  data_b_358->data = params_base + 2099484;
  data_b_358->is_const = 1;
  data_b_358->dtype = CSINN_DTYPE_INT8;
  data_b_358->layout = CSINN_LAYOUT_OIW;
  data_b_358->dim[0] = 1;
  data_b_358->dim[1] = 192;
  data_b_358->dim[2] = 576;
  data_b_358->dim_count = 3;
  memcpy(data_b_358->qinfo, params_base + 2099460, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_358 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_358->trans_a = false;
  params_358->trans_b = false;
  params_358->base.name = "batch_matmul_/layer_4/layer_4.1/global_rep.3/pre_norm_mha.1/qkv_proj/MatMul_283";
  params_358->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_356, data_b_358, output_358, params_358);
  struct csinn_tensor *output_360 = csinn_alloc_tensor(sess);
  output_360->name = "output_360";
  output_360->dtype = CSINN_DTYPE_FLOAT16;
  output_360->layout = CSINN_LAYOUT_NCW;
  output_360->dim[0] = 4;
  output_360->dim[1] = 64;
  output_360->dim[2] = 576;
  output_360->dim_count = 3;
  memcpy(output_360->qinfo, params_base + 2210076, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *rhs_360 = csinn_alloc_tensor(sess);
  rhs_360->name = "rhs_360";
  rhs_360->data = params_base + 2210124;
  rhs_360->is_const = 1;
  rhs_360->dtype = CSINN_DTYPE_FLOAT16;
  rhs_360->layout = CSINN_LAYOUT_OIW;
  rhs_360->dim[0] = 1;
  rhs_360->dim[1] = 1;
  rhs_360->dim[2] = 576;
  rhs_360->dim_count = 3;
  memcpy(rhs_360->qinfo, params_base + 2210100, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_360 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_360->base.name = "add_/layer_4/layer_4.1/global_rep.3/pre_norm_mha.1/qkv_proj/Add_285";
  params_360->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_358, rhs_360, output_360, params_360);
  int32_t *shape_362 = malloc(5 * 4);
  shape_362[0] = 4;
  shape_362[1] = 64;
  shape_362[2] = 3;
  shape_362[3] = 4;
  shape_362[4] = -1;
  struct csinn_tensor *output_362 = csinn_alloc_tensor(sess);
  output_362->name = "output_362";
  output_362->dtype = CSINN_DTYPE_FLOAT16;
  output_362->layout = CSINN_LAYOUT_NCDHW;
  output_362->dim[0] = 4;
  output_362->dim[1] = 64;
  output_362->dim[2] = 3;
  output_362->dim[3] = 4;
  output_362->dim[4] = 48;
  output_362->dim_count = 5;
  memcpy(output_362->qinfo, params_base + 2211276, sizeof(struct csinn_quant_info) * 1);
  struct csinn_reshape_params *params_362 = csinn_alloc_params(sizeof(struct csinn_reshape_params), sess);
  params_362->shape = shape_362;
  params_362->shape_num = 5;
  params_362->base.name = "reshape_/layer_4/layer_4.1/global_rep.3/pre_norm_mha.1/Reshape_286";
  params_362->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_reshape_init(output_360, output_362, params_362);
  int32_t *permute_363 = malloc(5 * 4);
  permute_363[0] = 0;
  permute_363[1] = 3;
  permute_363[2] = 2;
  permute_363[3] = 1;
  permute_363[4] = 4;
  struct csinn_tensor *output_363 = csinn_alloc_tensor(sess);
  output_363->name = "output_363";
  output_363->dtype = CSINN_DTYPE_FLOAT16;
  output_363->layout = CSINN_LAYOUT_NCDHW;
  output_363->dim[0] = 4;
  output_363->dim[1] = 4;
  output_363->dim[2] = 3;
  output_363->dim[3] = 64;
  output_363->dim[4] = 48;
  output_363->dim_count = 5;
  memcpy(output_363->qinfo, params_base + 2211300, sizeof(struct csinn_quant_info) * 1);
  struct csinn_transpose_params *params_363 = csinn_alloc_params(sizeof(struct csinn_transpose_params), sess);
  params_363->permute = permute_363;
  params_363->permute_num = 5;
  params_363->base.name = "transpose_/layer_4/layer_4.1/global_rep.3/pre_norm_mha.1/Transpose_287";
  params_363->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_transpose_init(output_362, output_363, params_363);
  struct csinn_tensor *output_364 = csinn_alloc_tensor(sess);
  output_364->name = "output_364";
  output_364->dtype = CSINN_DTYPE_FLOAT16;
  output_364->layout = CSINN_LAYOUT_NCHW;
  output_364->dim[0] = 4;
  output_364->dim[1] = 4;
  output_364->dim[2] = 64;
  output_364->dim[3] = 48;
  output_364->dim_count = 4;
  memcpy(output_364->qinfo, params_base + 2211324, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *indices_364 = csinn_alloc_tensor(sess);
  indices_364->name = "indices_364";
  indices_364->data = params_base + 2211372;
  indices_364->is_const = 1;
  indices_364->dtype = CSINN_DTYPE_INT64;
  indices_364->layout = CSINN_LAYOUT_O;
  indices_364->dim[0] = 1;
  indices_364->dim_count = 1;
  memcpy(indices_364->qinfo, params_base + 2211348, sizeof(struct csinn_quant_info) * 1);
  struct csinn_gather_params *params_364 = csinn_alloc_params(sizeof(struct csinn_gather_params), sess);
  params_364->axis = 2;
  params_364->base.name = "take_/layer_4/layer_4.1/global_rep.3/pre_norm_mha.1/Gather_288";
  params_364->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_gather_init(output_363, indices_364, output_364, params_364);
  struct csinn_tensor *output_366 = csinn_alloc_tensor(sess);
  output_366->name = "output_366";
  output_366->dtype = CSINN_DTYPE_FLOAT16;
  output_366->layout = CSINN_LAYOUT_NCHW;
  output_366->dim[0] = 4;
  output_366->dim[1] = 4;
  output_366->dim[2] = 64;
  output_366->dim[3] = 48;
  output_366->dim_count = 4;
  memcpy(output_366->qinfo, params_base + 2211380, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *rhs_366 = csinn_alloc_tensor(sess);
  rhs_366->name = "rhs_366";
  rhs_366->data = params_base + 2211428;
  rhs_366->is_const = 1;
  rhs_366->dtype = CSINN_DTYPE_FLOAT16;
  rhs_366->layout = CSINN_LAYOUT_OIHW;
  rhs_366->dim[0] = 1;
  rhs_366->dim[1] = 1;
  rhs_366->dim[2] = 1;
  rhs_366->dim[3] = 1;
  rhs_366->dim_count = 4;
  memcpy(rhs_366->qinfo, params_base + 2211404, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_366 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_366->base.name = "multiply_/layer_4/layer_4.1/global_rep.3/pre_norm_mha.1/Mul_289";
  params_366->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_mul_init(output_364, rhs_366, output_366, params_366);
  struct csinn_tensor *output_369 = csinn_alloc_tensor(sess);
  output_369->name = "output_369";
  output_369->dtype = CSINN_DTYPE_FLOAT16;
  output_369->layout = CSINN_LAYOUT_NCHW;
  output_369->dim[0] = 4;
  output_369->dim[1] = 4;
  output_369->dim[2] = 64;
  output_369->dim[3] = 48;
  output_369->dim_count = 4;
  memcpy(output_369->qinfo, params_base + 2211432, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *indices_369 = csinn_alloc_tensor(sess);
  indices_369->name = "indices_369";
  indices_369->data = params_base + 2211480;
  indices_369->is_const = 1;
  indices_369->dtype = CSINN_DTYPE_INT64;
  indices_369->layout = CSINN_LAYOUT_O;
  indices_369->dim[0] = 1;
  indices_369->dim_count = 1;
  memcpy(indices_369->qinfo, params_base + 2211456, sizeof(struct csinn_quant_info) * 1);
  struct csinn_gather_params *params_369 = csinn_alloc_params(sizeof(struct csinn_gather_params), sess);
  params_369->axis = 2;
  params_369->base.name = "take_/layer_4/layer_4.1/global_rep.3/pre_norm_mha.1/Gather_1_291";
  params_369->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_gather_init(output_363, indices_369, output_369, params_369);
  int32_t *permute_370 = malloc(4 * 4);
  permute_370[0] = 0;
  permute_370[1] = 1;
  permute_370[2] = 3;
  permute_370[3] = 2;
  struct csinn_tensor *output_370 = csinn_alloc_tensor(sess);
  output_370->name = "output_370";
  output_370->dtype = CSINN_DTYPE_FLOAT16;
  output_370->layout = CSINN_LAYOUT_NCHW;
  output_370->dim[0] = 4;
  output_370->dim[1] = 4;
  output_370->dim[2] = 48;
  output_370->dim[3] = 64;
  output_370->dim_count = 4;
  memcpy(output_370->qinfo, params_base + 2211488, sizeof(struct csinn_quant_info) * 1);
  struct csinn_transpose_params *params_370 = csinn_alloc_params(sizeof(struct csinn_transpose_params), sess);
  params_370->permute = permute_370;
  params_370->permute_num = 4;
  params_370->base.name = "transpose_/layer_4/layer_4.1/global_rep.3/pre_norm_mha.1/Transpose_1_292";
  params_370->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_transpose_init(output_369, output_370, params_370);
  struct csinn_tensor *output_371 = csinn_alloc_tensor(sess);
  output_371->name = "output_371";
  output_371->dtype = CSINN_DTYPE_FLOAT16;
  output_371->layout = CSINN_LAYOUT_NCHW;
  output_371->dim[0] = 4;
  output_371->dim[1] = 4;
  output_371->dim[2] = 64;
  output_371->dim[3] = 64;
  output_371->dim_count = 4;
  memcpy(output_371->qinfo, params_base + 2211512, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_371 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_371->trans_a = false;
  params_371->trans_b = false;
  params_371->base.name = "batch_matmul_/layer_4/layer_4.1/global_rep.3/pre_norm_mha.1/MatMul_294";
  params_371->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_366, output_370, output_371, params_371);
  struct csinn_tensor *output_372 = csinn_alloc_tensor(sess);
  output_372->name = "output_372";
  output_372->dtype = CSINN_DTYPE_FLOAT16;
  output_372->layout = CSINN_LAYOUT_NCHW;
  output_372->dim[0] = 4;
  output_372->dim[1] = 4;
  output_372->dim[2] = 64;
  output_372->dim[3] = 64;
  output_372->dim_count = 4;
  memcpy(output_372->qinfo, params_base + 2211536, sizeof(struct csinn_quant_info) * 1);
  struct csinn_softmax_params *params_372 = csinn_alloc_params(sizeof(struct csinn_softmax_params), sess);
  params_372->axis = 3;
  params_372->base.name = "softmax_/layer_4/layer_4.1/global_rep.3/pre_norm_mha.1/softmax/Softmax_296";
  params_372->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_softmax_init(output_371, output_372, params_372);
  struct csinn_tensor *output_374 = csinn_alloc_tensor(sess);
  output_374->name = "output_374";
  output_374->dtype = CSINN_DTYPE_FLOAT16;
  output_374->layout = CSINN_LAYOUT_NCHW;
  output_374->dim[0] = 4;
  output_374->dim[1] = 4;
  output_374->dim[2] = 64;
  output_374->dim[3] = 48;
  output_374->dim_count = 4;
  memcpy(output_374->qinfo, params_base + 2211560, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *indices_374 = csinn_alloc_tensor(sess);
  indices_374->name = "indices_374";
  indices_374->data = params_base + 2211608;
  indices_374->is_const = 1;
  indices_374->dtype = CSINN_DTYPE_INT64;
  indices_374->layout = CSINN_LAYOUT_O;
  indices_374->dim[0] = 1;
  indices_374->dim_count = 1;
  memcpy(indices_374->qinfo, params_base + 2211584, sizeof(struct csinn_quant_info) * 1);
  struct csinn_gather_params *params_374 = csinn_alloc_params(sizeof(struct csinn_gather_params), sess);
  params_374->axis = 2;
  params_374->base.name = "take_/layer_4/layer_4.1/global_rep.3/pre_norm_mha.1/Gather_2_298";
  params_374->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_gather_init(output_363, indices_374, output_374, params_374);
  struct csinn_tensor *output_375 = csinn_alloc_tensor(sess);
  output_375->name = "output_375";
  output_375->dtype = CSINN_DTYPE_FLOAT16;
  output_375->layout = CSINN_LAYOUT_NCHW;
  output_375->dim[0] = 4;
  output_375->dim[1] = 4;
  output_375->dim[2] = 64;
  output_375->dim[3] = 48;
  output_375->dim_count = 4;
  memcpy(output_375->qinfo, params_base + 2211616, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_375 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_375->trans_a = false;
  params_375->trans_b = false;
  params_375->base.name = "batch_matmul_/layer_4/layer_4.1/global_rep.3/pre_norm_mha.1/MatMul_1_300";
  params_375->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_372, output_374, output_375, params_375);
  int32_t *permute_376 = malloc(4 * 4);
  permute_376[0] = 0;
  permute_376[1] = 2;
  permute_376[2] = 1;
  permute_376[3] = 3;
  struct csinn_tensor *output_376 = csinn_alloc_tensor(sess);
  output_376->name = "output_376";
  output_376->dtype = CSINN_DTYPE_FLOAT16;
  output_376->layout = CSINN_LAYOUT_NCHW;
  output_376->dim[0] = 4;
  output_376->dim[1] = 64;
  output_376->dim[2] = 4;
  output_376->dim[3] = 48;
  output_376->dim_count = 4;
  memcpy(output_376->qinfo, params_base + 2211640, sizeof(struct csinn_quant_info) * 1);
  struct csinn_transpose_params *params_376 = csinn_alloc_params(sizeof(struct csinn_transpose_params), sess);
  params_376->permute = permute_376;
  params_376->permute_num = 4;
  params_376->base.name = "transpose_/layer_4/layer_4.1/global_rep.3/pre_norm_mha.1/Transpose_2_302";
  params_376->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_transpose_init(output_375, output_376, params_376);
  int32_t *shape_377 = malloc(3 * 4);
  shape_377[0] = 4;
  shape_377[1] = 64;
  shape_377[2] = -1;
  struct csinn_tensor *output_377 = csinn_alloc_tensor(sess);
  output_377->name = "output_377";
  output_377->dtype = CSINN_DTYPE_FLOAT16;
  output_377->layout = CSINN_LAYOUT_NCW;
  output_377->dim[0] = 4;
  output_377->dim[1] = 64;
  output_377->dim[2] = 192;
  output_377->dim_count = 3;
  memcpy(output_377->qinfo, params_base + 2211664, sizeof(struct csinn_quant_info) * 1);
  struct csinn_reshape_params *params_377 = csinn_alloc_params(sizeof(struct csinn_reshape_params), sess);
  params_377->shape = shape_377;
  params_377->shape_num = 3;
  params_377->base.name = "reshape_/layer_4/layer_4.1/global_rep.3/pre_norm_mha.1/Reshape_1_303";
  params_377->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_reshape_init(output_376, output_377, params_377);
  struct csinn_tensor *output_379 = csinn_alloc_tensor(sess);
  output_379->name = "output_379";
  output_379->dtype = CSINN_DTYPE_FLOAT16;
  output_379->layout = CSINN_LAYOUT_NCW;
  output_379->dim[0] = 4;
  output_379->dim[1] = 64;
  output_379->dim[2] = 192;
  output_379->dim_count = 3;
  memcpy(output_379->qinfo, params_base + 2211688, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *data_b_379 = csinn_alloc_tensor(sess);
  data_b_379->name = "data_b_379";
  data_b_379->data = params_base + 2211736;
  data_b_379->is_const = 1;
  data_b_379->dtype = CSINN_DTYPE_INT8;
  data_b_379->layout = CSINN_LAYOUT_OIW;
  data_b_379->dim[0] = 1;
  data_b_379->dim[1] = 192;
  data_b_379->dim[2] = 192;
  data_b_379->dim_count = 3;
  memcpy(data_b_379->qinfo, params_base + 2211712, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_379 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_379->trans_a = false;
  params_379->trans_b = false;
  params_379->base.name = "batch_matmul_/layer_4/layer_4.1/global_rep.3/pre_norm_mha.1/out_proj/MatMul_304";
  params_379->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_377, data_b_379, output_379, params_379);
  struct csinn_tensor *output_381 = csinn_alloc_tensor(sess);
  output_381->name = "output_381";
  output_381->dtype = CSINN_DTYPE_FLOAT16;
  output_381->layout = CSINN_LAYOUT_NCW;
  output_381->dim[0] = 4;
  output_381->dim[1] = 64;
  output_381->dim[2] = 192;
  output_381->dim_count = 3;
  memcpy(output_381->qinfo, params_base + 2248600, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *rhs_381 = csinn_alloc_tensor(sess);
  rhs_381->name = "rhs_381";
  rhs_381->data = params_base + 2248648;
  rhs_381->is_const = 1;
  rhs_381->dtype = CSINN_DTYPE_FLOAT16;
  rhs_381->layout = CSINN_LAYOUT_OIW;
  rhs_381->dim[0] = 1;
  rhs_381->dim[1] = 1;
  rhs_381->dim[2] = 192;
  rhs_381->dim_count = 3;
  memcpy(rhs_381->qinfo, params_base + 2248624, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_381 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_381->base.name = "add_/layer_4/layer_4.1/global_rep.3/pre_norm_mha.1/out_proj/Add_306";
  params_381->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_379, rhs_381, output_381, params_381);
  struct csinn_tensor *output_384 = csinn_alloc_tensor(sess);
  output_384->name = "output_384";
  output_384->dtype = CSINN_DTYPE_FLOAT16;
  output_384->layout = CSINN_LAYOUT_NCW;
  output_384->dim[0] = 4;
  output_384->dim[1] = 64;
  output_384->dim[2] = 192;
  output_384->dim_count = 3;
  memcpy(output_384->qinfo, params_base + 2249032, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_384 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_384->base.name = "add_/layer_4/layer_4.1/global_rep.3/Add_307";
  params_384->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_381, output_354, output_384, params_384);
  struct csinn_tensor *output_387 = csinn_alloc_tensor(sess);
  output_387->name = "output_387";
  output_387->dtype = CSINN_DTYPE_FLOAT16;
  output_387->layout = CSINN_LAYOUT_NCW;
  output_387->dim[0] = 4;
  output_387->dim[1] = 64;
  output_387->dim[2] = 192;
  output_387->dim_count = 3;
  memcpy(output_387->qinfo, params_base + 2249056, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *gamma_387 = csinn_alloc_tensor(sess);
  gamma_387->name = "gamma_387";
  gamma_387->data = params_base + 2249104;
  gamma_387->is_const = 1;
  gamma_387->dtype = CSINN_DTYPE_FLOAT16;
  gamma_387->layout = CSINN_LAYOUT_O;
  gamma_387->dim[0] = 192;
  gamma_387->dim_count = 1;
  memcpy(gamma_387->qinfo, params_base + 2249080, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *beta_387 = csinn_alloc_tensor(sess);
  beta_387->name = "beta_387";
  beta_387->data = params_base + 2249512;
  beta_387->is_const = 1;
  beta_387->dtype = CSINN_DTYPE_FLOAT16;
  beta_387->layout = CSINN_LAYOUT_O;
  beta_387->dim[0] = 192;
  beta_387->dim_count = 1;
  memcpy(beta_387->qinfo, params_base + 2249488, sizeof(struct csinn_quant_info) * 1);
  struct csinn_layer_norm_params *params_387 = csinn_alloc_params(sizeof(struct csinn_layer_norm_params), sess);
  params_387->epsilon = 1e-05;
  params_387->axis = -1;
  params_387->center = true;
  params_387->scale = true;
  params_387->base.name = "layer_norm_308";
  params_387->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_layer_norm_init(output_384, output_387, gamma_387, beta_387, params_387);
  struct csinn_tensor *output_389 = csinn_alloc_tensor(sess);
  output_389->name = "output_389";
  output_389->dtype = CSINN_DTYPE_FLOAT16;
  output_389->layout = CSINN_LAYOUT_NCW;
  output_389->dim[0] = 4;
  output_389->dim[1] = 64;
  output_389->dim[2] = 384;
  output_389->dim_count = 3;
  memcpy(output_389->qinfo, params_base + 2249896, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *data_b_389 = csinn_alloc_tensor(sess);
  data_b_389->name = "data_b_389";
  data_b_389->data = params_base + 2249944;
  data_b_389->is_const = 1;
  data_b_389->dtype = CSINN_DTYPE_INT8;
  data_b_389->layout = CSINN_LAYOUT_OIW;
  data_b_389->dim[0] = 1;
  data_b_389->dim[1] = 192;
  data_b_389->dim[2] = 384;
  data_b_389->dim_count = 3;
  memcpy(data_b_389->qinfo, params_base + 2249920, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_389 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_389->trans_a = false;
  params_389->trans_b = false;
  params_389->base.name = "batch_matmul_/layer_4/layer_4.1/global_rep.3/pre_norm_ffn/pre_norm_ffn.1/MatMul_309";
  params_389->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_387, data_b_389, output_389, params_389);
  struct csinn_tensor *output_391 = csinn_alloc_tensor(sess);
  output_391->name = "output_391";
  output_391->dtype = CSINN_DTYPE_FLOAT16;
  output_391->layout = CSINN_LAYOUT_NCW;
  output_391->dim[0] = 4;
  output_391->dim[1] = 64;
  output_391->dim[2] = 384;
  output_391->dim_count = 3;
  memcpy(output_391->qinfo, params_base + 2323672, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *rhs_391 = csinn_alloc_tensor(sess);
  rhs_391->name = "rhs_391";
  rhs_391->data = params_base + 2323720;
  rhs_391->is_const = 1;
  rhs_391->dtype = CSINN_DTYPE_FLOAT16;
  rhs_391->layout = CSINN_LAYOUT_OIW;
  rhs_391->dim[0] = 1;
  rhs_391->dim[1] = 1;
  rhs_391->dim[2] = 384;
  rhs_391->dim_count = 3;
  memcpy(rhs_391->qinfo, params_base + 2323696, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_391 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_391->base.name = "add_/layer_4/layer_4.1/global_rep.3/pre_norm_ffn/pre_norm_ffn.1/Add_311";
  params_391->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_389, rhs_391, output_391, params_391);
  struct csinn_tensor *output_394 = csinn_alloc_tensor(sess);
  output_394->name = "output_394";
  output_394->dtype = CSINN_DTYPE_FLOAT16;
  output_394->layout = CSINN_LAYOUT_NCW;
  output_394->dim[0] = 4;
  output_394->dim[1] = 64;
  output_394->dim[2] = 384;
  output_394->dim_count = 3;
  memcpy(output_394->qinfo, params_base + 2324488, sizeof(struct csinn_quant_info) * 1);
  struct csinn_sigmoid_params *params_394 = csinn_alloc_params(sizeof(struct csinn_sigmoid_params), sess);
  params_394->base.name = "sigmoid_/layer_4/layer_4.1/global_rep.3/pre_norm_ffn/pre_norm_ffn.2/Sigmoid_312";
  params_394->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_sigmoid_init(output_391, output_394, params_394);
  struct csinn_tensor *output_395 = csinn_alloc_tensor(sess);
  output_395->name = "output_395";
  output_395->dtype = CSINN_DTYPE_FLOAT16;
  output_395->layout = CSINN_LAYOUT_NCW;
  output_395->dim[0] = 4;
  output_395->dim[1] = 64;
  output_395->dim[2] = 384;
  output_395->dim_count = 3;
  memcpy(output_395->qinfo, params_base + 2324512, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_395 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_395->base.name = "multiply_/layer_4/layer_4.1/global_rep.3/pre_norm_ffn/pre_norm_ffn.2/Mul_313";
  params_395->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_mul_init(output_391, output_394, output_395, params_395);
  struct csinn_tensor *output_398 = csinn_alloc_tensor(sess);
  output_398->name = "output_398";
  output_398->dtype = CSINN_DTYPE_FLOAT16;
  output_398->layout = CSINN_LAYOUT_NCW;
  output_398->dim[0] = 4;
  output_398->dim[1] = 64;
  output_398->dim[2] = 192;
  output_398->dim_count = 3;
  memcpy(output_398->qinfo, params_base + 2324536, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *data_b_398 = csinn_alloc_tensor(sess);
  data_b_398->name = "data_b_398";
  data_b_398->data = params_base + 2324584;
  data_b_398->is_const = 1;
  data_b_398->dtype = CSINN_DTYPE_INT8;
  data_b_398->layout = CSINN_LAYOUT_OIW;
  data_b_398->dim[0] = 1;
  data_b_398->dim[1] = 384;
  data_b_398->dim[2] = 192;
  data_b_398->dim_count = 3;
  memcpy(data_b_398->qinfo, params_base + 2324560, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_398 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_398->trans_a = false;
  params_398->trans_b = false;
  params_398->base.name = "batch_matmul_/layer_4/layer_4.1/global_rep.3/pre_norm_ffn/pre_norm_ffn.4/MatMul_314";
  params_398->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_395, data_b_398, output_398, params_398);
  struct csinn_tensor *output_400 = csinn_alloc_tensor(sess);
  output_400->name = "output_400";
  output_400->dtype = CSINN_DTYPE_FLOAT16;
  output_400->layout = CSINN_LAYOUT_NCW;
  output_400->dim[0] = 4;
  output_400->dim[1] = 64;
  output_400->dim[2] = 192;
  output_400->dim_count = 3;
  memcpy(output_400->qinfo, params_base + 2398312, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *rhs_400 = csinn_alloc_tensor(sess);
  rhs_400->name = "rhs_400";
  rhs_400->data = params_base + 2398360;
  rhs_400->is_const = 1;
  rhs_400->dtype = CSINN_DTYPE_FLOAT16;
  rhs_400->layout = CSINN_LAYOUT_OIW;
  rhs_400->dim[0] = 1;
  rhs_400->dim[1] = 1;
  rhs_400->dim[2] = 192;
  rhs_400->dim_count = 3;
  memcpy(rhs_400->qinfo, params_base + 2398336, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_400 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_400->base.name = "add_/layer_4/layer_4.1/global_rep.3/pre_norm_ffn/pre_norm_ffn.4/Add_316";
  params_400->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_398, rhs_400, output_400, params_400);
  struct csinn_tensor *output_402 = csinn_alloc_tensor(sess);
  output_402->name = "output_402";
  output_402->dtype = CSINN_DTYPE_FLOAT16;
  output_402->layout = CSINN_LAYOUT_NCW;
  output_402->dim[0] = 4;
  output_402->dim[1] = 64;
  output_402->dim[2] = 192;
  output_402->dim_count = 3;
  memcpy(output_402->qinfo, params_base + 2398744, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_402 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_402->base.name = "add_/layer_4/layer_4.1/global_rep.3/Add_1_317";
  params_402->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_384, output_400, output_402, params_402);
  struct csinn_tensor *output_404 = csinn_alloc_tensor(sess);
  output_404->name = "output_404";
  output_404->dtype = CSINN_DTYPE_FLOAT16;
  output_404->layout = CSINN_LAYOUT_NCW;
  output_404->dim[0] = 4;
  output_404->dim[1] = 64;
  output_404->dim[2] = 192;
  output_404->dim_count = 3;
  memcpy(output_404->qinfo, params_base + 2398768, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *gamma_404 = csinn_alloc_tensor(sess);
  gamma_404->name = "gamma_404";
  gamma_404->data = params_base + 2398816;
  gamma_404->is_const = 1;
  gamma_404->dtype = CSINN_DTYPE_FLOAT16;
  gamma_404->layout = CSINN_LAYOUT_O;
  gamma_404->dim[0] = 192;
  gamma_404->dim_count = 1;
  memcpy(gamma_404->qinfo, params_base + 2398792, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *beta_404 = csinn_alloc_tensor(sess);
  beta_404->name = "beta_404";
  beta_404->data = params_base + 2399224;
  beta_404->is_const = 1;
  beta_404->dtype = CSINN_DTYPE_FLOAT16;
  beta_404->layout = CSINN_LAYOUT_O;
  beta_404->dim[0] = 192;
  beta_404->dim_count = 1;
  memcpy(beta_404->qinfo, params_base + 2399200, sizeof(struct csinn_quant_info) * 1);
  struct csinn_layer_norm_params *params_404 = csinn_alloc_params(sizeof(struct csinn_layer_norm_params), sess);
  params_404->epsilon = 1e-05;
  params_404->axis = -1;
  params_404->center = true;
  params_404->scale = true;
  params_404->base.name = "layer_norm_318";
  params_404->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_layer_norm_init(output_402, output_404, gamma_404, beta_404, params_404);
  int32_t *shape_405 = malloc(4 * 4);
  shape_405[0] = 1;
  shape_405[1] = 4;
  shape_405[2] = 64;
  shape_405[3] = -1;
  struct csinn_tensor *output_405 = csinn_alloc_tensor(sess);
  output_405->name = "output_405";
  output_405->dtype = CSINN_DTYPE_FLOAT16;
  output_405->layout = CSINN_LAYOUT_NCHW;
  output_405->dim[0] = 1;
  output_405->dim[1] = 4;
  output_405->dim[2] = 64;
  output_405->dim[3] = 192;
  output_405->dim_count = 4;
  memcpy(output_405->qinfo, params_base + 2399608, sizeof(struct csinn_quant_info) * 1);
  struct csinn_reshape_params *params_405 = csinn_alloc_params(sizeof(struct csinn_reshape_params), sess);
  params_405->shape = shape_405;
  params_405->shape_num = 4;
  params_405->base.name = "reshape_/layer_4/layer_4.1/Reshape_3_319";
  params_405->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_reshape_init(output_404, output_405, params_405);
  int32_t *permute_406 = malloc(4 * 4);
  permute_406[0] = 0;
  permute_406[1] = 3;
  permute_406[2] = 2;
  permute_406[3] = 1;
  struct csinn_tensor *output_406 = csinn_alloc_tensor(sess);
  output_406->name = "output_406";
  output_406->dtype = CSINN_DTYPE_FLOAT16;
  output_406->layout = CSINN_LAYOUT_NCHW;
  output_406->dim[0] = 1;
  output_406->dim[1] = 192;
  output_406->dim[2] = 64;
  output_406->dim[3] = 4;
  output_406->dim_count = 4;
  memcpy(output_406->qinfo, params_base + 2399632, sizeof(struct csinn_quant_info) * 1);
  struct csinn_transpose_params *params_406 = csinn_alloc_params(sizeof(struct csinn_transpose_params), sess);
  params_406->permute = permute_406;
  params_406->permute_num = 4;
  params_406->base.name = "transpose_/layer_4/layer_4.1/Transpose_2_320";
  params_406->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_transpose_init(output_405, output_406, params_406);
  int32_t *shape_407 = malloc(4 * 4);
  shape_407[0] = 1536;
  shape_407[1] = 8;
  shape_407[2] = 2;
  shape_407[3] = 2;
  struct csinn_tensor *output_407 = csinn_alloc_tensor(sess);
  output_407->name = "output_407";
  output_407->dtype = CSINN_DTYPE_FLOAT16;
  output_407->layout = CSINN_LAYOUT_NCHW;
  output_407->dim[0] = 1536;
  output_407->dim[1] = 8;
  output_407->dim[2] = 2;
  output_407->dim[3] = 2;
  output_407->dim_count = 4;
  memcpy(output_407->qinfo, params_base + 2399656, sizeof(struct csinn_quant_info) * 1);
  struct csinn_reshape_params *params_407 = csinn_alloc_params(sizeof(struct csinn_reshape_params), sess);
  params_407->shape = shape_407;
  params_407->shape_num = 4;
  params_407->base.name = "reshape_/layer_4/layer_4.1/Reshape_4_321";
  params_407->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_reshape_init(output_406, output_407, params_407);
  int32_t *permute_408 = malloc(4 * 4);
  permute_408[0] = 0;
  permute_408[1] = 2;
  permute_408[2] = 1;
  permute_408[3] = 3;
  struct csinn_tensor *output_408 = csinn_alloc_tensor(sess);
  output_408->name = "output_408";
  output_408->dtype = CSINN_DTYPE_FLOAT16;
  output_408->layout = CSINN_LAYOUT_NCHW;
  output_408->dim[0] = 1536;
  output_408->dim[1] = 2;
  output_408->dim[2] = 8;
  output_408->dim[3] = 2;
  output_408->dim_count = 4;
  memcpy(output_408->qinfo, params_base + 2399680, sizeof(struct csinn_quant_info) * 1);
  struct csinn_transpose_params *params_408 = csinn_alloc_params(sizeof(struct csinn_transpose_params), sess);
  params_408->permute = permute_408;
  params_408->permute_num = 4;
  params_408->base.name = "transpose_/layer_4/layer_4.1/Transpose_3_322";
  params_408->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_transpose_init(output_407, output_408, params_408);
  int32_t *shape_409 = malloc(4 * 4);
  shape_409[0] = 1;
  shape_409[1] = 192;
  shape_409[2] = 16;
  shape_409[3] = 16;
  struct csinn_tensor *output_409 = csinn_alloc_tensor(sess);
  output_409->name = "output_409";
  output_409->dtype = CSINN_DTYPE_FLOAT16;
  output_409->layout = CSINN_LAYOUT_NCHW;
  output_409->dim[0] = 1;
  output_409->dim[1] = 192;
  output_409->dim[2] = 16;
  output_409->dim[3] = 16;
  output_409->dim_count = 4;
  memcpy(output_409->qinfo, params_base + 2399704, sizeof(struct csinn_quant_info) * 1);
  struct csinn_reshape_params *params_409 = csinn_alloc_params(sizeof(struct csinn_reshape_params), sess);
  params_409->shape = shape_409;
  params_409->shape_num = 4;
  params_409->base.name = "reshape_/layer_4/layer_4.1/Reshape_5_323";
  params_409->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_reshape_init(output_408, output_409, params_409);
  struct csinn_tensor *output_410 = csinn_alloc_tensor(sess);
  output_410->name = "output_410";
  output_410->dtype = CSINN_DTYPE_FLOAT16;
  output_410->layout = CSINN_LAYOUT_NCHW;
  output_410->dim[0] = 1;
  output_410->dim[1] = 128;
  output_410->dim[2] = 16;
  output_410->dim[3] = 16;
  output_410->dim_count = 4;
  memcpy(output_410->qinfo, params_base + 2399728, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_410 = csinn_alloc_tensor(sess);
  kernel_410->name = "kernel_410";
  kernel_410->data = params_base + 2402824;
  kernel_410->is_const = 1;
  kernel_410->dtype = CSINN_DTYPE_INT8;
  kernel_410->layout = CSINN_LAYOUT_OIHW;
  kernel_410->dim[0] = 128;
  kernel_410->dim[1] = 192;
  kernel_410->dim[2] = 1;
  kernel_410->dim[3] = 1;
  kernel_410->dim_count = 4;
  csinn_realloc_quant_info(kernel_410, 128);
  memcpy(kernel_410->qinfo, params_base + 2399752, sizeof(struct csinn_quant_info) * 128);
  struct csinn_tensor *bias_410 = csinn_alloc_tensor(sess);
  bias_410->name = "bias_410";
  bias_410->data = params_base + 2430472;
  bias_410->is_const = 1;
  bias_410->dtype = CSINN_DTYPE_FLOAT16;
  bias_410->layout = CSINN_LAYOUT_O;
  bias_410->dim[0] = 128;
  bias_410->dim_count = 1;
  csinn_realloc_quant_info(bias_410, 128);
  memcpy(bias_410->qinfo, params_base + 2427400, sizeof(struct csinn_quant_info) * 128);
  struct csinn_conv2d_params *params_410 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_410->group = 1;
  params_410->stride_height = 1;
  params_410->stride_width = 1;
  params_410->dilation_height = 1;
  params_410->dilation_width = 1;
  params_410->conv_extra.kernel_tm = NULL;
  params_410->conv_extra.conv_mode = CSINN_DIRECT;
  params_410->pad_top = 0;
  params_410->pad_left = 0;
  params_410->pad_down = 0;
  params_410->pad_right = 0;
  params_410->base.name = "conv2d_/layer_4/layer_4.1/conv_proj/block/conv/Conv_324_fuse_bias_add_/layer_4/layer_4.1/conv_proj/block/conv/Conv_325";
  params_410->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_409, output_410, kernel_410, bias_410, params_410);
  struct csinn_tensor *output_412 = csinn_alloc_tensor(sess);
  output_412->name = "output_412";
  output_412->dtype = CSINN_DTYPE_FLOAT16;
  output_412->layout = CSINN_LAYOUT_NCHW;
  output_412->dim[0] = 1;
  output_412->dim[1] = 128;
  output_412->dim[2] = 16;
  output_412->dim[3] = 16;
  output_412->dim_count = 4;
  memcpy(output_412->qinfo, params_base + 2430728, sizeof(struct csinn_quant_info) * 1);
  struct csinn_sigmoid_params *params_412 = csinn_alloc_params(sizeof(struct csinn_sigmoid_params), sess);
  params_412->base.name = "sigmoid_/layer_4/layer_4.1/conv_proj/block/act/Sigmoid_326";
  params_412->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_sigmoid_init(output_410, output_412, params_412);
  struct csinn_tensor *output_413 = csinn_alloc_tensor(sess);
  output_413->name = "output_413";
  output_413->dtype = CSINN_DTYPE_FLOAT16;
  output_413->layout = CSINN_LAYOUT_NCHW;
  output_413->dim[0] = 1;
  output_413->dim[1] = 128;
  output_413->dim[2] = 16;
  output_413->dim[3] = 16;
  output_413->dim_count = 4;
  memcpy(output_413->qinfo, params_base + 2430752, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_413 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_413->base.name = "multiply_/layer_4/layer_4.1/conv_proj/block/act/Mul_327";
  params_413->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_mul_init(output_410, output_412, output_413, params_413);
  struct csinn_tensor *input_415_concat[2];
  struct csinn_tensor *output_415 = csinn_alloc_tensor(sess);
  output_415->name = "output_415";
  output_415->dtype = CSINN_DTYPE_FLOAT16;
  output_415->layout = CSINN_LAYOUT_NCHW;
  output_415->dim[0] = 1;
  output_415->dim[1] = 256;
  output_415->dim[2] = 16;
  output_415->dim[3] = 16;
  output_415->dim_count = 4;
  memcpy(output_415->qinfo, params_base + 2430776, sizeof(struct csinn_quant_info) * 1);
  struct csinn_concat_params *params_415 = csinn_alloc_params(sizeof(struct csinn_concat_params), sess);
  params_415->inputs_count = 2;
  params_415->axis = 1;
  params_415->base.name = "concatenate_/layer_4/layer_4.1/Concat_328";
  params_415->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_concat_init(input_415_concat, output_415, params_415);
  struct csinn_tensor *output_416 = csinn_alloc_tensor(sess);
  output_416->name = "output_416";
  output_416->dtype = CSINN_DTYPE_FLOAT16;
  output_416->layout = CSINN_LAYOUT_NCHW;
  output_416->dim[0] = 1;
  output_416->dim[1] = 128;
  output_416->dim[2] = 16;
  output_416->dim[3] = 16;
  output_416->dim_count = 4;
  memcpy(output_416->qinfo, params_base + 2430800, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_416 = csinn_alloc_tensor(sess);
  kernel_416->name = "kernel_416";
  kernel_416->data = params_base + 2433896;
  kernel_416->is_const = 1;
  kernel_416->dtype = CSINN_DTYPE_INT8;
  kernel_416->layout = CSINN_LAYOUT_OIHW;
  kernel_416->dim[0] = 128;
  kernel_416->dim[1] = 256;
  kernel_416->dim[2] = 3;
  kernel_416->dim[3] = 3;
  kernel_416->dim_count = 4;
  csinn_realloc_quant_info(kernel_416, 128);
  memcpy(kernel_416->qinfo, params_base + 2430824, sizeof(struct csinn_quant_info) * 128);
  struct csinn_tensor *bias_416 = csinn_alloc_tensor(sess);
  bias_416->name = "bias_416";
  bias_416->data = params_base + 2731880;
  bias_416->is_const = 1;
  bias_416->dtype = CSINN_DTYPE_FLOAT16;
  bias_416->layout = CSINN_LAYOUT_O;
  bias_416->dim[0] = 128;
  bias_416->dim_count = 1;
  csinn_realloc_quant_info(bias_416, 128);
  memcpy(bias_416->qinfo, params_base + 2728808, sizeof(struct csinn_quant_info) * 128);
  struct csinn_conv2d_params *params_416 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_416->group = 1;
  params_416->stride_height = 1;
  params_416->stride_width = 1;
  params_416->dilation_height = 1;
  params_416->dilation_width = 1;
  params_416->conv_extra.kernel_tm = NULL;
  params_416->conv_extra.conv_mode = CSINN_DIRECT;
  params_416->pad_top = 1;
  params_416->pad_left = 1;
  params_416->pad_down = 1;
  params_416->pad_right = 1;
  params_416->base.name = "conv2d_/layer_4/layer_4.1/fusion/block/conv/Conv_329_fuse_bias_add_/layer_4/layer_4.1/fusion/block/conv/Conv_330";
  params_416->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_415, output_416, kernel_416, bias_416, params_416);
  struct csinn_tensor *output_418 = csinn_alloc_tensor(sess);
  output_418->name = "output_418";
  output_418->dtype = CSINN_DTYPE_FLOAT16;
  output_418->layout = CSINN_LAYOUT_NCHW;
  output_418->dim[0] = 1;
  output_418->dim[1] = 128;
  output_418->dim[2] = 16;
  output_418->dim[3] = 16;
  output_418->dim_count = 4;
  memcpy(output_418->qinfo, params_base + 2732136, sizeof(struct csinn_quant_info) * 1);
  struct csinn_sigmoid_params *params_418 = csinn_alloc_params(sizeof(struct csinn_sigmoid_params), sess);
  params_418->base.name = "sigmoid_/layer_4/layer_4.1/fusion/block/act/Sigmoid_331";
  params_418->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_sigmoid_init(output_416, output_418, params_418);
  struct csinn_tensor *output_419 = csinn_alloc_tensor(sess);
  output_419->name = "output_419";
  output_419->dtype = CSINN_DTYPE_FLOAT16;
  output_419->layout = CSINN_LAYOUT_NCHW;
  output_419->dim[0] = 1;
  output_419->dim[1] = 128;
  output_419->dim[2] = 16;
  output_419->dim[3] = 16;
  output_419->dim_count = 4;
  memcpy(output_419->qinfo, params_base + 2732160, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_419 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_419->base.name = "multiply_/layer_4/layer_4.1/fusion/block/act/Mul_332";
  params_419->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_mul_init(output_416, output_418, output_419, params_419);
  struct csinn_tensor *output_421 = csinn_alloc_tensor(sess);
  output_421->name = "output_421";
  output_421->dtype = CSINN_DTYPE_FLOAT16;
  output_421->layout = CSINN_LAYOUT_NCHW;
  output_421->dim[0] = 1;
  output_421->dim[1] = 512;
  output_421->dim[2] = 16;
  output_421->dim[3] = 16;
  output_421->dim_count = 4;
  memcpy(output_421->qinfo, params_base + 2732184, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_421 = csinn_alloc_tensor(sess);
  kernel_421->name = "kernel_421";
  kernel_421->data = params_base + 2744496;
  kernel_421->is_const = 1;
  kernel_421->dtype = CSINN_DTYPE_INT8;
  kernel_421->layout = CSINN_LAYOUT_OIHW;
  kernel_421->dim[0] = 512;
  kernel_421->dim[1] = 128;
  kernel_421->dim[2] = 1;
  kernel_421->dim[3] = 1;
  kernel_421->dim_count = 4;
  csinn_realloc_quant_info(kernel_421, 512);
  memcpy(kernel_421->qinfo, params_base + 2732208, sizeof(struct csinn_quant_info) * 512);
  struct csinn_tensor *bias_421 = csinn_alloc_tensor(sess);
  bias_421->name = "bias_421";
  bias_421->data = params_base + 2822320;
  bias_421->is_const = 1;
  bias_421->dtype = CSINN_DTYPE_FLOAT16;
  bias_421->layout = CSINN_LAYOUT_O;
  bias_421->dim[0] = 512;
  bias_421->dim_count = 1;
  csinn_realloc_quant_info(bias_421, 512);
  memcpy(bias_421->qinfo, params_base + 2810032, sizeof(struct csinn_quant_info) * 512);
  struct csinn_conv2d_params *params_421 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_421->group = 1;
  params_421->stride_height = 1;
  params_421->stride_width = 1;
  params_421->dilation_height = 1;
  params_421->dilation_width = 1;
  params_421->conv_extra.kernel_tm = NULL;
  params_421->conv_extra.conv_mode = CSINN_DIRECT;
  params_421->pad_top = 0;
  params_421->pad_left = 0;
  params_421->pad_down = 0;
  params_421->pad_right = 0;
  params_421->base.name = "conv2d_/layer_5/layer_5.0/block/exp_1x1/block/conv/Conv_333_fuse_bias_add_/layer_5/layer_5.0/block/exp_1x1/block/conv/Conv_334";
  params_421->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_419, output_421, kernel_421, bias_421, params_421);
  struct csinn_tensor *output_423 = csinn_alloc_tensor(sess);
  output_423->name = "output_423";
  output_423->dtype = CSINN_DTYPE_FLOAT16;
  output_423->layout = CSINN_LAYOUT_NCHW;
  output_423->dim[0] = 1;
  output_423->dim[1] = 512;
  output_423->dim[2] = 16;
  output_423->dim[3] = 16;
  output_423->dim_count = 4;
  memcpy(output_423->qinfo, params_base + 2823344, sizeof(struct csinn_quant_info) * 1);
  struct csinn_sigmoid_params *params_423 = csinn_alloc_params(sizeof(struct csinn_sigmoid_params), sess);
  params_423->base.name = "sigmoid_/layer_5/layer_5.0/block/exp_1x1/block/act/Sigmoid_335";
  params_423->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_sigmoid_init(output_421, output_423, params_423);
  struct csinn_tensor *output_424 = csinn_alloc_tensor(sess);
  output_424->name = "output_424";
  output_424->dtype = CSINN_DTYPE_FLOAT16;
  output_424->layout = CSINN_LAYOUT_NCHW;
  output_424->dim[0] = 1;
  output_424->dim[1] = 512;
  output_424->dim[2] = 16;
  output_424->dim[3] = 16;
  output_424->dim_count = 4;
  memcpy(output_424->qinfo, params_base + 2823368, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_424 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_424->base.name = "multiply_/layer_5/layer_5.0/block/exp_1x1/block/act/Mul_336";
  params_424->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_mul_init(output_421, output_423, output_424, params_424);
  struct csinn_tensor *output_426 = csinn_alloc_tensor(sess);
  output_426->name = "output_426";
  output_426->dtype = CSINN_DTYPE_FLOAT16;
  output_426->layout = CSINN_LAYOUT_NCHW;
  output_426->dim[0] = 1;
  output_426->dim[1] = 512;
  output_426->dim[2] = 8;
  output_426->dim[3] = 8;
  output_426->dim_count = 4;
  memcpy(output_426->qinfo, params_base + 2823392, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_426 = csinn_alloc_tensor(sess);
  kernel_426->name = "kernel_426";
  kernel_426->data = params_base + 2835704;
  kernel_426->is_const = 1;
  kernel_426->dtype = CSINN_DTYPE_INT8;
  kernel_426->layout = CSINN_LAYOUT_OIHW;
  kernel_426->dim[0] = 512;
  kernel_426->dim[1] = 1;
  kernel_426->dim[2] = 3;
  kernel_426->dim[3] = 3;
  kernel_426->dim_count = 4;
  csinn_realloc_quant_info(kernel_426, 512);
  memcpy(kernel_426->qinfo, params_base + 2823416, sizeof(struct csinn_quant_info) * 512);
  struct csinn_tensor *bias_426 = csinn_alloc_tensor(sess);
  bias_426->name = "bias_426";
  bias_426->data = params_base + 2852600;
  bias_426->is_const = 1;
  bias_426->dtype = CSINN_DTYPE_FLOAT16;
  bias_426->layout = CSINN_LAYOUT_O;
  bias_426->dim[0] = 512;
  bias_426->dim_count = 1;
  csinn_realloc_quant_info(bias_426, 512);
  memcpy(bias_426->qinfo, params_base + 2840312, sizeof(struct csinn_quant_info) * 512);
  struct csinn_conv2d_params *params_426 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_426->group = 512;
  params_426->stride_height = 2;
  params_426->stride_width = 2;
  params_426->dilation_height = 1;
  params_426->dilation_width = 1;
  params_426->conv_extra.kernel_tm = NULL;
  params_426->conv_extra.conv_mode = CSINN_DIRECT;
  params_426->pad_top = 1;
  params_426->pad_left = 1;
  params_426->pad_down = 1;
  params_426->pad_right = 1;
  params_426->base.name = "conv2d_/layer_5/layer_5.0/block/conv_3x3/block/conv/Conv_337_fuse_bias_add_/layer_5/layer_5.0/block/conv_3x3/block/conv/Conv_338";
  params_426->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_424, output_426, kernel_426, bias_426, params_426);
  struct csinn_tensor *output_428 = csinn_alloc_tensor(sess);
  output_428->name = "output_428";
  output_428->dtype = CSINN_DTYPE_FLOAT16;
  output_428->layout = CSINN_LAYOUT_NCHW;
  output_428->dim[0] = 1;
  output_428->dim[1] = 512;
  output_428->dim[2] = 8;
  output_428->dim[3] = 8;
  output_428->dim_count = 4;
  memcpy(output_428->qinfo, params_base + 2853624, sizeof(struct csinn_quant_info) * 1);
  struct csinn_sigmoid_params *params_428 = csinn_alloc_params(sizeof(struct csinn_sigmoid_params), sess);
  params_428->base.name = "sigmoid_/layer_5/layer_5.0/block/conv_3x3/block/act/Sigmoid_339";
  params_428->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_sigmoid_init(output_426, output_428, params_428);
  struct csinn_tensor *output_429 = csinn_alloc_tensor(sess);
  output_429->name = "output_429";
  output_429->dtype = CSINN_DTYPE_FLOAT16;
  output_429->layout = CSINN_LAYOUT_NCHW;
  output_429->dim[0] = 1;
  output_429->dim[1] = 512;
  output_429->dim[2] = 8;
  output_429->dim[3] = 8;
  output_429->dim_count = 4;
  memcpy(output_429->qinfo, params_base + 2853648, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_429 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_429->base.name = "multiply_/layer_5/layer_5.0/block/conv_3x3/block/act/Mul_340";
  params_429->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_mul_init(output_426, output_428, output_429, params_429);
  struct csinn_tensor *output_431 = csinn_alloc_tensor(sess);
  output_431->name = "output_431";
  output_431->dtype = CSINN_DTYPE_FLOAT16;
  output_431->layout = CSINN_LAYOUT_NCHW;
  output_431->dim[0] = 1;
  output_431->dim[1] = 160;
  output_431->dim[2] = 8;
  output_431->dim[3] = 8;
  output_431->dim_count = 4;
  memcpy(output_431->qinfo, params_base + 2853672, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_431 = csinn_alloc_tensor(sess);
  kernel_431->name = "kernel_431";
  kernel_431->data = params_base + 2857536;
  kernel_431->is_const = 1;
  kernel_431->dtype = CSINN_DTYPE_INT8;
  kernel_431->layout = CSINN_LAYOUT_OIHW;
  kernel_431->dim[0] = 160;
  kernel_431->dim[1] = 512;
  kernel_431->dim[2] = 1;
  kernel_431->dim[3] = 1;
  kernel_431->dim_count = 4;
  csinn_realloc_quant_info(kernel_431, 160);
  memcpy(kernel_431->qinfo, params_base + 2853696, sizeof(struct csinn_quant_info) * 160);
  struct csinn_tensor *bias_431 = csinn_alloc_tensor(sess);
  bias_431->name = "bias_431";
  bias_431->data = params_base + 2943296;
  bias_431->is_const = 1;
  bias_431->dtype = CSINN_DTYPE_FLOAT16;
  bias_431->layout = CSINN_LAYOUT_O;
  bias_431->dim[0] = 160;
  bias_431->dim_count = 1;
  csinn_realloc_quant_info(bias_431, 160);
  memcpy(bias_431->qinfo, params_base + 2939456, sizeof(struct csinn_quant_info) * 160);
  struct csinn_conv2d_params *params_431 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_431->group = 1;
  params_431->stride_height = 1;
  params_431->stride_width = 1;
  params_431->dilation_height = 1;
  params_431->dilation_width = 1;
  params_431->conv_extra.kernel_tm = NULL;
  params_431->conv_extra.conv_mode = CSINN_DIRECT;
  params_431->pad_top = 0;
  params_431->pad_left = 0;
  params_431->pad_down = 0;
  params_431->pad_right = 0;
  params_431->base.name = "conv2d_/layer_5/layer_5.0/block/red_1x1/block/conv/Conv_341_fuse_bias_add_/layer_5/layer_5.0/block/red_1x1/block/conv/Conv_342";
  params_431->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_429, output_431, kernel_431, bias_431, params_431);
  struct csinn_tensor *output_432 = csinn_alloc_tensor(sess);
  output_432->name = "output_432";
  output_432->dtype = CSINN_DTYPE_FLOAT16;
  output_432->layout = CSINN_LAYOUT_NCHW;
  output_432->dim[0] = 1;
  output_432->dim[1] = 160;
  output_432->dim[2] = 8;
  output_432->dim[3] = 8;
  output_432->dim_count = 4;
  memcpy(output_432->qinfo, params_base + 2943616, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_432 = csinn_alloc_tensor(sess);
  kernel_432->name = "kernel_432";
  kernel_432->data = params_base + 2947480;
  kernel_432->is_const = 1;
  kernel_432->dtype = CSINN_DTYPE_INT8;
  kernel_432->layout = CSINN_LAYOUT_OIHW;
  kernel_432->dim[0] = 160;
  kernel_432->dim[1] = 160;
  kernel_432->dim[2] = 3;
  kernel_432->dim[3] = 3;
  kernel_432->dim_count = 4;
  csinn_realloc_quant_info(kernel_432, 160);
  memcpy(kernel_432->qinfo, params_base + 2943640, sizeof(struct csinn_quant_info) * 160);
  struct csinn_tensor *bias_432 = csinn_alloc_tensor(sess);
  bias_432->name = "bias_432";
  bias_432->data = params_base + 3181720;
  bias_432->is_const = 1;
  bias_432->dtype = CSINN_DTYPE_FLOAT16;
  bias_432->layout = CSINN_LAYOUT_O;
  bias_432->dim[0] = 160;
  bias_432->dim_count = 1;
  csinn_realloc_quant_info(bias_432, 160);
  memcpy(bias_432->qinfo, params_base + 3177880, sizeof(struct csinn_quant_info) * 160);
  struct csinn_conv2d_params *params_432 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_432->group = 1;
  params_432->stride_height = 1;
  params_432->stride_width = 1;
  params_432->dilation_height = 1;
  params_432->dilation_width = 1;
  params_432->conv_extra.kernel_tm = NULL;
  params_432->conv_extra.conv_mode = CSINN_DIRECT;
  params_432->pad_top = 1;
  params_432->pad_left = 1;
  params_432->pad_down = 1;
  params_432->pad_right = 1;
  params_432->base.name = "conv2d_/layer_5/layer_5.1/local_rep/conv_3x3/block/conv/Conv_343_fuse_bias_add_/layer_5/layer_5.1/local_rep/conv_3x3/block/conv/Conv_344";
  params_432->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_431, output_432, kernel_432, bias_432, params_432);
  struct csinn_tensor *output_434 = csinn_alloc_tensor(sess);
  output_434->name = "output_434";
  output_434->dtype = CSINN_DTYPE_FLOAT16;
  output_434->layout = CSINN_LAYOUT_NCHW;
  output_434->dim[0] = 1;
  output_434->dim[1] = 160;
  output_434->dim[2] = 8;
  output_434->dim[3] = 8;
  output_434->dim_count = 4;
  memcpy(output_434->qinfo, params_base + 3182040, sizeof(struct csinn_quant_info) * 1);
  struct csinn_sigmoid_params *params_434 = csinn_alloc_params(sizeof(struct csinn_sigmoid_params), sess);
  params_434->base.name = "sigmoid_/layer_5/layer_5.1/local_rep/conv_3x3/block/act/Sigmoid_345";
  params_434->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_sigmoid_init(output_432, output_434, params_434);
  struct csinn_tensor *output_435 = csinn_alloc_tensor(sess);
  output_435->name = "output_435";
  output_435->dtype = CSINN_DTYPE_FLOAT16;
  output_435->layout = CSINN_LAYOUT_NCHW;
  output_435->dim[0] = 1;
  output_435->dim[1] = 160;
  output_435->dim[2] = 8;
  output_435->dim[3] = 8;
  output_435->dim_count = 4;
  memcpy(output_435->qinfo, params_base + 3182064, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_435 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_435->base.name = "multiply_/layer_5/layer_5.1/local_rep/conv_3x3/block/act/Mul_346";
  params_435->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_mul_init(output_432, output_434, output_435, params_435);
  struct csinn_tensor *bias_437 = csinn_alloc_tensor(sess);
  bias_437->data = NULL;
  bias_437->name = "bias_437";
  bias_437->is_const = 1;
  bias_437->dim_count = 0;
  struct csinn_tensor *output_437 = csinn_alloc_tensor(sess);
  output_437->name = "output_437";
  output_437->dtype = CSINN_DTYPE_FLOAT16;
  output_437->layout = CSINN_LAYOUT_NCHW;
  output_437->dim[0] = 1;
  output_437->dim[1] = 240;
  output_437->dim[2] = 8;
  output_437->dim[3] = 8;
  output_437->dim_count = 4;
  memcpy(output_437->qinfo, params_base + 3182088, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_437 = csinn_alloc_tensor(sess);
  kernel_437->name = "kernel_437";
  kernel_437->data = params_base + 3187872;
  kernel_437->is_const = 1;
  kernel_437->dtype = CSINN_DTYPE_INT8;
  kernel_437->layout = CSINN_LAYOUT_OIHW;
  kernel_437->dim[0] = 240;
  kernel_437->dim[1] = 160;
  kernel_437->dim[2] = 1;
  kernel_437->dim[3] = 1;
  kernel_437->dim_count = 4;
  csinn_realloc_quant_info(kernel_437, 240);
  memcpy(kernel_437->qinfo, params_base + 3182112, sizeof(struct csinn_quant_info) * 240);
  struct csinn_conv2d_params *params_437 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_437->group = 1;
  params_437->stride_height = 1;
  params_437->stride_width = 1;
  params_437->dilation_height = 1;
  params_437->dilation_width = 1;
  params_437->conv_extra.kernel_tm = NULL;
  params_437->conv_extra.conv_mode = CSINN_DIRECT;
  params_437->pad_top = 0;
  params_437->pad_left = 0;
  params_437->pad_down = 0;
  params_437->pad_right = 0;
  params_437->base.name = "conv2d_/layer_5/layer_5.1/local_rep/conv_1x1/block/conv/Conv_347";
  params_437->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_435, output_437, kernel_437, bias_437, params_437);
  int32_t *shape_438 = malloc(4 * 4);
  shape_438[0] = 960;
  shape_438[1] = 2;
  shape_438[2] = 4;
  shape_438[3] = 2;
  struct csinn_tensor *output_438 = csinn_alloc_tensor(sess);
  output_438->name = "output_438";
  output_438->dtype = CSINN_DTYPE_FLOAT16;
  output_438->layout = CSINN_LAYOUT_NCHW;
  output_438->dim[0] = 960;
  output_438->dim[1] = 2;
  output_438->dim[2] = 4;
  output_438->dim[3] = 2;
  output_438->dim_count = 4;
  memcpy(output_438->qinfo, params_base + 3226272, sizeof(struct csinn_quant_info) * 1);
  struct csinn_reshape_params *params_438 = csinn_alloc_params(sizeof(struct csinn_reshape_params), sess);
  params_438->shape = shape_438;
  params_438->shape_num = 4;
  params_438->base.name = "reshape_/layer_5/layer_5.1/Reshape_348";
  params_438->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_reshape_init(output_437, output_438, params_438);
  int32_t *permute_439 = malloc(4 * 4);
  permute_439[0] = 0;
  permute_439[1] = 2;
  permute_439[2] = 1;
  permute_439[3] = 3;
  struct csinn_tensor *output_439 = csinn_alloc_tensor(sess);
  output_439->name = "output_439";
  output_439->dtype = CSINN_DTYPE_FLOAT16;
  output_439->layout = CSINN_LAYOUT_NCHW;
  output_439->dim[0] = 960;
  output_439->dim[1] = 4;
  output_439->dim[2] = 2;
  output_439->dim[3] = 2;
  output_439->dim_count = 4;
  memcpy(output_439->qinfo, params_base + 3226296, sizeof(struct csinn_quant_info) * 1);
  struct csinn_transpose_params *params_439 = csinn_alloc_params(sizeof(struct csinn_transpose_params), sess);
  params_439->permute = permute_439;
  params_439->permute_num = 4;
  params_439->base.name = "transpose_/layer_5/layer_5.1/Transpose_349";
  params_439->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_transpose_init(output_438, output_439, params_439);
  int32_t *shape_440 = malloc(4 * 4);
  shape_440[0] = 1;
  shape_440[1] = 240;
  shape_440[2] = 16;
  shape_440[3] = 4;
  struct csinn_tensor *output_440 = csinn_alloc_tensor(sess);
  output_440->name = "output_440";
  output_440->dtype = CSINN_DTYPE_FLOAT16;
  output_440->layout = CSINN_LAYOUT_NCHW;
  output_440->dim[0] = 1;
  output_440->dim[1] = 240;
  output_440->dim[2] = 16;
  output_440->dim[3] = 4;
  output_440->dim_count = 4;
  memcpy(output_440->qinfo, params_base + 3226320, sizeof(struct csinn_quant_info) * 1);
  struct csinn_reshape_params *params_440 = csinn_alloc_params(sizeof(struct csinn_reshape_params), sess);
  params_440->shape = shape_440;
  params_440->shape_num = 4;
  params_440->base.name = "reshape_/layer_5/layer_5.1/Reshape_1_350";
  params_440->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_reshape_init(output_439, output_440, params_440);
  int32_t *permute_441 = malloc(4 * 4);
  permute_441[0] = 0;
  permute_441[1] = 3;
  permute_441[2] = 2;
  permute_441[3] = 1;
  struct csinn_tensor *output_441 = csinn_alloc_tensor(sess);
  output_441->name = "output_441";
  output_441->dtype = CSINN_DTYPE_FLOAT16;
  output_441->layout = CSINN_LAYOUT_NCHW;
  output_441->dim[0] = 1;
  output_441->dim[1] = 4;
  output_441->dim[2] = 16;
  output_441->dim[3] = 240;
  output_441->dim_count = 4;
  memcpy(output_441->qinfo, params_base + 3226344, sizeof(struct csinn_quant_info) * 1);
  struct csinn_transpose_params *params_441 = csinn_alloc_params(sizeof(struct csinn_transpose_params), sess);
  params_441->permute = permute_441;
  params_441->permute_num = 4;
  params_441->base.name = "transpose_/layer_5/layer_5.1/Transpose_1_351";
  params_441->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_transpose_init(output_440, output_441, params_441);
  int32_t *shape_442 = malloc(3 * 4);
  shape_442[0] = 4;
  shape_442[1] = 16;
  shape_442[2] = -1;
  struct csinn_tensor *output_442 = csinn_alloc_tensor(sess);
  output_442->name = "output_442";
  output_442->dtype = CSINN_DTYPE_FLOAT16;
  output_442->layout = CSINN_LAYOUT_NCW;
  output_442->dim[0] = 4;
  output_442->dim[1] = 16;
  output_442->dim[2] = 240;
  output_442->dim_count = 3;
  memcpy(output_442->qinfo, params_base + 3226368, sizeof(struct csinn_quant_info) * 1);
  struct csinn_reshape_params *params_442 = csinn_alloc_params(sizeof(struct csinn_reshape_params), sess);
  params_442->shape = shape_442;
  params_442->shape_num = 3;
  params_442->base.name = "reshape_/layer_5/layer_5.1/Reshape_2_352";
  params_442->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_reshape_init(output_441, output_442, params_442);
  struct csinn_tensor *output_443 = csinn_alloc_tensor(sess);
  output_443->name = "output_443";
  output_443->dtype = CSINN_DTYPE_FLOAT16;
  output_443->layout = CSINN_LAYOUT_NCW;
  output_443->dim[0] = 4;
  output_443->dim[1] = 16;
  output_443->dim[2] = 240;
  output_443->dim_count = 3;
  memcpy(output_443->qinfo, params_base + 3226392, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *gamma_443 = csinn_alloc_tensor(sess);
  gamma_443->name = "gamma_443";
  gamma_443->data = params_base + 3226440;
  gamma_443->is_const = 1;
  gamma_443->dtype = CSINN_DTYPE_FLOAT16;
  gamma_443->layout = CSINN_LAYOUT_O;
  gamma_443->dim[0] = 240;
  gamma_443->dim_count = 1;
  memcpy(gamma_443->qinfo, params_base + 3226416, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *beta_443 = csinn_alloc_tensor(sess);
  beta_443->name = "beta_443";
  beta_443->data = params_base + 3226944;
  beta_443->is_const = 1;
  beta_443->dtype = CSINN_DTYPE_FLOAT16;
  beta_443->layout = CSINN_LAYOUT_O;
  beta_443->dim[0] = 240;
  beta_443->dim_count = 1;
  memcpy(beta_443->qinfo, params_base + 3226920, sizeof(struct csinn_quant_info) * 1);
  struct csinn_layer_norm_params *params_443 = csinn_alloc_params(sizeof(struct csinn_layer_norm_params), sess);
  params_443->epsilon = 1e-05;
  params_443->axis = -1;
  params_443->center = true;
  params_443->scale = true;
  params_443->base.name = "layer_norm_353";
  params_443->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_layer_norm_init(output_442, output_443, gamma_443, beta_443, params_443);
  struct csinn_tensor *output_445 = csinn_alloc_tensor(sess);
  output_445->name = "output_445";
  output_445->dtype = CSINN_DTYPE_FLOAT16;
  output_445->layout = CSINN_LAYOUT_NCW;
  output_445->dim[0] = 4;
  output_445->dim[1] = 16;
  output_445->dim[2] = 720;
  output_445->dim_count = 3;
  memcpy(output_445->qinfo, params_base + 3227424, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *data_b_445 = csinn_alloc_tensor(sess);
  data_b_445->name = "data_b_445";
  data_b_445->data = params_base + 3227472;
  data_b_445->is_const = 1;
  data_b_445->dtype = CSINN_DTYPE_INT8;
  data_b_445->layout = CSINN_LAYOUT_OIW;
  data_b_445->dim[0] = 1;
  data_b_445->dim[1] = 240;
  data_b_445->dim[2] = 720;
  data_b_445->dim_count = 3;
  memcpy(data_b_445->qinfo, params_base + 3227448, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_445 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_445->trans_a = false;
  params_445->trans_b = false;
  params_445->base.name = "batch_matmul_/layer_5/layer_5.1/global_rep.0/pre_norm_mha.1/qkv_proj/MatMul_354";
  params_445->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_443, data_b_445, output_445, params_445);
  struct csinn_tensor *output_447 = csinn_alloc_tensor(sess);
  output_447->name = "output_447";
  output_447->dtype = CSINN_DTYPE_FLOAT16;
  output_447->layout = CSINN_LAYOUT_NCW;
  output_447->dim[0] = 4;
  output_447->dim[1] = 16;
  output_447->dim[2] = 720;
  output_447->dim_count = 3;
  memcpy(output_447->qinfo, params_base + 3400272, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *rhs_447 = csinn_alloc_tensor(sess);
  rhs_447->name = "rhs_447";
  rhs_447->data = params_base + 3400320;
  rhs_447->is_const = 1;
  rhs_447->dtype = CSINN_DTYPE_FLOAT16;
  rhs_447->layout = CSINN_LAYOUT_OIW;
  rhs_447->dim[0] = 1;
  rhs_447->dim[1] = 1;
  rhs_447->dim[2] = 720;
  rhs_447->dim_count = 3;
  memcpy(rhs_447->qinfo, params_base + 3400296, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_447 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_447->base.name = "add_/layer_5/layer_5.1/global_rep.0/pre_norm_mha.1/qkv_proj/Add_356";
  params_447->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_445, rhs_447, output_447, params_447);
  int32_t *shape_449 = malloc(5 * 4);
  shape_449[0] = 4;
  shape_449[1] = 16;
  shape_449[2] = 3;
  shape_449[3] = 4;
  shape_449[4] = -1;
  struct csinn_tensor *output_449 = csinn_alloc_tensor(sess);
  output_449->name = "output_449";
  output_449->dtype = CSINN_DTYPE_FLOAT16;
  output_449->layout = CSINN_LAYOUT_NCDHW;
  output_449->dim[0] = 4;
  output_449->dim[1] = 16;
  output_449->dim[2] = 3;
  output_449->dim[3] = 4;
  output_449->dim[4] = 60;
  output_449->dim_count = 5;
  memcpy(output_449->qinfo, params_base + 3401760, sizeof(struct csinn_quant_info) * 1);
  struct csinn_reshape_params *params_449 = csinn_alloc_params(sizeof(struct csinn_reshape_params), sess);
  params_449->shape = shape_449;
  params_449->shape_num = 5;
  params_449->base.name = "reshape_/layer_5/layer_5.1/global_rep.0/pre_norm_mha.1/Reshape_357";
  params_449->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_reshape_init(output_447, output_449, params_449);
  int32_t *permute_450 = malloc(5 * 4);
  permute_450[0] = 0;
  permute_450[1] = 3;
  permute_450[2] = 2;
  permute_450[3] = 1;
  permute_450[4] = 4;
  struct csinn_tensor *output_450 = csinn_alloc_tensor(sess);
  output_450->name = "output_450";
  output_450->dtype = CSINN_DTYPE_FLOAT16;
  output_450->layout = CSINN_LAYOUT_NCDHW;
  output_450->dim[0] = 4;
  output_450->dim[1] = 4;
  output_450->dim[2] = 3;
  output_450->dim[3] = 16;
  output_450->dim[4] = 60;
  output_450->dim_count = 5;
  memcpy(output_450->qinfo, params_base + 3401784, sizeof(struct csinn_quant_info) * 1);
  struct csinn_transpose_params *params_450 = csinn_alloc_params(sizeof(struct csinn_transpose_params), sess);
  params_450->permute = permute_450;
  params_450->permute_num = 5;
  params_450->base.name = "transpose_/layer_5/layer_5.1/global_rep.0/pre_norm_mha.1/Transpose_358";
  params_450->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_transpose_init(output_449, output_450, params_450);
  struct csinn_tensor *output_451 = csinn_alloc_tensor(sess);
  output_451->name = "output_451";
  output_451->dtype = CSINN_DTYPE_FLOAT16;
  output_451->layout = CSINN_LAYOUT_NCHW;
  output_451->dim[0] = 4;
  output_451->dim[1] = 4;
  output_451->dim[2] = 16;
  output_451->dim[3] = 60;
  output_451->dim_count = 4;
  memcpy(output_451->qinfo, params_base + 3401808, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *indices_451 = csinn_alloc_tensor(sess);
  indices_451->name = "indices_451";
  indices_451->data = params_base + 3401856;
  indices_451->is_const = 1;
  indices_451->dtype = CSINN_DTYPE_INT64;
  indices_451->layout = CSINN_LAYOUT_O;
  indices_451->dim[0] = 1;
  indices_451->dim_count = 1;
  memcpy(indices_451->qinfo, params_base + 3401832, sizeof(struct csinn_quant_info) * 1);
  struct csinn_gather_params *params_451 = csinn_alloc_params(sizeof(struct csinn_gather_params), sess);
  params_451->axis = 2;
  params_451->base.name = "take_/layer_5/layer_5.1/global_rep.0/pre_norm_mha.1/Gather_359";
  params_451->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_gather_init(output_450, indices_451, output_451, params_451);
  struct csinn_tensor *output_453 = csinn_alloc_tensor(sess);
  output_453->name = "output_453";
  output_453->dtype = CSINN_DTYPE_FLOAT16;
  output_453->layout = CSINN_LAYOUT_NCHW;
  output_453->dim[0] = 4;
  output_453->dim[1] = 4;
  output_453->dim[2] = 16;
  output_453->dim[3] = 60;
  output_453->dim_count = 4;
  memcpy(output_453->qinfo, params_base + 3401864, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *rhs_453 = csinn_alloc_tensor(sess);
  rhs_453->name = "rhs_453";
  rhs_453->data = params_base + 3401912;
  rhs_453->is_const = 1;
  rhs_453->dtype = CSINN_DTYPE_FLOAT16;
  rhs_453->layout = CSINN_LAYOUT_OIHW;
  rhs_453->dim[0] = 1;
  rhs_453->dim[1] = 1;
  rhs_453->dim[2] = 1;
  rhs_453->dim[3] = 1;
  rhs_453->dim_count = 4;
  memcpy(rhs_453->qinfo, params_base + 3401888, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_453 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_453->base.name = "multiply_/layer_5/layer_5.1/global_rep.0/pre_norm_mha.1/Mul_360";
  params_453->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_mul_init(output_451, rhs_453, output_453, params_453);
  struct csinn_tensor *output_456 = csinn_alloc_tensor(sess);
  output_456->name = "output_456";
  output_456->dtype = CSINN_DTYPE_FLOAT16;
  output_456->layout = CSINN_LAYOUT_NCHW;
  output_456->dim[0] = 4;
  output_456->dim[1] = 4;
  output_456->dim[2] = 16;
  output_456->dim[3] = 60;
  output_456->dim_count = 4;
  memcpy(output_456->qinfo, params_base + 3401916, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *indices_456 = csinn_alloc_tensor(sess);
  indices_456->name = "indices_456";
  indices_456->data = params_base + 3401964;
  indices_456->is_const = 1;
  indices_456->dtype = CSINN_DTYPE_INT64;
  indices_456->layout = CSINN_LAYOUT_O;
  indices_456->dim[0] = 1;
  indices_456->dim_count = 1;
  memcpy(indices_456->qinfo, params_base + 3401940, sizeof(struct csinn_quant_info) * 1);
  struct csinn_gather_params *params_456 = csinn_alloc_params(sizeof(struct csinn_gather_params), sess);
  params_456->axis = 2;
  params_456->base.name = "take_/layer_5/layer_5.1/global_rep.0/pre_norm_mha.1/Gather_1_362";
  params_456->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_gather_init(output_450, indices_456, output_456, params_456);
  int32_t *permute_457 = malloc(4 * 4);
  permute_457[0] = 0;
  permute_457[1] = 1;
  permute_457[2] = 3;
  permute_457[3] = 2;
  struct csinn_tensor *output_457 = csinn_alloc_tensor(sess);
  output_457->name = "output_457";
  output_457->dtype = CSINN_DTYPE_FLOAT16;
  output_457->layout = CSINN_LAYOUT_NCHW;
  output_457->dim[0] = 4;
  output_457->dim[1] = 4;
  output_457->dim[2] = 60;
  output_457->dim[3] = 16;
  output_457->dim_count = 4;
  memcpy(output_457->qinfo, params_base + 3401972, sizeof(struct csinn_quant_info) * 1);
  struct csinn_transpose_params *params_457 = csinn_alloc_params(sizeof(struct csinn_transpose_params), sess);
  params_457->permute = permute_457;
  params_457->permute_num = 4;
  params_457->base.name = "transpose_/layer_5/layer_5.1/global_rep.0/pre_norm_mha.1/Transpose_1_363";
  params_457->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_transpose_init(output_456, output_457, params_457);
  struct csinn_tensor *output_458 = csinn_alloc_tensor(sess);
  output_458->name = "output_458";
  output_458->dtype = CSINN_DTYPE_FLOAT16;
  output_458->layout = CSINN_LAYOUT_NCHW;
  output_458->dim[0] = 4;
  output_458->dim[1] = 4;
  output_458->dim[2] = 16;
  output_458->dim[3] = 16;
  output_458->dim_count = 4;
  memcpy(output_458->qinfo, params_base + 3401996, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_458 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_458->trans_a = false;
  params_458->trans_b = false;
  params_458->base.name = "batch_matmul_/layer_5/layer_5.1/global_rep.0/pre_norm_mha.1/MatMul_365";
  params_458->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_453, output_457, output_458, params_458);
  struct csinn_tensor *output_459 = csinn_alloc_tensor(sess);
  output_459->name = "output_459";
  output_459->dtype = CSINN_DTYPE_FLOAT16;
  output_459->layout = CSINN_LAYOUT_NCHW;
  output_459->dim[0] = 4;
  output_459->dim[1] = 4;
  output_459->dim[2] = 16;
  output_459->dim[3] = 16;
  output_459->dim_count = 4;
  memcpy(output_459->qinfo, params_base + 3402020, sizeof(struct csinn_quant_info) * 1);
  struct csinn_softmax_params *params_459 = csinn_alloc_params(sizeof(struct csinn_softmax_params), sess);
  params_459->axis = 3;
  params_459->base.name = "softmax_/layer_5/layer_5.1/global_rep.0/pre_norm_mha.1/softmax/Softmax_367";
  params_459->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_softmax_init(output_458, output_459, params_459);
  struct csinn_tensor *output_461 = csinn_alloc_tensor(sess);
  output_461->name = "output_461";
  output_461->dtype = CSINN_DTYPE_FLOAT16;
  output_461->layout = CSINN_LAYOUT_NCHW;
  output_461->dim[0] = 4;
  output_461->dim[1] = 4;
  output_461->dim[2] = 16;
  output_461->dim[3] = 60;
  output_461->dim_count = 4;
  memcpy(output_461->qinfo, params_base + 3402044, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *indices_461 = csinn_alloc_tensor(sess);
  indices_461->name = "indices_461";
  indices_461->data = params_base + 3402092;
  indices_461->is_const = 1;
  indices_461->dtype = CSINN_DTYPE_INT64;
  indices_461->layout = CSINN_LAYOUT_O;
  indices_461->dim[0] = 1;
  indices_461->dim_count = 1;
  memcpy(indices_461->qinfo, params_base + 3402068, sizeof(struct csinn_quant_info) * 1);
  struct csinn_gather_params *params_461 = csinn_alloc_params(sizeof(struct csinn_gather_params), sess);
  params_461->axis = 2;
  params_461->base.name = "take_/layer_5/layer_5.1/global_rep.0/pre_norm_mha.1/Gather_2_369";
  params_461->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_gather_init(output_450, indices_461, output_461, params_461);
  struct csinn_tensor *output_462 = csinn_alloc_tensor(sess);
  output_462->name = "output_462";
  output_462->dtype = CSINN_DTYPE_FLOAT16;
  output_462->layout = CSINN_LAYOUT_NCHW;
  output_462->dim[0] = 4;
  output_462->dim[1] = 4;
  output_462->dim[2] = 16;
  output_462->dim[3] = 60;
  output_462->dim_count = 4;
  memcpy(output_462->qinfo, params_base + 3402100, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_462 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_462->trans_a = false;
  params_462->trans_b = false;
  params_462->base.name = "batch_matmul_/layer_5/layer_5.1/global_rep.0/pre_norm_mha.1/MatMul_1_371";
  params_462->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_459, output_461, output_462, params_462);
  int32_t *permute_463 = malloc(4 * 4);
  permute_463[0] = 0;
  permute_463[1] = 2;
  permute_463[2] = 1;
  permute_463[3] = 3;
  struct csinn_tensor *output_463 = csinn_alloc_tensor(sess);
  output_463->name = "output_463";
  output_463->dtype = CSINN_DTYPE_FLOAT16;
  output_463->layout = CSINN_LAYOUT_NCHW;
  output_463->dim[0] = 4;
  output_463->dim[1] = 16;
  output_463->dim[2] = 4;
  output_463->dim[3] = 60;
  output_463->dim_count = 4;
  memcpy(output_463->qinfo, params_base + 3402124, sizeof(struct csinn_quant_info) * 1);
  struct csinn_transpose_params *params_463 = csinn_alloc_params(sizeof(struct csinn_transpose_params), sess);
  params_463->permute = permute_463;
  params_463->permute_num = 4;
  params_463->base.name = "transpose_/layer_5/layer_5.1/global_rep.0/pre_norm_mha.1/Transpose_2_373";
  params_463->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_transpose_init(output_462, output_463, params_463);
  int32_t *shape_464 = malloc(3 * 4);
  shape_464[0] = 4;
  shape_464[1] = 16;
  shape_464[2] = -1;
  struct csinn_tensor *output_464 = csinn_alloc_tensor(sess);
  output_464->name = "output_464";
  output_464->dtype = CSINN_DTYPE_FLOAT16;
  output_464->layout = CSINN_LAYOUT_NCW;
  output_464->dim[0] = 4;
  output_464->dim[1] = 16;
  output_464->dim[2] = 240;
  output_464->dim_count = 3;
  memcpy(output_464->qinfo, params_base + 3402148, sizeof(struct csinn_quant_info) * 1);
  struct csinn_reshape_params *params_464 = csinn_alloc_params(sizeof(struct csinn_reshape_params), sess);
  params_464->shape = shape_464;
  params_464->shape_num = 3;
  params_464->base.name = "reshape_/layer_5/layer_5.1/global_rep.0/pre_norm_mha.1/Reshape_1_374";
  params_464->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_reshape_init(output_463, output_464, params_464);
  struct csinn_tensor *output_466 = csinn_alloc_tensor(sess);
  output_466->name = "output_466";
  output_466->dtype = CSINN_DTYPE_FLOAT16;
  output_466->layout = CSINN_LAYOUT_NCW;
  output_466->dim[0] = 4;
  output_466->dim[1] = 16;
  output_466->dim[2] = 240;
  output_466->dim_count = 3;
  memcpy(output_466->qinfo, params_base + 3402172, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *data_b_466 = csinn_alloc_tensor(sess);
  data_b_466->name = "data_b_466";
  data_b_466->data = params_base + 3402220;
  data_b_466->is_const = 1;
  data_b_466->dtype = CSINN_DTYPE_INT8;
  data_b_466->layout = CSINN_LAYOUT_OIW;
  data_b_466->dim[0] = 1;
  data_b_466->dim[1] = 240;
  data_b_466->dim[2] = 240;
  data_b_466->dim_count = 3;
  memcpy(data_b_466->qinfo, params_base + 3402196, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_466 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_466->trans_a = false;
  params_466->trans_b = false;
  params_466->base.name = "batch_matmul_/layer_5/layer_5.1/global_rep.0/pre_norm_mha.1/out_proj/MatMul_375";
  params_466->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_464, data_b_466, output_466, params_466);
  struct csinn_tensor *output_468 = csinn_alloc_tensor(sess);
  output_468->name = "output_468";
  output_468->dtype = CSINN_DTYPE_FLOAT16;
  output_468->layout = CSINN_LAYOUT_NCW;
  output_468->dim[0] = 4;
  output_468->dim[1] = 16;
  output_468->dim[2] = 240;
  output_468->dim_count = 3;
  memcpy(output_468->qinfo, params_base + 3459820, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *rhs_468 = csinn_alloc_tensor(sess);
  rhs_468->name = "rhs_468";
  rhs_468->data = params_base + 3459868;
  rhs_468->is_const = 1;
  rhs_468->dtype = CSINN_DTYPE_FLOAT16;
  rhs_468->layout = CSINN_LAYOUT_OIW;
  rhs_468->dim[0] = 1;
  rhs_468->dim[1] = 1;
  rhs_468->dim[2] = 240;
  rhs_468->dim_count = 3;
  memcpy(rhs_468->qinfo, params_base + 3459844, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_468 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_468->base.name = "add_/layer_5/layer_5.1/global_rep.0/pre_norm_mha.1/out_proj/Add_377";
  params_468->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_466, rhs_468, output_468, params_468);
  struct csinn_tensor *output_471 = csinn_alloc_tensor(sess);
  output_471->name = "output_471";
  output_471->dtype = CSINN_DTYPE_FLOAT16;
  output_471->layout = CSINN_LAYOUT_NCW;
  output_471->dim[0] = 4;
  output_471->dim[1] = 16;
  output_471->dim[2] = 240;
  output_471->dim_count = 3;
  memcpy(output_471->qinfo, params_base + 3460348, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_471 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_471->base.name = "add_/layer_5/layer_5.1/global_rep.0/Add_378";
  params_471->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_468, output_442, output_471, params_471);
  struct csinn_tensor *output_474 = csinn_alloc_tensor(sess);
  output_474->name = "output_474";
  output_474->dtype = CSINN_DTYPE_FLOAT16;
  output_474->layout = CSINN_LAYOUT_NCW;
  output_474->dim[0] = 4;
  output_474->dim[1] = 16;
  output_474->dim[2] = 240;
  output_474->dim_count = 3;
  memcpy(output_474->qinfo, params_base + 3460372, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *gamma_474 = csinn_alloc_tensor(sess);
  gamma_474->name = "gamma_474";
  gamma_474->data = params_base + 3460420;
  gamma_474->is_const = 1;
  gamma_474->dtype = CSINN_DTYPE_FLOAT16;
  gamma_474->layout = CSINN_LAYOUT_O;
  gamma_474->dim[0] = 240;
  gamma_474->dim_count = 1;
  memcpy(gamma_474->qinfo, params_base + 3460396, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *beta_474 = csinn_alloc_tensor(sess);
  beta_474->name = "beta_474";
  beta_474->data = params_base + 3460924;
  beta_474->is_const = 1;
  beta_474->dtype = CSINN_DTYPE_FLOAT16;
  beta_474->layout = CSINN_LAYOUT_O;
  beta_474->dim[0] = 240;
  beta_474->dim_count = 1;
  memcpy(beta_474->qinfo, params_base + 3460900, sizeof(struct csinn_quant_info) * 1);
  struct csinn_layer_norm_params *params_474 = csinn_alloc_params(sizeof(struct csinn_layer_norm_params), sess);
  params_474->epsilon = 1e-05;
  params_474->axis = -1;
  params_474->center = true;
  params_474->scale = true;
  params_474->base.name = "layer_norm_379";
  params_474->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_layer_norm_init(output_471, output_474, gamma_474, beta_474, params_474);
  struct csinn_tensor *output_476 = csinn_alloc_tensor(sess);
  output_476->name = "output_476";
  output_476->dtype = CSINN_DTYPE_FLOAT16;
  output_476->layout = CSINN_LAYOUT_NCW;
  output_476->dim[0] = 4;
  output_476->dim[1] = 16;
  output_476->dim[2] = 480;
  output_476->dim_count = 3;
  memcpy(output_476->qinfo, params_base + 3461404, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *data_b_476 = csinn_alloc_tensor(sess);
  data_b_476->name = "data_b_476";
  data_b_476->data = params_base + 3461452;
  data_b_476->is_const = 1;
  data_b_476->dtype = CSINN_DTYPE_INT8;
  data_b_476->layout = CSINN_LAYOUT_OIW;
  data_b_476->dim[0] = 1;
  data_b_476->dim[1] = 240;
  data_b_476->dim[2] = 480;
  data_b_476->dim_count = 3;
  memcpy(data_b_476->qinfo, params_base + 3461428, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_476 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_476->trans_a = false;
  params_476->trans_b = false;
  params_476->base.name = "batch_matmul_/layer_5/layer_5.1/global_rep.0/pre_norm_ffn/pre_norm_ffn.1/MatMul_380";
  params_476->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_474, data_b_476, output_476, params_476);
  struct csinn_tensor *output_478 = csinn_alloc_tensor(sess);
  output_478->name = "output_478";
  output_478->dtype = CSINN_DTYPE_FLOAT16;
  output_478->layout = CSINN_LAYOUT_NCW;
  output_478->dim[0] = 4;
  output_478->dim[1] = 16;
  output_478->dim[2] = 480;
  output_478->dim_count = 3;
  memcpy(output_478->qinfo, params_base + 3576652, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *rhs_478 = csinn_alloc_tensor(sess);
  rhs_478->name = "rhs_478";
  rhs_478->data = params_base + 3576700;
  rhs_478->is_const = 1;
  rhs_478->dtype = CSINN_DTYPE_FLOAT16;
  rhs_478->layout = CSINN_LAYOUT_OIW;
  rhs_478->dim[0] = 1;
  rhs_478->dim[1] = 1;
  rhs_478->dim[2] = 480;
  rhs_478->dim_count = 3;
  memcpy(rhs_478->qinfo, params_base + 3576676, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_478 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_478->base.name = "add_/layer_5/layer_5.1/global_rep.0/pre_norm_ffn/pre_norm_ffn.1/Add_382";
  params_478->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_476, rhs_478, output_478, params_478);
  struct csinn_tensor *output_481 = csinn_alloc_tensor(sess);
  output_481->name = "output_481";
  output_481->dtype = CSINN_DTYPE_FLOAT16;
  output_481->layout = CSINN_LAYOUT_NCW;
  output_481->dim[0] = 4;
  output_481->dim[1] = 16;
  output_481->dim[2] = 480;
  output_481->dim_count = 3;
  memcpy(output_481->qinfo, params_base + 3577660, sizeof(struct csinn_quant_info) * 1);
  struct csinn_sigmoid_params *params_481 = csinn_alloc_params(sizeof(struct csinn_sigmoid_params), sess);
  params_481->base.name = "sigmoid_/layer_5/layer_5.1/global_rep.0/pre_norm_ffn/pre_norm_ffn.2/Sigmoid_383";
  params_481->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_sigmoid_init(output_478, output_481, params_481);
  struct csinn_tensor *output_482 = csinn_alloc_tensor(sess);
  output_482->name = "output_482";
  output_482->dtype = CSINN_DTYPE_FLOAT16;
  output_482->layout = CSINN_LAYOUT_NCW;
  output_482->dim[0] = 4;
  output_482->dim[1] = 16;
  output_482->dim[2] = 480;
  output_482->dim_count = 3;
  memcpy(output_482->qinfo, params_base + 3577684, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_482 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_482->base.name = "multiply_/layer_5/layer_5.1/global_rep.0/pre_norm_ffn/pre_norm_ffn.2/Mul_384";
  params_482->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_mul_init(output_478, output_481, output_482, params_482);
  struct csinn_tensor *output_485 = csinn_alloc_tensor(sess);
  output_485->name = "output_485";
  output_485->dtype = CSINN_DTYPE_FLOAT16;
  output_485->layout = CSINN_LAYOUT_NCW;
  output_485->dim[0] = 4;
  output_485->dim[1] = 16;
  output_485->dim[2] = 240;
  output_485->dim_count = 3;
  memcpy(output_485->qinfo, params_base + 3577708, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *data_b_485 = csinn_alloc_tensor(sess);
  data_b_485->name = "data_b_485";
  data_b_485->data = params_base + 3577756;
  data_b_485->is_const = 1;
  data_b_485->dtype = CSINN_DTYPE_INT8;
  data_b_485->layout = CSINN_LAYOUT_OIW;
  data_b_485->dim[0] = 1;
  data_b_485->dim[1] = 480;
  data_b_485->dim[2] = 240;
  data_b_485->dim_count = 3;
  memcpy(data_b_485->qinfo, params_base + 3577732, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_485 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_485->trans_a = false;
  params_485->trans_b = false;
  params_485->base.name = "batch_matmul_/layer_5/layer_5.1/global_rep.0/pre_norm_ffn/pre_norm_ffn.4/MatMul_385";
  params_485->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_482, data_b_485, output_485, params_485);
  struct csinn_tensor *output_487 = csinn_alloc_tensor(sess);
  output_487->name = "output_487";
  output_487->dtype = CSINN_DTYPE_FLOAT16;
  output_487->layout = CSINN_LAYOUT_NCW;
  output_487->dim[0] = 4;
  output_487->dim[1] = 16;
  output_487->dim[2] = 240;
  output_487->dim_count = 3;
  memcpy(output_487->qinfo, params_base + 3692956, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *rhs_487 = csinn_alloc_tensor(sess);
  rhs_487->name = "rhs_487";
  rhs_487->data = params_base + 3693004;
  rhs_487->is_const = 1;
  rhs_487->dtype = CSINN_DTYPE_FLOAT16;
  rhs_487->layout = CSINN_LAYOUT_OIW;
  rhs_487->dim[0] = 1;
  rhs_487->dim[1] = 1;
  rhs_487->dim[2] = 240;
  rhs_487->dim_count = 3;
  memcpy(rhs_487->qinfo, params_base + 3692980, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_487 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_487->base.name = "add_/layer_5/layer_5.1/global_rep.0/pre_norm_ffn/pre_norm_ffn.4/Add_387";
  params_487->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_485, rhs_487, output_487, params_487);
  struct csinn_tensor *output_489 = csinn_alloc_tensor(sess);
  output_489->name = "output_489";
  output_489->dtype = CSINN_DTYPE_FLOAT16;
  output_489->layout = CSINN_LAYOUT_NCW;
  output_489->dim[0] = 4;
  output_489->dim[1] = 16;
  output_489->dim[2] = 240;
  output_489->dim_count = 3;
  memcpy(output_489->qinfo, params_base + 3693484, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_489 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_489->base.name = "add_/layer_5/layer_5.1/global_rep.0/Add_1_388";
  params_489->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_471, output_487, output_489, params_489);
  struct csinn_tensor *output_491 = csinn_alloc_tensor(sess);
  output_491->name = "output_491";
  output_491->dtype = CSINN_DTYPE_FLOAT16;
  output_491->layout = CSINN_LAYOUT_NCW;
  output_491->dim[0] = 4;
  output_491->dim[1] = 16;
  output_491->dim[2] = 240;
  output_491->dim_count = 3;
  memcpy(output_491->qinfo, params_base + 3693508, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *gamma_491 = csinn_alloc_tensor(sess);
  gamma_491->name = "gamma_491";
  gamma_491->data = params_base + 3693556;
  gamma_491->is_const = 1;
  gamma_491->dtype = CSINN_DTYPE_FLOAT16;
  gamma_491->layout = CSINN_LAYOUT_O;
  gamma_491->dim[0] = 240;
  gamma_491->dim_count = 1;
  memcpy(gamma_491->qinfo, params_base + 3693532, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *beta_491 = csinn_alloc_tensor(sess);
  beta_491->name = "beta_491";
  beta_491->data = params_base + 3694060;
  beta_491->is_const = 1;
  beta_491->dtype = CSINN_DTYPE_FLOAT16;
  beta_491->layout = CSINN_LAYOUT_O;
  beta_491->dim[0] = 240;
  beta_491->dim_count = 1;
  memcpy(beta_491->qinfo, params_base + 3694036, sizeof(struct csinn_quant_info) * 1);
  struct csinn_layer_norm_params *params_491 = csinn_alloc_params(sizeof(struct csinn_layer_norm_params), sess);
  params_491->epsilon = 1e-05;
  params_491->axis = -1;
  params_491->center = true;
  params_491->scale = true;
  params_491->base.name = "layer_norm_389";
  params_491->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_layer_norm_init(output_489, output_491, gamma_491, beta_491, params_491);
  struct csinn_tensor *output_493 = csinn_alloc_tensor(sess);
  output_493->name = "output_493";
  output_493->dtype = CSINN_DTYPE_FLOAT16;
  output_493->layout = CSINN_LAYOUT_NCW;
  output_493->dim[0] = 4;
  output_493->dim[1] = 16;
  output_493->dim[2] = 720;
  output_493->dim_count = 3;
  memcpy(output_493->qinfo, params_base + 3694540, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *data_b_493 = csinn_alloc_tensor(sess);
  data_b_493->name = "data_b_493";
  data_b_493->data = params_base + 3694588;
  data_b_493->is_const = 1;
  data_b_493->dtype = CSINN_DTYPE_INT8;
  data_b_493->layout = CSINN_LAYOUT_OIW;
  data_b_493->dim[0] = 1;
  data_b_493->dim[1] = 240;
  data_b_493->dim[2] = 720;
  data_b_493->dim_count = 3;
  memcpy(data_b_493->qinfo, params_base + 3694564, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_493 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_493->trans_a = false;
  params_493->trans_b = false;
  params_493->base.name = "batch_matmul_/layer_5/layer_5.1/global_rep.1/pre_norm_mha.1/qkv_proj/MatMul_390";
  params_493->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_491, data_b_493, output_493, params_493);
  struct csinn_tensor *output_495 = csinn_alloc_tensor(sess);
  output_495->name = "output_495";
  output_495->dtype = CSINN_DTYPE_FLOAT16;
  output_495->layout = CSINN_LAYOUT_NCW;
  output_495->dim[0] = 4;
  output_495->dim[1] = 16;
  output_495->dim[2] = 720;
  output_495->dim_count = 3;
  memcpy(output_495->qinfo, params_base + 3867388, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *rhs_495 = csinn_alloc_tensor(sess);
  rhs_495->name = "rhs_495";
  rhs_495->data = params_base + 3867436;
  rhs_495->is_const = 1;
  rhs_495->dtype = CSINN_DTYPE_FLOAT16;
  rhs_495->layout = CSINN_LAYOUT_OIW;
  rhs_495->dim[0] = 1;
  rhs_495->dim[1] = 1;
  rhs_495->dim[2] = 720;
  rhs_495->dim_count = 3;
  memcpy(rhs_495->qinfo, params_base + 3867412, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_495 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_495->base.name = "add_/layer_5/layer_5.1/global_rep.1/pre_norm_mha.1/qkv_proj/Add_392";
  params_495->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_493, rhs_495, output_495, params_495);
  int32_t *shape_497 = malloc(5 * 4);
  shape_497[0] = 4;
  shape_497[1] = 16;
  shape_497[2] = 3;
  shape_497[3] = 4;
  shape_497[4] = -1;
  struct csinn_tensor *output_497 = csinn_alloc_tensor(sess);
  output_497->name = "output_497";
  output_497->dtype = CSINN_DTYPE_FLOAT16;
  output_497->layout = CSINN_LAYOUT_NCDHW;
  output_497->dim[0] = 4;
  output_497->dim[1] = 16;
  output_497->dim[2] = 3;
  output_497->dim[3] = 4;
  output_497->dim[4] = 60;
  output_497->dim_count = 5;
  memcpy(output_497->qinfo, params_base + 3868876, sizeof(struct csinn_quant_info) * 1);
  struct csinn_reshape_params *params_497 = csinn_alloc_params(sizeof(struct csinn_reshape_params), sess);
  params_497->shape = shape_497;
  params_497->shape_num = 5;
  params_497->base.name = "reshape_/layer_5/layer_5.1/global_rep.1/pre_norm_mha.1/Reshape_393";
  params_497->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_reshape_init(output_495, output_497, params_497);
  int32_t *permute_498 = malloc(5 * 4);
  permute_498[0] = 0;
  permute_498[1] = 3;
  permute_498[2] = 2;
  permute_498[3] = 1;
  permute_498[4] = 4;
  struct csinn_tensor *output_498 = csinn_alloc_tensor(sess);
  output_498->name = "output_498";
  output_498->dtype = CSINN_DTYPE_FLOAT16;
  output_498->layout = CSINN_LAYOUT_NCDHW;
  output_498->dim[0] = 4;
  output_498->dim[1] = 4;
  output_498->dim[2] = 3;
  output_498->dim[3] = 16;
  output_498->dim[4] = 60;
  output_498->dim_count = 5;
  memcpy(output_498->qinfo, params_base + 3868900, sizeof(struct csinn_quant_info) * 1);
  struct csinn_transpose_params *params_498 = csinn_alloc_params(sizeof(struct csinn_transpose_params), sess);
  params_498->permute = permute_498;
  params_498->permute_num = 5;
  params_498->base.name = "transpose_/layer_5/layer_5.1/global_rep.1/pre_norm_mha.1/Transpose_394";
  params_498->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_transpose_init(output_497, output_498, params_498);
  struct csinn_tensor *output_499 = csinn_alloc_tensor(sess);
  output_499->name = "output_499";
  output_499->dtype = CSINN_DTYPE_FLOAT16;
  output_499->layout = CSINN_LAYOUT_NCHW;
  output_499->dim[0] = 4;
  output_499->dim[1] = 4;
  output_499->dim[2] = 16;
  output_499->dim[3] = 60;
  output_499->dim_count = 4;
  memcpy(output_499->qinfo, params_base + 3868924, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *indices_499 = csinn_alloc_tensor(sess);
  indices_499->name = "indices_499";
  indices_499->data = params_base + 3868972;
  indices_499->is_const = 1;
  indices_499->dtype = CSINN_DTYPE_INT64;
  indices_499->layout = CSINN_LAYOUT_O;
  indices_499->dim[0] = 1;
  indices_499->dim_count = 1;
  memcpy(indices_499->qinfo, params_base + 3868948, sizeof(struct csinn_quant_info) * 1);
  struct csinn_gather_params *params_499 = csinn_alloc_params(sizeof(struct csinn_gather_params), sess);
  params_499->axis = 2;
  params_499->base.name = "take_/layer_5/layer_5.1/global_rep.1/pre_norm_mha.1/Gather_395";
  params_499->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_gather_init(output_498, indices_499, output_499, params_499);
  struct csinn_tensor *output_501 = csinn_alloc_tensor(sess);
  output_501->name = "output_501";
  output_501->dtype = CSINN_DTYPE_FLOAT16;
  output_501->layout = CSINN_LAYOUT_NCHW;
  output_501->dim[0] = 4;
  output_501->dim[1] = 4;
  output_501->dim[2] = 16;
  output_501->dim[3] = 60;
  output_501->dim_count = 4;
  memcpy(output_501->qinfo, params_base + 3868980, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *rhs_501 = csinn_alloc_tensor(sess);
  rhs_501->name = "rhs_501";
  rhs_501->data = params_base + 3869028;
  rhs_501->is_const = 1;
  rhs_501->dtype = CSINN_DTYPE_FLOAT16;
  rhs_501->layout = CSINN_LAYOUT_OIHW;
  rhs_501->dim[0] = 1;
  rhs_501->dim[1] = 1;
  rhs_501->dim[2] = 1;
  rhs_501->dim[3] = 1;
  rhs_501->dim_count = 4;
  memcpy(rhs_501->qinfo, params_base + 3869004, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_501 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_501->base.name = "multiply_/layer_5/layer_5.1/global_rep.1/pre_norm_mha.1/Mul_396";
  params_501->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_mul_init(output_499, rhs_501, output_501, params_501);
  struct csinn_tensor *output_504 = csinn_alloc_tensor(sess);
  output_504->name = "output_504";
  output_504->dtype = CSINN_DTYPE_FLOAT16;
  output_504->layout = CSINN_LAYOUT_NCHW;
  output_504->dim[0] = 4;
  output_504->dim[1] = 4;
  output_504->dim[2] = 16;
  output_504->dim[3] = 60;
  output_504->dim_count = 4;
  memcpy(output_504->qinfo, params_base + 3869032, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *indices_504 = csinn_alloc_tensor(sess);
  indices_504->name = "indices_504";
  indices_504->data = params_base + 3869080;
  indices_504->is_const = 1;
  indices_504->dtype = CSINN_DTYPE_INT64;
  indices_504->layout = CSINN_LAYOUT_O;
  indices_504->dim[0] = 1;
  indices_504->dim_count = 1;
  memcpy(indices_504->qinfo, params_base + 3869056, sizeof(struct csinn_quant_info) * 1);
  struct csinn_gather_params *params_504 = csinn_alloc_params(sizeof(struct csinn_gather_params), sess);
  params_504->axis = 2;
  params_504->base.name = "take_/layer_5/layer_5.1/global_rep.1/pre_norm_mha.1/Gather_1_398";
  params_504->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_gather_init(output_498, indices_504, output_504, params_504);
  int32_t *permute_505 = malloc(4 * 4);
  permute_505[0] = 0;
  permute_505[1] = 1;
  permute_505[2] = 3;
  permute_505[3] = 2;
  struct csinn_tensor *output_505 = csinn_alloc_tensor(sess);
  output_505->name = "output_505";
  output_505->dtype = CSINN_DTYPE_FLOAT16;
  output_505->layout = CSINN_LAYOUT_NCHW;
  output_505->dim[0] = 4;
  output_505->dim[1] = 4;
  output_505->dim[2] = 60;
  output_505->dim[3] = 16;
  output_505->dim_count = 4;
  memcpy(output_505->qinfo, params_base + 3869088, sizeof(struct csinn_quant_info) * 1);
  struct csinn_transpose_params *params_505 = csinn_alloc_params(sizeof(struct csinn_transpose_params), sess);
  params_505->permute = permute_505;
  params_505->permute_num = 4;
  params_505->base.name = "transpose_/layer_5/layer_5.1/global_rep.1/pre_norm_mha.1/Transpose_1_399";
  params_505->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_transpose_init(output_504, output_505, params_505);
  struct csinn_tensor *output_506 = csinn_alloc_tensor(sess);
  output_506->name = "output_506";
  output_506->dtype = CSINN_DTYPE_FLOAT16;
  output_506->layout = CSINN_LAYOUT_NCHW;
  output_506->dim[0] = 4;
  output_506->dim[1] = 4;
  output_506->dim[2] = 16;
  output_506->dim[3] = 16;
  output_506->dim_count = 4;
  memcpy(output_506->qinfo, params_base + 3869112, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_506 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_506->trans_a = false;
  params_506->trans_b = false;
  params_506->base.name = "batch_matmul_/layer_5/layer_5.1/global_rep.1/pre_norm_mha.1/MatMul_401";
  params_506->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_501, output_505, output_506, params_506);
  struct csinn_tensor *output_507 = csinn_alloc_tensor(sess);
  output_507->name = "output_507";
  output_507->dtype = CSINN_DTYPE_FLOAT16;
  output_507->layout = CSINN_LAYOUT_NCHW;
  output_507->dim[0] = 4;
  output_507->dim[1] = 4;
  output_507->dim[2] = 16;
  output_507->dim[3] = 16;
  output_507->dim_count = 4;
  memcpy(output_507->qinfo, params_base + 3869136, sizeof(struct csinn_quant_info) * 1);
  struct csinn_softmax_params *params_507 = csinn_alloc_params(sizeof(struct csinn_softmax_params), sess);
  params_507->axis = 3;
  params_507->base.name = "softmax_/layer_5/layer_5.1/global_rep.1/pre_norm_mha.1/softmax/Softmax_403";
  params_507->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_softmax_init(output_506, output_507, params_507);
  struct csinn_tensor *output_509 = csinn_alloc_tensor(sess);
  output_509->name = "output_509";
  output_509->dtype = CSINN_DTYPE_FLOAT16;
  output_509->layout = CSINN_LAYOUT_NCHW;
  output_509->dim[0] = 4;
  output_509->dim[1] = 4;
  output_509->dim[2] = 16;
  output_509->dim[3] = 60;
  output_509->dim_count = 4;
  memcpy(output_509->qinfo, params_base + 3869160, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *indices_509 = csinn_alloc_tensor(sess);
  indices_509->name = "indices_509";
  indices_509->data = params_base + 3869208;
  indices_509->is_const = 1;
  indices_509->dtype = CSINN_DTYPE_INT64;
  indices_509->layout = CSINN_LAYOUT_O;
  indices_509->dim[0] = 1;
  indices_509->dim_count = 1;
  memcpy(indices_509->qinfo, params_base + 3869184, sizeof(struct csinn_quant_info) * 1);
  struct csinn_gather_params *params_509 = csinn_alloc_params(sizeof(struct csinn_gather_params), sess);
  params_509->axis = 2;
  params_509->base.name = "take_/layer_5/layer_5.1/global_rep.1/pre_norm_mha.1/Gather_2_405";
  params_509->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_gather_init(output_498, indices_509, output_509, params_509);
  struct csinn_tensor *output_510 = csinn_alloc_tensor(sess);
  output_510->name = "output_510";
  output_510->dtype = CSINN_DTYPE_FLOAT16;
  output_510->layout = CSINN_LAYOUT_NCHW;
  output_510->dim[0] = 4;
  output_510->dim[1] = 4;
  output_510->dim[2] = 16;
  output_510->dim[3] = 60;
  output_510->dim_count = 4;
  memcpy(output_510->qinfo, params_base + 3869216, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_510 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_510->trans_a = false;
  params_510->trans_b = false;
  params_510->base.name = "batch_matmul_/layer_5/layer_5.1/global_rep.1/pre_norm_mha.1/MatMul_1_407";
  params_510->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_507, output_509, output_510, params_510);
  int32_t *permute_511 = malloc(4 * 4);
  permute_511[0] = 0;
  permute_511[1] = 2;
  permute_511[2] = 1;
  permute_511[3] = 3;
  struct csinn_tensor *output_511 = csinn_alloc_tensor(sess);
  output_511->name = "output_511";
  output_511->dtype = CSINN_DTYPE_FLOAT16;
  output_511->layout = CSINN_LAYOUT_NCHW;
  output_511->dim[0] = 4;
  output_511->dim[1] = 16;
  output_511->dim[2] = 4;
  output_511->dim[3] = 60;
  output_511->dim_count = 4;
  memcpy(output_511->qinfo, params_base + 3869240, sizeof(struct csinn_quant_info) * 1);
  struct csinn_transpose_params *params_511 = csinn_alloc_params(sizeof(struct csinn_transpose_params), sess);
  params_511->permute = permute_511;
  params_511->permute_num = 4;
  params_511->base.name = "transpose_/layer_5/layer_5.1/global_rep.1/pre_norm_mha.1/Transpose_2_409";
  params_511->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_transpose_init(output_510, output_511, params_511);
  int32_t *shape_512 = malloc(3 * 4);
  shape_512[0] = 4;
  shape_512[1] = 16;
  shape_512[2] = -1;
  struct csinn_tensor *output_512 = csinn_alloc_tensor(sess);
  output_512->name = "output_512";
  output_512->dtype = CSINN_DTYPE_FLOAT16;
  output_512->layout = CSINN_LAYOUT_NCW;
  output_512->dim[0] = 4;
  output_512->dim[1] = 16;
  output_512->dim[2] = 240;
  output_512->dim_count = 3;
  memcpy(output_512->qinfo, params_base + 3869264, sizeof(struct csinn_quant_info) * 1);
  struct csinn_reshape_params *params_512 = csinn_alloc_params(sizeof(struct csinn_reshape_params), sess);
  params_512->shape = shape_512;
  params_512->shape_num = 3;
  params_512->base.name = "reshape_/layer_5/layer_5.1/global_rep.1/pre_norm_mha.1/Reshape_1_410";
  params_512->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_reshape_init(output_511, output_512, params_512);
  struct csinn_tensor *output_514 = csinn_alloc_tensor(sess);
  output_514->name = "output_514";
  output_514->dtype = CSINN_DTYPE_FLOAT16;
  output_514->layout = CSINN_LAYOUT_NCW;
  output_514->dim[0] = 4;
  output_514->dim[1] = 16;
  output_514->dim[2] = 240;
  output_514->dim_count = 3;
  memcpy(output_514->qinfo, params_base + 3869288, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *data_b_514 = csinn_alloc_tensor(sess);
  data_b_514->name = "data_b_514";
  data_b_514->data = params_base + 3869336;
  data_b_514->is_const = 1;
  data_b_514->dtype = CSINN_DTYPE_INT8;
  data_b_514->layout = CSINN_LAYOUT_OIW;
  data_b_514->dim[0] = 1;
  data_b_514->dim[1] = 240;
  data_b_514->dim[2] = 240;
  data_b_514->dim_count = 3;
  memcpy(data_b_514->qinfo, params_base + 3869312, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_514 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_514->trans_a = false;
  params_514->trans_b = false;
  params_514->base.name = "batch_matmul_/layer_5/layer_5.1/global_rep.1/pre_norm_mha.1/out_proj/MatMul_411";
  params_514->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_512, data_b_514, output_514, params_514);
  struct csinn_tensor *output_516 = csinn_alloc_tensor(sess);
  output_516->name = "output_516";
  output_516->dtype = CSINN_DTYPE_FLOAT16;
  output_516->layout = CSINN_LAYOUT_NCW;
  output_516->dim[0] = 4;
  output_516->dim[1] = 16;
  output_516->dim[2] = 240;
  output_516->dim_count = 3;
  memcpy(output_516->qinfo, params_base + 3926936, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *rhs_516 = csinn_alloc_tensor(sess);
  rhs_516->name = "rhs_516";
  rhs_516->data = params_base + 3926984;
  rhs_516->is_const = 1;
  rhs_516->dtype = CSINN_DTYPE_FLOAT16;
  rhs_516->layout = CSINN_LAYOUT_OIW;
  rhs_516->dim[0] = 1;
  rhs_516->dim[1] = 1;
  rhs_516->dim[2] = 240;
  rhs_516->dim_count = 3;
  memcpy(rhs_516->qinfo, params_base + 3926960, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_516 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_516->base.name = "add_/layer_5/layer_5.1/global_rep.1/pre_norm_mha.1/out_proj/Add_413";
  params_516->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_514, rhs_516, output_516, params_516);
  struct csinn_tensor *output_519 = csinn_alloc_tensor(sess);
  output_519->name = "output_519";
  output_519->dtype = CSINN_DTYPE_FLOAT16;
  output_519->layout = CSINN_LAYOUT_NCW;
  output_519->dim[0] = 4;
  output_519->dim[1] = 16;
  output_519->dim[2] = 240;
  output_519->dim_count = 3;
  memcpy(output_519->qinfo, params_base + 3927464, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_519 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_519->base.name = "add_/layer_5/layer_5.1/global_rep.1/Add_414";
  params_519->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_516, output_489, output_519, params_519);
  struct csinn_tensor *output_522 = csinn_alloc_tensor(sess);
  output_522->name = "output_522";
  output_522->dtype = CSINN_DTYPE_FLOAT16;
  output_522->layout = CSINN_LAYOUT_NCW;
  output_522->dim[0] = 4;
  output_522->dim[1] = 16;
  output_522->dim[2] = 240;
  output_522->dim_count = 3;
  memcpy(output_522->qinfo, params_base + 3927488, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *gamma_522 = csinn_alloc_tensor(sess);
  gamma_522->name = "gamma_522";
  gamma_522->data = params_base + 3927536;
  gamma_522->is_const = 1;
  gamma_522->dtype = CSINN_DTYPE_FLOAT16;
  gamma_522->layout = CSINN_LAYOUT_O;
  gamma_522->dim[0] = 240;
  gamma_522->dim_count = 1;
  memcpy(gamma_522->qinfo, params_base + 3927512, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *beta_522 = csinn_alloc_tensor(sess);
  beta_522->name = "beta_522";
  beta_522->data = params_base + 3928040;
  beta_522->is_const = 1;
  beta_522->dtype = CSINN_DTYPE_FLOAT16;
  beta_522->layout = CSINN_LAYOUT_O;
  beta_522->dim[0] = 240;
  beta_522->dim_count = 1;
  memcpy(beta_522->qinfo, params_base + 3928016, sizeof(struct csinn_quant_info) * 1);
  struct csinn_layer_norm_params *params_522 = csinn_alloc_params(sizeof(struct csinn_layer_norm_params), sess);
  params_522->epsilon = 1e-05;
  params_522->axis = -1;
  params_522->center = true;
  params_522->scale = true;
  params_522->base.name = "layer_norm_415";
  params_522->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_layer_norm_init(output_519, output_522, gamma_522, beta_522, params_522);
  struct csinn_tensor *output_524 = csinn_alloc_tensor(sess);
  output_524->name = "output_524";
  output_524->dtype = CSINN_DTYPE_FLOAT16;
  output_524->layout = CSINN_LAYOUT_NCW;
  output_524->dim[0] = 4;
  output_524->dim[1] = 16;
  output_524->dim[2] = 480;
  output_524->dim_count = 3;
  memcpy(output_524->qinfo, params_base + 3928520, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *data_b_524 = csinn_alloc_tensor(sess);
  data_b_524->name = "data_b_524";
  data_b_524->data = params_base + 3928568;
  data_b_524->is_const = 1;
  data_b_524->dtype = CSINN_DTYPE_INT8;
  data_b_524->layout = CSINN_LAYOUT_OIW;
  data_b_524->dim[0] = 1;
  data_b_524->dim[1] = 240;
  data_b_524->dim[2] = 480;
  data_b_524->dim_count = 3;
  memcpy(data_b_524->qinfo, params_base + 3928544, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_524 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_524->trans_a = false;
  params_524->trans_b = false;
  params_524->base.name = "batch_matmul_/layer_5/layer_5.1/global_rep.1/pre_norm_ffn/pre_norm_ffn.1/MatMul_416";
  params_524->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_522, data_b_524, output_524, params_524);
  struct csinn_tensor *output_526 = csinn_alloc_tensor(sess);
  output_526->name = "output_526";
  output_526->dtype = CSINN_DTYPE_FLOAT16;
  output_526->layout = CSINN_LAYOUT_NCW;
  output_526->dim[0] = 4;
  output_526->dim[1] = 16;
  output_526->dim[2] = 480;
  output_526->dim_count = 3;
  memcpy(output_526->qinfo, params_base + 4043768, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *rhs_526 = csinn_alloc_tensor(sess);
  rhs_526->name = "rhs_526";
  rhs_526->data = params_base + 4043816;
  rhs_526->is_const = 1;
  rhs_526->dtype = CSINN_DTYPE_FLOAT16;
  rhs_526->layout = CSINN_LAYOUT_OIW;
  rhs_526->dim[0] = 1;
  rhs_526->dim[1] = 1;
  rhs_526->dim[2] = 480;
  rhs_526->dim_count = 3;
  memcpy(rhs_526->qinfo, params_base + 4043792, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_526 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_526->base.name = "add_/layer_5/layer_5.1/global_rep.1/pre_norm_ffn/pre_norm_ffn.1/Add_418";
  params_526->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_524, rhs_526, output_526, params_526);
  struct csinn_tensor *output_529 = csinn_alloc_tensor(sess);
  output_529->name = "output_529";
  output_529->dtype = CSINN_DTYPE_FLOAT16;
  output_529->layout = CSINN_LAYOUT_NCW;
  output_529->dim[0] = 4;
  output_529->dim[1] = 16;
  output_529->dim[2] = 480;
  output_529->dim_count = 3;
  memcpy(output_529->qinfo, params_base + 4044776, sizeof(struct csinn_quant_info) * 1);
  struct csinn_sigmoid_params *params_529 = csinn_alloc_params(sizeof(struct csinn_sigmoid_params), sess);
  params_529->base.name = "sigmoid_/layer_5/layer_5.1/global_rep.1/pre_norm_ffn/pre_norm_ffn.2/Sigmoid_419";
  params_529->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_sigmoid_init(output_526, output_529, params_529);
  struct csinn_tensor *output_530 = csinn_alloc_tensor(sess);
  output_530->name = "output_530";
  output_530->dtype = CSINN_DTYPE_FLOAT16;
  output_530->layout = CSINN_LAYOUT_NCW;
  output_530->dim[0] = 4;
  output_530->dim[1] = 16;
  output_530->dim[2] = 480;
  output_530->dim_count = 3;
  memcpy(output_530->qinfo, params_base + 4044800, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_530 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_530->base.name = "multiply_/layer_5/layer_5.1/global_rep.1/pre_norm_ffn/pre_norm_ffn.2/Mul_420";
  params_530->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_mul_init(output_526, output_529, output_530, params_530);
  struct csinn_tensor *output_533 = csinn_alloc_tensor(sess);
  output_533->name = "output_533";
  output_533->dtype = CSINN_DTYPE_FLOAT16;
  output_533->layout = CSINN_LAYOUT_NCW;
  output_533->dim[0] = 4;
  output_533->dim[1] = 16;
  output_533->dim[2] = 240;
  output_533->dim_count = 3;
  memcpy(output_533->qinfo, params_base + 4044824, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *data_b_533 = csinn_alloc_tensor(sess);
  data_b_533->name = "data_b_533";
  data_b_533->data = params_base + 4044872;
  data_b_533->is_const = 1;
  data_b_533->dtype = CSINN_DTYPE_INT8;
  data_b_533->layout = CSINN_LAYOUT_OIW;
  data_b_533->dim[0] = 1;
  data_b_533->dim[1] = 480;
  data_b_533->dim[2] = 240;
  data_b_533->dim_count = 3;
  memcpy(data_b_533->qinfo, params_base + 4044848, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_533 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_533->trans_a = false;
  params_533->trans_b = false;
  params_533->base.name = "batch_matmul_/layer_5/layer_5.1/global_rep.1/pre_norm_ffn/pre_norm_ffn.4/MatMul_421";
  params_533->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_530, data_b_533, output_533, params_533);
  struct csinn_tensor *output_535 = csinn_alloc_tensor(sess);
  output_535->name = "output_535";
  output_535->dtype = CSINN_DTYPE_FLOAT16;
  output_535->layout = CSINN_LAYOUT_NCW;
  output_535->dim[0] = 4;
  output_535->dim[1] = 16;
  output_535->dim[2] = 240;
  output_535->dim_count = 3;
  memcpy(output_535->qinfo, params_base + 4160072, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *rhs_535 = csinn_alloc_tensor(sess);
  rhs_535->name = "rhs_535";
  rhs_535->data = params_base + 4160120;
  rhs_535->is_const = 1;
  rhs_535->dtype = CSINN_DTYPE_FLOAT16;
  rhs_535->layout = CSINN_LAYOUT_OIW;
  rhs_535->dim[0] = 1;
  rhs_535->dim[1] = 1;
  rhs_535->dim[2] = 240;
  rhs_535->dim_count = 3;
  memcpy(rhs_535->qinfo, params_base + 4160096, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_535 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_535->base.name = "add_/layer_5/layer_5.1/global_rep.1/pre_norm_ffn/pre_norm_ffn.4/Add_423";
  params_535->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_533, rhs_535, output_535, params_535);
  struct csinn_tensor *output_537 = csinn_alloc_tensor(sess);
  output_537->name = "output_537";
  output_537->dtype = CSINN_DTYPE_FLOAT16;
  output_537->layout = CSINN_LAYOUT_NCW;
  output_537->dim[0] = 4;
  output_537->dim[1] = 16;
  output_537->dim[2] = 240;
  output_537->dim_count = 3;
  memcpy(output_537->qinfo, params_base + 4160600, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_537 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_537->base.name = "add_/layer_5/layer_5.1/global_rep.1/Add_1_424";
  params_537->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_519, output_535, output_537, params_537);
  struct csinn_tensor *output_539 = csinn_alloc_tensor(sess);
  output_539->name = "output_539";
  output_539->dtype = CSINN_DTYPE_FLOAT16;
  output_539->layout = CSINN_LAYOUT_NCW;
  output_539->dim[0] = 4;
  output_539->dim[1] = 16;
  output_539->dim[2] = 240;
  output_539->dim_count = 3;
  memcpy(output_539->qinfo, params_base + 4160624, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *gamma_539 = csinn_alloc_tensor(sess);
  gamma_539->name = "gamma_539";
  gamma_539->data = params_base + 4160672;
  gamma_539->is_const = 1;
  gamma_539->dtype = CSINN_DTYPE_FLOAT16;
  gamma_539->layout = CSINN_LAYOUT_O;
  gamma_539->dim[0] = 240;
  gamma_539->dim_count = 1;
  memcpy(gamma_539->qinfo, params_base + 4160648, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *beta_539 = csinn_alloc_tensor(sess);
  beta_539->name = "beta_539";
  beta_539->data = params_base + 4161176;
  beta_539->is_const = 1;
  beta_539->dtype = CSINN_DTYPE_FLOAT16;
  beta_539->layout = CSINN_LAYOUT_O;
  beta_539->dim[0] = 240;
  beta_539->dim_count = 1;
  memcpy(beta_539->qinfo, params_base + 4161152, sizeof(struct csinn_quant_info) * 1);
  struct csinn_layer_norm_params *params_539 = csinn_alloc_params(sizeof(struct csinn_layer_norm_params), sess);
  params_539->epsilon = 1e-05;
  params_539->axis = -1;
  params_539->center = true;
  params_539->scale = true;
  params_539->base.name = "layer_norm_425";
  params_539->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_layer_norm_init(output_537, output_539, gamma_539, beta_539, params_539);
  struct csinn_tensor *output_541 = csinn_alloc_tensor(sess);
  output_541->name = "output_541";
  output_541->dtype = CSINN_DTYPE_FLOAT16;
  output_541->layout = CSINN_LAYOUT_NCW;
  output_541->dim[0] = 4;
  output_541->dim[1] = 16;
  output_541->dim[2] = 720;
  output_541->dim_count = 3;
  memcpy(output_541->qinfo, params_base + 4161656, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *data_b_541 = csinn_alloc_tensor(sess);
  data_b_541->name = "data_b_541";
  data_b_541->data = params_base + 4161704;
  data_b_541->is_const = 1;
  data_b_541->dtype = CSINN_DTYPE_INT8;
  data_b_541->layout = CSINN_LAYOUT_OIW;
  data_b_541->dim[0] = 1;
  data_b_541->dim[1] = 240;
  data_b_541->dim[2] = 720;
  data_b_541->dim_count = 3;
  memcpy(data_b_541->qinfo, params_base + 4161680, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_541 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_541->trans_a = false;
  params_541->trans_b = false;
  params_541->base.name = "batch_matmul_/layer_5/layer_5.1/global_rep.2/pre_norm_mha.1/qkv_proj/MatMul_426";
  params_541->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_539, data_b_541, output_541, params_541);
  struct csinn_tensor *output_543 = csinn_alloc_tensor(sess);
  output_543->name = "output_543";
  output_543->dtype = CSINN_DTYPE_FLOAT16;
  output_543->layout = CSINN_LAYOUT_NCW;
  output_543->dim[0] = 4;
  output_543->dim[1] = 16;
  output_543->dim[2] = 720;
  output_543->dim_count = 3;
  memcpy(output_543->qinfo, params_base + 4334504, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *rhs_543 = csinn_alloc_tensor(sess);
  rhs_543->name = "rhs_543";
  rhs_543->data = params_base + 4334552;
  rhs_543->is_const = 1;
  rhs_543->dtype = CSINN_DTYPE_FLOAT16;
  rhs_543->layout = CSINN_LAYOUT_OIW;
  rhs_543->dim[0] = 1;
  rhs_543->dim[1] = 1;
  rhs_543->dim[2] = 720;
  rhs_543->dim_count = 3;
  memcpy(rhs_543->qinfo, params_base + 4334528, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_543 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_543->base.name = "add_/layer_5/layer_5.1/global_rep.2/pre_norm_mha.1/qkv_proj/Add_428";
  params_543->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_541, rhs_543, output_543, params_543);
  int32_t *shape_545 = malloc(5 * 4);
  shape_545[0] = 4;
  shape_545[1] = 16;
  shape_545[2] = 3;
  shape_545[3] = 4;
  shape_545[4] = -1;
  struct csinn_tensor *output_545 = csinn_alloc_tensor(sess);
  output_545->name = "output_545";
  output_545->dtype = CSINN_DTYPE_FLOAT16;
  output_545->layout = CSINN_LAYOUT_NCDHW;
  output_545->dim[0] = 4;
  output_545->dim[1] = 16;
  output_545->dim[2] = 3;
  output_545->dim[3] = 4;
  output_545->dim[4] = 60;
  output_545->dim_count = 5;
  memcpy(output_545->qinfo, params_base + 4335992, sizeof(struct csinn_quant_info) * 1);
  struct csinn_reshape_params *params_545 = csinn_alloc_params(sizeof(struct csinn_reshape_params), sess);
  params_545->shape = shape_545;
  params_545->shape_num = 5;
  params_545->base.name = "reshape_/layer_5/layer_5.1/global_rep.2/pre_norm_mha.1/Reshape_429";
  params_545->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_reshape_init(output_543, output_545, params_545);
  int32_t *permute_546 = malloc(5 * 4);
  permute_546[0] = 0;
  permute_546[1] = 3;
  permute_546[2] = 2;
  permute_546[3] = 1;
  permute_546[4] = 4;
  struct csinn_tensor *output_546 = csinn_alloc_tensor(sess);
  output_546->name = "output_546";
  output_546->dtype = CSINN_DTYPE_FLOAT16;
  output_546->layout = CSINN_LAYOUT_NCDHW;
  output_546->dim[0] = 4;
  output_546->dim[1] = 4;
  output_546->dim[2] = 3;
  output_546->dim[3] = 16;
  output_546->dim[4] = 60;
  output_546->dim_count = 5;
  memcpy(output_546->qinfo, params_base + 4336016, sizeof(struct csinn_quant_info) * 1);
  struct csinn_transpose_params *params_546 = csinn_alloc_params(sizeof(struct csinn_transpose_params), sess);
  params_546->permute = permute_546;
  params_546->permute_num = 5;
  params_546->base.name = "transpose_/layer_5/layer_5.1/global_rep.2/pre_norm_mha.1/Transpose_430";
  params_546->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_transpose_init(output_545, output_546, params_546);
  struct csinn_tensor *output_547 = csinn_alloc_tensor(sess);
  output_547->name = "output_547";
  output_547->dtype = CSINN_DTYPE_FLOAT16;
  output_547->layout = CSINN_LAYOUT_NCHW;
  output_547->dim[0] = 4;
  output_547->dim[1] = 4;
  output_547->dim[2] = 16;
  output_547->dim[3] = 60;
  output_547->dim_count = 4;
  memcpy(output_547->qinfo, params_base + 4336040, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *indices_547 = csinn_alloc_tensor(sess);
  indices_547->name = "indices_547";
  indices_547->data = params_base + 4336088;
  indices_547->is_const = 1;
  indices_547->dtype = CSINN_DTYPE_INT64;
  indices_547->layout = CSINN_LAYOUT_O;
  indices_547->dim[0] = 1;
  indices_547->dim_count = 1;
  memcpy(indices_547->qinfo, params_base + 4336064, sizeof(struct csinn_quant_info) * 1);
  struct csinn_gather_params *params_547 = csinn_alloc_params(sizeof(struct csinn_gather_params), sess);
  params_547->axis = 2;
  params_547->base.name = "take_/layer_5/layer_5.1/global_rep.2/pre_norm_mha.1/Gather_431";
  params_547->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_gather_init(output_546, indices_547, output_547, params_547);
  struct csinn_tensor *output_549 = csinn_alloc_tensor(sess);
  output_549->name = "output_549";
  output_549->dtype = CSINN_DTYPE_FLOAT16;
  output_549->layout = CSINN_LAYOUT_NCHW;
  output_549->dim[0] = 4;
  output_549->dim[1] = 4;
  output_549->dim[2] = 16;
  output_549->dim[3] = 60;
  output_549->dim_count = 4;
  memcpy(output_549->qinfo, params_base + 4336096, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *rhs_549 = csinn_alloc_tensor(sess);
  rhs_549->name = "rhs_549";
  rhs_549->data = params_base + 4336144;
  rhs_549->is_const = 1;
  rhs_549->dtype = CSINN_DTYPE_FLOAT16;
  rhs_549->layout = CSINN_LAYOUT_OIHW;
  rhs_549->dim[0] = 1;
  rhs_549->dim[1] = 1;
  rhs_549->dim[2] = 1;
  rhs_549->dim[3] = 1;
  rhs_549->dim_count = 4;
  memcpy(rhs_549->qinfo, params_base + 4336120, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_549 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_549->base.name = "multiply_/layer_5/layer_5.1/global_rep.2/pre_norm_mha.1/Mul_432";
  params_549->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_mul_init(output_547, rhs_549, output_549, params_549);
  struct csinn_tensor *output_552 = csinn_alloc_tensor(sess);
  output_552->name = "output_552";
  output_552->dtype = CSINN_DTYPE_FLOAT16;
  output_552->layout = CSINN_LAYOUT_NCHW;
  output_552->dim[0] = 4;
  output_552->dim[1] = 4;
  output_552->dim[2] = 16;
  output_552->dim[3] = 60;
  output_552->dim_count = 4;
  memcpy(output_552->qinfo, params_base + 4336148, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *indices_552 = csinn_alloc_tensor(sess);
  indices_552->name = "indices_552";
  indices_552->data = params_base + 4336196;
  indices_552->is_const = 1;
  indices_552->dtype = CSINN_DTYPE_INT64;
  indices_552->layout = CSINN_LAYOUT_O;
  indices_552->dim[0] = 1;
  indices_552->dim_count = 1;
  memcpy(indices_552->qinfo, params_base + 4336172, sizeof(struct csinn_quant_info) * 1);
  struct csinn_gather_params *params_552 = csinn_alloc_params(sizeof(struct csinn_gather_params), sess);
  params_552->axis = 2;
  params_552->base.name = "take_/layer_5/layer_5.1/global_rep.2/pre_norm_mha.1/Gather_1_434";
  params_552->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_gather_init(output_546, indices_552, output_552, params_552);
  int32_t *permute_553 = malloc(4 * 4);
  permute_553[0] = 0;
  permute_553[1] = 1;
  permute_553[2] = 3;
  permute_553[3] = 2;
  struct csinn_tensor *output_553 = csinn_alloc_tensor(sess);
  output_553->name = "output_553";
  output_553->dtype = CSINN_DTYPE_FLOAT16;
  output_553->layout = CSINN_LAYOUT_NCHW;
  output_553->dim[0] = 4;
  output_553->dim[1] = 4;
  output_553->dim[2] = 60;
  output_553->dim[3] = 16;
  output_553->dim_count = 4;
  memcpy(output_553->qinfo, params_base + 4336204, sizeof(struct csinn_quant_info) * 1);
  struct csinn_transpose_params *params_553 = csinn_alloc_params(sizeof(struct csinn_transpose_params), sess);
  params_553->permute = permute_553;
  params_553->permute_num = 4;
  params_553->base.name = "transpose_/layer_5/layer_5.1/global_rep.2/pre_norm_mha.1/Transpose_1_435";
  params_553->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_transpose_init(output_552, output_553, params_553);
  struct csinn_tensor *output_554 = csinn_alloc_tensor(sess);
  output_554->name = "output_554";
  output_554->dtype = CSINN_DTYPE_FLOAT16;
  output_554->layout = CSINN_LAYOUT_NCHW;
  output_554->dim[0] = 4;
  output_554->dim[1] = 4;
  output_554->dim[2] = 16;
  output_554->dim[3] = 16;
  output_554->dim_count = 4;
  memcpy(output_554->qinfo, params_base + 4336228, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_554 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_554->trans_a = false;
  params_554->trans_b = false;
  params_554->base.name = "batch_matmul_/layer_5/layer_5.1/global_rep.2/pre_norm_mha.1/MatMul_437";
  params_554->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_549, output_553, output_554, params_554);
  struct csinn_tensor *output_555 = csinn_alloc_tensor(sess);
  output_555->name = "output_555";
  output_555->dtype = CSINN_DTYPE_FLOAT16;
  output_555->layout = CSINN_LAYOUT_NCHW;
  output_555->dim[0] = 4;
  output_555->dim[1] = 4;
  output_555->dim[2] = 16;
  output_555->dim[3] = 16;
  output_555->dim_count = 4;
  memcpy(output_555->qinfo, params_base + 4336252, sizeof(struct csinn_quant_info) * 1);
  struct csinn_softmax_params *params_555 = csinn_alloc_params(sizeof(struct csinn_softmax_params), sess);
  params_555->axis = 3;
  params_555->base.name = "softmax_/layer_5/layer_5.1/global_rep.2/pre_norm_mha.1/softmax/Softmax_439";
  params_555->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_softmax_init(output_554, output_555, params_555);
  struct csinn_tensor *output_557 = csinn_alloc_tensor(sess);
  output_557->name = "output_557";
  output_557->dtype = CSINN_DTYPE_FLOAT16;
  output_557->layout = CSINN_LAYOUT_NCHW;
  output_557->dim[0] = 4;
  output_557->dim[1] = 4;
  output_557->dim[2] = 16;
  output_557->dim[3] = 60;
  output_557->dim_count = 4;
  memcpy(output_557->qinfo, params_base + 4336276, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *indices_557 = csinn_alloc_tensor(sess);
  indices_557->name = "indices_557";
  indices_557->data = params_base + 4336324;
  indices_557->is_const = 1;
  indices_557->dtype = CSINN_DTYPE_INT64;
  indices_557->layout = CSINN_LAYOUT_O;
  indices_557->dim[0] = 1;
  indices_557->dim_count = 1;
  memcpy(indices_557->qinfo, params_base + 4336300, sizeof(struct csinn_quant_info) * 1);
  struct csinn_gather_params *params_557 = csinn_alloc_params(sizeof(struct csinn_gather_params), sess);
  params_557->axis = 2;
  params_557->base.name = "take_/layer_5/layer_5.1/global_rep.2/pre_norm_mha.1/Gather_2_441";
  params_557->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_gather_init(output_546, indices_557, output_557, params_557);
  struct csinn_tensor *output_558 = csinn_alloc_tensor(sess);
  output_558->name = "output_558";
  output_558->dtype = CSINN_DTYPE_FLOAT16;
  output_558->layout = CSINN_LAYOUT_NCHW;
  output_558->dim[0] = 4;
  output_558->dim[1] = 4;
  output_558->dim[2] = 16;
  output_558->dim[3] = 60;
  output_558->dim_count = 4;
  memcpy(output_558->qinfo, params_base + 4336332, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_558 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_558->trans_a = false;
  params_558->trans_b = false;
  params_558->base.name = "batch_matmul_/layer_5/layer_5.1/global_rep.2/pre_norm_mha.1/MatMul_1_443";
  params_558->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_555, output_557, output_558, params_558);
  int32_t *permute_559 = malloc(4 * 4);
  permute_559[0] = 0;
  permute_559[1] = 2;
  permute_559[2] = 1;
  permute_559[3] = 3;
  struct csinn_tensor *output_559 = csinn_alloc_tensor(sess);
  output_559->name = "output_559";
  output_559->dtype = CSINN_DTYPE_FLOAT16;
  output_559->layout = CSINN_LAYOUT_NCHW;
  output_559->dim[0] = 4;
  output_559->dim[1] = 16;
  output_559->dim[2] = 4;
  output_559->dim[3] = 60;
  output_559->dim_count = 4;
  memcpy(output_559->qinfo, params_base + 4336356, sizeof(struct csinn_quant_info) * 1);
  struct csinn_transpose_params *params_559 = csinn_alloc_params(sizeof(struct csinn_transpose_params), sess);
  params_559->permute = permute_559;
  params_559->permute_num = 4;
  params_559->base.name = "transpose_/layer_5/layer_5.1/global_rep.2/pre_norm_mha.1/Transpose_2_445";
  params_559->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_transpose_init(output_558, output_559, params_559);
  int32_t *shape_560 = malloc(3 * 4);
  shape_560[0] = 4;
  shape_560[1] = 16;
  shape_560[2] = -1;
  struct csinn_tensor *output_560 = csinn_alloc_tensor(sess);
  output_560->name = "output_560";
  output_560->dtype = CSINN_DTYPE_FLOAT16;
  output_560->layout = CSINN_LAYOUT_NCW;
  output_560->dim[0] = 4;
  output_560->dim[1] = 16;
  output_560->dim[2] = 240;
  output_560->dim_count = 3;
  memcpy(output_560->qinfo, params_base + 4336380, sizeof(struct csinn_quant_info) * 1);
  struct csinn_reshape_params *params_560 = csinn_alloc_params(sizeof(struct csinn_reshape_params), sess);
  params_560->shape = shape_560;
  params_560->shape_num = 3;
  params_560->base.name = "reshape_/layer_5/layer_5.1/global_rep.2/pre_norm_mha.1/Reshape_1_446";
  params_560->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_reshape_init(output_559, output_560, params_560);
  struct csinn_tensor *output_562 = csinn_alloc_tensor(sess);
  output_562->name = "output_562";
  output_562->dtype = CSINN_DTYPE_FLOAT16;
  output_562->layout = CSINN_LAYOUT_NCW;
  output_562->dim[0] = 4;
  output_562->dim[1] = 16;
  output_562->dim[2] = 240;
  output_562->dim_count = 3;
  memcpy(output_562->qinfo, params_base + 4336404, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *data_b_562 = csinn_alloc_tensor(sess);
  data_b_562->name = "data_b_562";
  data_b_562->data = params_base + 4336452;
  data_b_562->is_const = 1;
  data_b_562->dtype = CSINN_DTYPE_INT8;
  data_b_562->layout = CSINN_LAYOUT_OIW;
  data_b_562->dim[0] = 1;
  data_b_562->dim[1] = 240;
  data_b_562->dim[2] = 240;
  data_b_562->dim_count = 3;
  memcpy(data_b_562->qinfo, params_base + 4336428, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_562 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_562->trans_a = false;
  params_562->trans_b = false;
  params_562->base.name = "batch_matmul_/layer_5/layer_5.1/global_rep.2/pre_norm_mha.1/out_proj/MatMul_447";
  params_562->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_560, data_b_562, output_562, params_562);
  struct csinn_tensor *output_564 = csinn_alloc_tensor(sess);
  output_564->name = "output_564";
  output_564->dtype = CSINN_DTYPE_FLOAT16;
  output_564->layout = CSINN_LAYOUT_NCW;
  output_564->dim[0] = 4;
  output_564->dim[1] = 16;
  output_564->dim[2] = 240;
  output_564->dim_count = 3;
  memcpy(output_564->qinfo, params_base + 4394052, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *rhs_564 = csinn_alloc_tensor(sess);
  rhs_564->name = "rhs_564";
  rhs_564->data = params_base + 4394100;
  rhs_564->is_const = 1;
  rhs_564->dtype = CSINN_DTYPE_FLOAT16;
  rhs_564->layout = CSINN_LAYOUT_OIW;
  rhs_564->dim[0] = 1;
  rhs_564->dim[1] = 1;
  rhs_564->dim[2] = 240;
  rhs_564->dim_count = 3;
  memcpy(rhs_564->qinfo, params_base + 4394076, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_564 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_564->base.name = "add_/layer_5/layer_5.1/global_rep.2/pre_norm_mha.1/out_proj/Add_449";
  params_564->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_562, rhs_564, output_564, params_564);
  struct csinn_tensor *output_567 = csinn_alloc_tensor(sess);
  output_567->name = "output_567";
  output_567->dtype = CSINN_DTYPE_FLOAT16;
  output_567->layout = CSINN_LAYOUT_NCW;
  output_567->dim[0] = 4;
  output_567->dim[1] = 16;
  output_567->dim[2] = 240;
  output_567->dim_count = 3;
  memcpy(output_567->qinfo, params_base + 4394580, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_567 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_567->base.name = "add_/layer_5/layer_5.1/global_rep.2/Add_450";
  params_567->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_564, output_537, output_567, params_567);
  struct csinn_tensor *output_570 = csinn_alloc_tensor(sess);
  output_570->name = "output_570";
  output_570->dtype = CSINN_DTYPE_FLOAT16;
  output_570->layout = CSINN_LAYOUT_NCW;
  output_570->dim[0] = 4;
  output_570->dim[1] = 16;
  output_570->dim[2] = 240;
  output_570->dim_count = 3;
  memcpy(output_570->qinfo, params_base + 4394604, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *gamma_570 = csinn_alloc_tensor(sess);
  gamma_570->name = "gamma_570";
  gamma_570->data = params_base + 4394652;
  gamma_570->is_const = 1;
  gamma_570->dtype = CSINN_DTYPE_FLOAT16;
  gamma_570->layout = CSINN_LAYOUT_O;
  gamma_570->dim[0] = 240;
  gamma_570->dim_count = 1;
  memcpy(gamma_570->qinfo, params_base + 4394628, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *beta_570 = csinn_alloc_tensor(sess);
  beta_570->name = "beta_570";
  beta_570->data = params_base + 4395156;
  beta_570->is_const = 1;
  beta_570->dtype = CSINN_DTYPE_FLOAT16;
  beta_570->layout = CSINN_LAYOUT_O;
  beta_570->dim[0] = 240;
  beta_570->dim_count = 1;
  memcpy(beta_570->qinfo, params_base + 4395132, sizeof(struct csinn_quant_info) * 1);
  struct csinn_layer_norm_params *params_570 = csinn_alloc_params(sizeof(struct csinn_layer_norm_params), sess);
  params_570->epsilon = 1e-05;
  params_570->axis = -1;
  params_570->center = true;
  params_570->scale = true;
  params_570->base.name = "layer_norm_451";
  params_570->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_layer_norm_init(output_567, output_570, gamma_570, beta_570, params_570);
  struct csinn_tensor *output_572 = csinn_alloc_tensor(sess);
  output_572->name = "output_572";
  output_572->dtype = CSINN_DTYPE_FLOAT16;
  output_572->layout = CSINN_LAYOUT_NCW;
  output_572->dim[0] = 4;
  output_572->dim[1] = 16;
  output_572->dim[2] = 480;
  output_572->dim_count = 3;
  memcpy(output_572->qinfo, params_base + 4395636, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *data_b_572 = csinn_alloc_tensor(sess);
  data_b_572->name = "data_b_572";
  data_b_572->data = params_base + 4395684;
  data_b_572->is_const = 1;
  data_b_572->dtype = CSINN_DTYPE_INT8;
  data_b_572->layout = CSINN_LAYOUT_OIW;
  data_b_572->dim[0] = 1;
  data_b_572->dim[1] = 240;
  data_b_572->dim[2] = 480;
  data_b_572->dim_count = 3;
  memcpy(data_b_572->qinfo, params_base + 4395660, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_572 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_572->trans_a = false;
  params_572->trans_b = false;
  params_572->base.name = "batch_matmul_/layer_5/layer_5.1/global_rep.2/pre_norm_ffn/pre_norm_ffn.1/MatMul_452";
  params_572->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_570, data_b_572, output_572, params_572);
  struct csinn_tensor *output_574 = csinn_alloc_tensor(sess);
  output_574->name = "output_574";
  output_574->dtype = CSINN_DTYPE_FLOAT16;
  output_574->layout = CSINN_LAYOUT_NCW;
  output_574->dim[0] = 4;
  output_574->dim[1] = 16;
  output_574->dim[2] = 480;
  output_574->dim_count = 3;
  memcpy(output_574->qinfo, params_base + 4510884, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *rhs_574 = csinn_alloc_tensor(sess);
  rhs_574->name = "rhs_574";
  rhs_574->data = params_base + 4510932;
  rhs_574->is_const = 1;
  rhs_574->dtype = CSINN_DTYPE_FLOAT16;
  rhs_574->layout = CSINN_LAYOUT_OIW;
  rhs_574->dim[0] = 1;
  rhs_574->dim[1] = 1;
  rhs_574->dim[2] = 480;
  rhs_574->dim_count = 3;
  memcpy(rhs_574->qinfo, params_base + 4510908, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_574 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_574->base.name = "add_/layer_5/layer_5.1/global_rep.2/pre_norm_ffn/pre_norm_ffn.1/Add_454";
  params_574->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_572, rhs_574, output_574, params_574);
  struct csinn_tensor *output_577 = csinn_alloc_tensor(sess);
  output_577->name = "output_577";
  output_577->dtype = CSINN_DTYPE_FLOAT16;
  output_577->layout = CSINN_LAYOUT_NCW;
  output_577->dim[0] = 4;
  output_577->dim[1] = 16;
  output_577->dim[2] = 480;
  output_577->dim_count = 3;
  memcpy(output_577->qinfo, params_base + 4511892, sizeof(struct csinn_quant_info) * 1);
  struct csinn_sigmoid_params *params_577 = csinn_alloc_params(sizeof(struct csinn_sigmoid_params), sess);
  params_577->base.name = "sigmoid_/layer_5/layer_5.1/global_rep.2/pre_norm_ffn/pre_norm_ffn.2/Sigmoid_455";
  params_577->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_sigmoid_init(output_574, output_577, params_577);
  struct csinn_tensor *output_578 = csinn_alloc_tensor(sess);
  output_578->name = "output_578";
  output_578->dtype = CSINN_DTYPE_FLOAT16;
  output_578->layout = CSINN_LAYOUT_NCW;
  output_578->dim[0] = 4;
  output_578->dim[1] = 16;
  output_578->dim[2] = 480;
  output_578->dim_count = 3;
  memcpy(output_578->qinfo, params_base + 4511916, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_578 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_578->base.name = "multiply_/layer_5/layer_5.1/global_rep.2/pre_norm_ffn/pre_norm_ffn.2/Mul_456";
  params_578->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_mul_init(output_574, output_577, output_578, params_578);
  struct csinn_tensor *output_581 = csinn_alloc_tensor(sess);
  output_581->name = "output_581";
  output_581->dtype = CSINN_DTYPE_FLOAT16;
  output_581->layout = CSINN_LAYOUT_NCW;
  output_581->dim[0] = 4;
  output_581->dim[1] = 16;
  output_581->dim[2] = 240;
  output_581->dim_count = 3;
  memcpy(output_581->qinfo, params_base + 4511940, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *data_b_581 = csinn_alloc_tensor(sess);
  data_b_581->name = "data_b_581";
  data_b_581->data = params_base + 4511988;
  data_b_581->is_const = 1;
  data_b_581->dtype = CSINN_DTYPE_INT8;
  data_b_581->layout = CSINN_LAYOUT_OIW;
  data_b_581->dim[0] = 1;
  data_b_581->dim[1] = 480;
  data_b_581->dim[2] = 240;
  data_b_581->dim_count = 3;
  memcpy(data_b_581->qinfo, params_base + 4511964, sizeof(struct csinn_quant_info) * 1);
  struct csinn_matmul_params *params_581 = csinn_alloc_params(sizeof(struct csinn_matmul_params), sess);
  params_581->trans_a = false;
  params_581->trans_b = false;
  params_581->base.name = "batch_matmul_/layer_5/layer_5.1/global_rep.2/pre_norm_ffn/pre_norm_ffn.4/MatMul_457";
  params_581->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_matmul_init(output_578, data_b_581, output_581, params_581);
  struct csinn_tensor *output_583 = csinn_alloc_tensor(sess);
  output_583->name = "output_583";
  output_583->dtype = CSINN_DTYPE_FLOAT16;
  output_583->layout = CSINN_LAYOUT_NCW;
  output_583->dim[0] = 4;
  output_583->dim[1] = 16;
  output_583->dim[2] = 240;
  output_583->dim_count = 3;
  memcpy(output_583->qinfo, params_base + 4627188, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *rhs_583 = csinn_alloc_tensor(sess);
  rhs_583->name = "rhs_583";
  rhs_583->data = params_base + 4627236;
  rhs_583->is_const = 1;
  rhs_583->dtype = CSINN_DTYPE_FLOAT16;
  rhs_583->layout = CSINN_LAYOUT_OIW;
  rhs_583->dim[0] = 1;
  rhs_583->dim[1] = 1;
  rhs_583->dim[2] = 240;
  rhs_583->dim_count = 3;
  memcpy(rhs_583->qinfo, params_base + 4627212, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_583 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_583->base.name = "add_/layer_5/layer_5.1/global_rep.2/pre_norm_ffn/pre_norm_ffn.4/Add_459";
  params_583->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_581, rhs_583, output_583, params_583);
  struct csinn_tensor *output_585 = csinn_alloc_tensor(sess);
  output_585->name = "output_585";
  output_585->dtype = CSINN_DTYPE_FLOAT16;
  output_585->layout = CSINN_LAYOUT_NCW;
  output_585->dim[0] = 4;
  output_585->dim[1] = 16;
  output_585->dim[2] = 240;
  output_585->dim_count = 3;
  memcpy(output_585->qinfo, params_base + 4627716, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_585 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_585->base.name = "add_/layer_5/layer_5.1/global_rep.2/Add_1_460";
  params_585->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_567, output_583, output_585, params_585);
  struct csinn_tensor *output_587 = csinn_alloc_tensor(sess);
  output_587->name = "output_587";
  output_587->dtype = CSINN_DTYPE_FLOAT16;
  output_587->layout = CSINN_LAYOUT_NCW;
  output_587->dim[0] = 4;
  output_587->dim[1] = 16;
  output_587->dim[2] = 240;
  output_587->dim_count = 3;
  memcpy(output_587->qinfo, params_base + 4627740, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *gamma_587 = csinn_alloc_tensor(sess);
  gamma_587->name = "gamma_587";
  gamma_587->data = params_base + 4627788;
  gamma_587->is_const = 1;
  gamma_587->dtype = CSINN_DTYPE_FLOAT16;
  gamma_587->layout = CSINN_LAYOUT_O;
  gamma_587->dim[0] = 240;
  gamma_587->dim_count = 1;
  memcpy(gamma_587->qinfo, params_base + 4627764, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *beta_587 = csinn_alloc_tensor(sess);
  beta_587->name = "beta_587";
  beta_587->data = params_base + 4628292;
  beta_587->is_const = 1;
  beta_587->dtype = CSINN_DTYPE_FLOAT16;
  beta_587->layout = CSINN_LAYOUT_O;
  beta_587->dim[0] = 240;
  beta_587->dim_count = 1;
  memcpy(beta_587->qinfo, params_base + 4628268, sizeof(struct csinn_quant_info) * 1);
  struct csinn_layer_norm_params *params_587 = csinn_alloc_params(sizeof(struct csinn_layer_norm_params), sess);
  params_587->epsilon = 1e-05;
  params_587->axis = -1;
  params_587->center = true;
  params_587->scale = true;
  params_587->base.name = "layer_norm_461";
  params_587->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_layer_norm_init(output_585, output_587, gamma_587, beta_587, params_587);
  int32_t *shape_588 = malloc(4 * 4);
  shape_588[0] = 1;
  shape_588[1] = 4;
  shape_588[2] = 16;
  shape_588[3] = -1;
  struct csinn_tensor *output_588 = csinn_alloc_tensor(sess);
  output_588->name = "output_588";
  output_588->dtype = CSINN_DTYPE_FLOAT16;
  output_588->layout = CSINN_LAYOUT_NCHW;
  output_588->dim[0] = 1;
  output_588->dim[1] = 4;
  output_588->dim[2] = 16;
  output_588->dim[3] = 240;
  output_588->dim_count = 4;
  memcpy(output_588->qinfo, params_base + 4628772, sizeof(struct csinn_quant_info) * 1);
  struct csinn_reshape_params *params_588 = csinn_alloc_params(sizeof(struct csinn_reshape_params), sess);
  params_588->shape = shape_588;
  params_588->shape_num = 4;
  params_588->base.name = "reshape_/layer_5/layer_5.1/Reshape_3_462";
  params_588->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_reshape_init(output_587, output_588, params_588);
  int32_t *permute_589 = malloc(4 * 4);
  permute_589[0] = 0;
  permute_589[1] = 3;
  permute_589[2] = 2;
  permute_589[3] = 1;
  struct csinn_tensor *output_589 = csinn_alloc_tensor(sess);
  output_589->name = "output_589";
  output_589->dtype = CSINN_DTYPE_FLOAT16;
  output_589->layout = CSINN_LAYOUT_NCHW;
  output_589->dim[0] = 1;
  output_589->dim[1] = 240;
  output_589->dim[2] = 16;
  output_589->dim[3] = 4;
  output_589->dim_count = 4;
  memcpy(output_589->qinfo, params_base + 4628796, sizeof(struct csinn_quant_info) * 1);
  struct csinn_transpose_params *params_589 = csinn_alloc_params(sizeof(struct csinn_transpose_params), sess);
  params_589->permute = permute_589;
  params_589->permute_num = 4;
  params_589->base.name = "transpose_/layer_5/layer_5.1/Transpose_2_463";
  params_589->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_transpose_init(output_588, output_589, params_589);
  int32_t *shape_590 = malloc(4 * 4);
  shape_590[0] = 960;
  shape_590[1] = 4;
  shape_590[2] = 2;
  shape_590[3] = 2;
  struct csinn_tensor *output_590 = csinn_alloc_tensor(sess);
  output_590->name = "output_590";
  output_590->dtype = CSINN_DTYPE_FLOAT16;
  output_590->layout = CSINN_LAYOUT_NCHW;
  output_590->dim[0] = 960;
  output_590->dim[1] = 4;
  output_590->dim[2] = 2;
  output_590->dim[3] = 2;
  output_590->dim_count = 4;
  memcpy(output_590->qinfo, params_base + 4628820, sizeof(struct csinn_quant_info) * 1);
  struct csinn_reshape_params *params_590 = csinn_alloc_params(sizeof(struct csinn_reshape_params), sess);
  params_590->shape = shape_590;
  params_590->shape_num = 4;
  params_590->base.name = "reshape_/layer_5/layer_5.1/Reshape_4_464";
  params_590->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_reshape_init(output_589, output_590, params_590);
  int32_t *permute_591 = malloc(4 * 4);
  permute_591[0] = 0;
  permute_591[1] = 2;
  permute_591[2] = 1;
  permute_591[3] = 3;
  struct csinn_tensor *output_591 = csinn_alloc_tensor(sess);
  output_591->name = "output_591";
  output_591->dtype = CSINN_DTYPE_FLOAT16;
  output_591->layout = CSINN_LAYOUT_NCHW;
  output_591->dim[0] = 960;
  output_591->dim[1] = 2;
  output_591->dim[2] = 4;
  output_591->dim[3] = 2;
  output_591->dim_count = 4;
  memcpy(output_591->qinfo, params_base + 4628844, sizeof(struct csinn_quant_info) * 1);
  struct csinn_transpose_params *params_591 = csinn_alloc_params(sizeof(struct csinn_transpose_params), sess);
  params_591->permute = permute_591;
  params_591->permute_num = 4;
  params_591->base.name = "transpose_/layer_5/layer_5.1/Transpose_3_465";
  params_591->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_transpose_init(output_590, output_591, params_591);
  int32_t *shape_592 = malloc(4 * 4);
  shape_592[0] = 1;
  shape_592[1] = 240;
  shape_592[2] = 8;
  shape_592[3] = 8;
  struct csinn_tensor *output_592 = csinn_alloc_tensor(sess);
  output_592->name = "output_592";
  output_592->dtype = CSINN_DTYPE_FLOAT16;
  output_592->layout = CSINN_LAYOUT_NCHW;
  output_592->dim[0] = 1;
  output_592->dim[1] = 240;
  output_592->dim[2] = 8;
  output_592->dim[3] = 8;
  output_592->dim_count = 4;
  memcpy(output_592->qinfo, params_base + 4628868, sizeof(struct csinn_quant_info) * 1);
  struct csinn_reshape_params *params_592 = csinn_alloc_params(sizeof(struct csinn_reshape_params), sess);
  params_592->shape = shape_592;
  params_592->shape_num = 4;
  params_592->base.name = "reshape_/layer_5/layer_5.1/Reshape_5_466";
  params_592->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_reshape_init(output_591, output_592, params_592);
  struct csinn_tensor *output_593 = csinn_alloc_tensor(sess);
  output_593->name = "output_593";
  output_593->dtype = CSINN_DTYPE_FLOAT16;
  output_593->layout = CSINN_LAYOUT_NCHW;
  output_593->dim[0] = 1;
  output_593->dim[1] = 160;
  output_593->dim[2] = 8;
  output_593->dim[3] = 8;
  output_593->dim_count = 4;
  memcpy(output_593->qinfo, params_base + 4628892, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_593 = csinn_alloc_tensor(sess);
  kernel_593->name = "kernel_593";
  kernel_593->data = params_base + 4632756;
  kernel_593->is_const = 1;
  kernel_593->dtype = CSINN_DTYPE_INT8;
  kernel_593->layout = CSINN_LAYOUT_OIHW;
  kernel_593->dim[0] = 160;
  kernel_593->dim[1] = 240;
  kernel_593->dim[2] = 1;
  kernel_593->dim[3] = 1;
  kernel_593->dim_count = 4;
  csinn_realloc_quant_info(kernel_593, 160);
  memcpy(kernel_593->qinfo, params_base + 4628916, sizeof(struct csinn_quant_info) * 160);
  struct csinn_tensor *bias_593 = csinn_alloc_tensor(sess);
  bias_593->name = "bias_593";
  bias_593->data = params_base + 4674996;
  bias_593->is_const = 1;
  bias_593->dtype = CSINN_DTYPE_FLOAT16;
  bias_593->layout = CSINN_LAYOUT_O;
  bias_593->dim[0] = 160;
  bias_593->dim_count = 1;
  csinn_realloc_quant_info(bias_593, 160);
  memcpy(bias_593->qinfo, params_base + 4671156, sizeof(struct csinn_quant_info) * 160);
  struct csinn_conv2d_params *params_593 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_593->group = 1;
  params_593->stride_height = 1;
  params_593->stride_width = 1;
  params_593->dilation_height = 1;
  params_593->dilation_width = 1;
  params_593->conv_extra.kernel_tm = NULL;
  params_593->conv_extra.conv_mode = CSINN_DIRECT;
  params_593->pad_top = 0;
  params_593->pad_left = 0;
  params_593->pad_down = 0;
  params_593->pad_right = 0;
  params_593->base.name = "conv2d_/layer_5/layer_5.1/conv_proj/block/conv/Conv_467_fuse_bias_add_/layer_5/layer_5.1/conv_proj/block/conv/Conv_468";
  params_593->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_592, output_593, kernel_593, bias_593, params_593);
  struct csinn_tensor *output_595 = csinn_alloc_tensor(sess);
  output_595->name = "output_595";
  output_595->dtype = CSINN_DTYPE_FLOAT16;
  output_595->layout = CSINN_LAYOUT_NCHW;
  output_595->dim[0] = 1;
  output_595->dim[1] = 160;
  output_595->dim[2] = 8;
  output_595->dim[3] = 8;
  output_595->dim_count = 4;
  memcpy(output_595->qinfo, params_base + 4675316, sizeof(struct csinn_quant_info) * 1);
  struct csinn_sigmoid_params *params_595 = csinn_alloc_params(sizeof(struct csinn_sigmoid_params), sess);
  params_595->base.name = "sigmoid_/layer_5/layer_5.1/conv_proj/block/act/Sigmoid_469";
  params_595->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_sigmoid_init(output_593, output_595, params_595);
  struct csinn_tensor *output_596 = csinn_alloc_tensor(sess);
  output_596->name = "output_596";
  output_596->dtype = CSINN_DTYPE_FLOAT16;
  output_596->layout = CSINN_LAYOUT_NCHW;
  output_596->dim[0] = 1;
  output_596->dim[1] = 160;
  output_596->dim[2] = 8;
  output_596->dim[3] = 8;
  output_596->dim_count = 4;
  memcpy(output_596->qinfo, params_base + 4675340, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_596 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_596->base.name = "multiply_/layer_5/layer_5.1/conv_proj/block/act/Mul_470";
  params_596->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_mul_init(output_593, output_595, output_596, params_596);
  struct csinn_tensor *input_598_concat[2];
  struct csinn_tensor *output_598 = csinn_alloc_tensor(sess);
  output_598->name = "output_598";
  output_598->dtype = CSINN_DTYPE_FLOAT16;
  output_598->layout = CSINN_LAYOUT_NCHW;
  output_598->dim[0] = 1;
  output_598->dim[1] = 320;
  output_598->dim[2] = 8;
  output_598->dim[3] = 8;
  output_598->dim_count = 4;
  memcpy(output_598->qinfo, params_base + 4675364, sizeof(struct csinn_quant_info) * 1);
  struct csinn_concat_params *params_598 = csinn_alloc_params(sizeof(struct csinn_concat_params), sess);
  params_598->inputs_count = 2;
  params_598->axis = 1;
  params_598->base.name = "concatenate_/layer_5/layer_5.1/Concat_471";
  params_598->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_concat_init(input_598_concat, output_598, params_598);
  struct csinn_tensor *output_599 = csinn_alloc_tensor(sess);
  output_599->name = "output_599";
  output_599->dtype = CSINN_DTYPE_FLOAT16;
  output_599->layout = CSINN_LAYOUT_NCHW;
  output_599->dim[0] = 1;
  output_599->dim[1] = 160;
  output_599->dim[2] = 8;
  output_599->dim[3] = 8;
  output_599->dim_count = 4;
  memcpy(output_599->qinfo, params_base + 4675388, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_599 = csinn_alloc_tensor(sess);
  kernel_599->name = "kernel_599";
  kernel_599->data = params_base + 4679252;
  kernel_599->is_const = 1;
  kernel_599->dtype = CSINN_DTYPE_INT8;
  kernel_599->layout = CSINN_LAYOUT_OIHW;
  kernel_599->dim[0] = 160;
  kernel_599->dim[1] = 320;
  kernel_599->dim[2] = 3;
  kernel_599->dim[3] = 3;
  kernel_599->dim_count = 4;
  csinn_realloc_quant_info(kernel_599, 160);
  memcpy(kernel_599->qinfo, params_base + 4675412, sizeof(struct csinn_quant_info) * 160);
  struct csinn_tensor *bias_599 = csinn_alloc_tensor(sess);
  bias_599->name = "bias_599";
  bias_599->data = params_base + 5143892;
  bias_599->is_const = 1;
  bias_599->dtype = CSINN_DTYPE_FLOAT16;
  bias_599->layout = CSINN_LAYOUT_O;
  bias_599->dim[0] = 160;
  bias_599->dim_count = 1;
  csinn_realloc_quant_info(bias_599, 160);
  memcpy(bias_599->qinfo, params_base + 5140052, sizeof(struct csinn_quant_info) * 160);
  struct csinn_conv2d_params *params_599 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_599->group = 1;
  params_599->stride_height = 1;
  params_599->stride_width = 1;
  params_599->dilation_height = 1;
  params_599->dilation_width = 1;
  params_599->conv_extra.kernel_tm = NULL;
  params_599->conv_extra.conv_mode = CSINN_DIRECT;
  params_599->pad_top = 1;
  params_599->pad_left = 1;
  params_599->pad_down = 1;
  params_599->pad_right = 1;
  params_599->base.name = "conv2d_/layer_5/layer_5.1/fusion/block/conv/Conv_472_fuse_bias_add_/layer_5/layer_5.1/fusion/block/conv/Conv_473";
  params_599->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_598, output_599, kernel_599, bias_599, params_599);
  struct csinn_tensor *output_601 = csinn_alloc_tensor(sess);
  output_601->name = "output_601";
  output_601->dtype = CSINN_DTYPE_FLOAT16;
  output_601->layout = CSINN_LAYOUT_NCHW;
  output_601->dim[0] = 1;
  output_601->dim[1] = 160;
  output_601->dim[2] = 8;
  output_601->dim[3] = 8;
  output_601->dim_count = 4;
  memcpy(output_601->qinfo, params_base + 5144212, sizeof(struct csinn_quant_info) * 1);
  struct csinn_sigmoid_params *params_601 = csinn_alloc_params(sizeof(struct csinn_sigmoid_params), sess);
  params_601->base.name = "sigmoid_/layer_5/layer_5.1/fusion/block/act/Sigmoid_474";
  params_601->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_sigmoid_init(output_599, output_601, params_601);
  struct csinn_tensor *output_602 = csinn_alloc_tensor(sess);
  output_602->name = "output_602";
  output_602->dtype = CSINN_DTYPE_FLOAT16;
  output_602->layout = CSINN_LAYOUT_NCHW;
  output_602->dim[0] = 1;
  output_602->dim[1] = 160;
  output_602->dim[2] = 8;
  output_602->dim[3] = 8;
  output_602->dim_count = 4;
  memcpy(output_602->qinfo, params_base + 5144236, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_602 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_602->base.name = "multiply_/layer_5/layer_5.1/fusion/block/act/Mul_475";
  params_602->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_mul_init(output_599, output_601, output_602, params_602);
  struct csinn_tensor *output_604 = csinn_alloc_tensor(sess);
  output_604->name = "output_604";
  output_604->dtype = CSINN_DTYPE_FLOAT16;
  output_604->layout = CSINN_LAYOUT_NCHW;
  output_604->dim[0] = 1;
  output_604->dim[1] = 640;
  output_604->dim[2] = 8;
  output_604->dim[3] = 8;
  output_604->dim_count = 4;
  memcpy(output_604->qinfo, params_base + 5144260, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_604 = csinn_alloc_tensor(sess);
  kernel_604->name = "kernel_604";
  kernel_604->data = params_base + 5159644;
  kernel_604->is_const = 1;
  kernel_604->dtype = CSINN_DTYPE_INT8;
  kernel_604->layout = CSINN_LAYOUT_OIHW;
  kernel_604->dim[0] = 640;
  kernel_604->dim[1] = 160;
  kernel_604->dim[2] = 1;
  kernel_604->dim[3] = 1;
  kernel_604->dim_count = 4;
  csinn_realloc_quant_info(kernel_604, 640);
  memcpy(kernel_604->qinfo, params_base + 5144284, sizeof(struct csinn_quant_info) * 640);
  struct csinn_tensor *bias_604 = csinn_alloc_tensor(sess);
  bias_604->name = "bias_604";
  bias_604->data = params_base + 5277404;
  bias_604->is_const = 1;
  bias_604->dtype = CSINN_DTYPE_FLOAT16;
  bias_604->layout = CSINN_LAYOUT_O;
  bias_604->dim[0] = 640;
  bias_604->dim_count = 1;
  csinn_realloc_quant_info(bias_604, 640);
  memcpy(bias_604->qinfo, params_base + 5262044, sizeof(struct csinn_quant_info) * 640);
  struct csinn_conv2d_params *params_604 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_604->group = 1;
  params_604->stride_height = 1;
  params_604->stride_width = 1;
  params_604->dilation_height = 1;
  params_604->dilation_width = 1;
  params_604->conv_extra.kernel_tm = NULL;
  params_604->conv_extra.conv_mode = CSINN_DIRECT;
  params_604->pad_top = 0;
  params_604->pad_left = 0;
  params_604->pad_down = 0;
  params_604->pad_right = 0;
  params_604->base.name = "conv2d_/conv_1x1_exp/block/conv/Conv_476_fuse_bias_add_/conv_1x1_exp/block/conv/Conv_477";
  params_604->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_602, output_604, kernel_604, bias_604, params_604);
  struct csinn_tensor *output_606 = csinn_alloc_tensor(sess);
  output_606->name = "output_606";
  output_606->dtype = CSINN_DTYPE_FLOAT16;
  output_606->layout = CSINN_LAYOUT_NCHW;
  output_606->dim[0] = 1;
  output_606->dim[1] = 640;
  output_606->dim[2] = 8;
  output_606->dim[3] = 8;
  output_606->dim_count = 4;
  memcpy(output_606->qinfo, params_base + 5278684, sizeof(struct csinn_quant_info) * 1);
  struct csinn_sigmoid_params *params_606 = csinn_alloc_params(sizeof(struct csinn_sigmoid_params), sess);
  params_606->base.name = "sigmoid_/conv_1x1_exp/block/act/Sigmoid_478";
  params_606->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_sigmoid_init(output_604, output_606, params_606);
  struct csinn_tensor *output_607 = csinn_alloc_tensor(sess);
  output_607->name = "output_607";
  output_607->dtype = CSINN_DTYPE_FLOAT16;
  output_607->layout = CSINN_LAYOUT_NCHW;
  output_607->dim[0] = 1;
  output_607->dim[1] = 640;
  output_607->dim[2] = 8;
  output_607->dim[3] = 8;
  output_607->dim_count = 4;
  memcpy(output_607->qinfo, params_base + 5278708, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_607 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_607->base.name = "multiply_/conv_1x1_exp/block/act/Mul_479";
  params_607->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_mul_init(output_604, output_606, output_607, params_607);
  int32_t *out_strides_609 = malloc(2 * 4);
  int32_t *out_extents_609 = malloc(2 * 4);
  out_strides_609[0] = 40960;
  out_strides_609[1] = 64;
  out_extents_609[0] = 1;
  out_extents_609[1] = 640;
  int32_t *inner_strides_609 = malloc(2 * 4);
  int32_t *inner_extents_609 = malloc(2 * 4);
  inner_strides_609[0] = 8;
  inner_strides_609[1] = 1;
  inner_extents_609[0] = 8;
  inner_extents_609[1] = 8;
  int32_t *aixs_609 = malloc(2 * 4);
  aixs_609[0] = -2;
  aixs_609[1] = -1;
  struct csinn_tensor *output_609 = csinn_alloc_tensor(sess);
  output_609->name = "output_609";
  output_609->dtype = CSINN_DTYPE_FLOAT16;
  output_609->layout = CSINN_LAYOUT_NC;
  output_609->dim[0] = 1;
  output_609->dim[1] = 640;
  output_609->dim_count = 2;
  memcpy(output_609->qinfo, params_base + 5278732, sizeof(struct csinn_quant_info) * 1);
  struct csinn_reduce_params *params_609 = csinn_alloc_params(sizeof(struct csinn_reduce_params), sess);
  params_609->out_strides = out_strides_609;
  params_609->out_extents = out_extents_609;
  params_609->n = 2;
  params_609->inner_strides = inner_strides_609;
  params_609->inner_extents = inner_extents_609;
  params_609->m = 2;
  params_609->axis = aixs_609;
  params_609->axis_count = 2;
  params_609->keepdims = false;
  params_609->base.name = "mean_/classifier/global_pool/ReduceMean_480";
  params_609->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_mean_init(output_607, output_609, params_609);
  struct csinn_tensor *output_610 = csinn_alloc_tensor(sess);
  output_610->name = "dense_/classifier/fc/Gemm_481_fuse_add_output@@/classifier/fc/Gemm_482_610";
  output_610->dtype = CSINN_DTYPE_FLOAT16;
  output_610->layout = CSINN_LAYOUT_NC;
  output_610->dim[0] = 1;
  output_610->dim[1] = 1000;
  output_610->dim_count = 2;
  memcpy(output_610->qinfo, params_base + 5278756, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_610 = csinn_alloc_tensor(sess);
  kernel_610->name = "kernel_610";
  kernel_610->data = params_base + 5278804;
  kernel_610->is_const = 1;
  kernel_610->dtype = CSINN_DTYPE_INT8;
  kernel_610->layout = CSINN_LAYOUT_OI;
  kernel_610->dim[0] = 1000;
  kernel_610->dim[1] = 640;
  kernel_610->dim_count = 2;
  memcpy(kernel_610->qinfo, params_base + 5278780, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *bias_610 = csinn_alloc_tensor(sess);
  bias_610->name = "bias_610";
  bias_610->data = params_base + 5918828;
  bias_610->is_const = 1;
  bias_610->dtype = CSINN_DTYPE_FLOAT16;
  bias_610->layout = CSINN_LAYOUT_O;
  bias_610->dim[0] = 1000;
  bias_610->dim_count = 1;
  memcpy(bias_610->qinfo, params_base + 5918804, sizeof(struct csinn_quant_info) * 1);
  struct csinn_fc_params *params_610 = csinn_alloc_params(sizeof(struct csinn_fc_params), sess);
  params_610->units = 1000;
  params_610->base.name = "dense_/classifier/fc/Gemm_481_fuse_add_output@@/classifier/fc/Gemm_482";
  params_610->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_fullyconnected_init(output_609, output_610, kernel_610, bias_610, params_610);
  csinn_set_tensor_entry(input, sess);
  csinn_set_input(0, input, sess);

  csinn_conv2d(input, output_0, kernel_0, bias_0, params_0);
  csinn_sigmoid(output_0, output_2, params_2);
  csinn_mul(output_0, output_2, output_3, params_3);
  csinn_conv2d(output_3, output_5, kernel_5, bias_5, params_5);
  csinn_sigmoid(output_5, output_7, params_7);
  csinn_mul(output_5, output_7, output_8, params_8);
  csinn_conv2d(output_8, output_10, kernel_10, bias_10, params_10);
  csinn_sigmoid(output_10, output_12, params_12);
  csinn_mul(output_10, output_12, output_13, params_13);
  csinn_conv2d(output_13, output_15, kernel_15, bias_15, params_15);
  csinn_conv2d(output_15, output_16, kernel_16, bias_16, params_16);
  csinn_sigmoid(output_16, output_18, params_18);
  csinn_mul(output_16, output_18, output_19, params_19);
  csinn_conv2d(output_19, output_21, kernel_21, bias_21, params_21);
  csinn_sigmoid(output_21, output_23, params_23);
  csinn_mul(output_21, output_23, output_24, params_24);
  csinn_conv2d(output_24, output_26, kernel_26, bias_26, params_26);
  csinn_conv2d(output_26, output_28, kernel_28, bias_28, params_28);
  csinn_sigmoid(output_28, output_30, params_30);
  csinn_mul(output_28, output_30, output_31, params_31);
  csinn_conv2d(output_31, output_33, kernel_33, bias_33, params_33);
  csinn_sigmoid(output_33, output_35, params_35);
  csinn_mul(output_33, output_35, output_36, params_36);
  csinn_conv2d(output_36, output_38, kernel_38, bias_38, params_38);
  csinn_add(output_26, output_38, output_39, params_39);
  csinn_conv2d(output_39, output_42, kernel_42, bias_42, params_42);
  csinn_sigmoid(output_42, output_44, params_44);
  csinn_mul(output_42, output_44, output_45, params_45);
  csinn_conv2d(output_45, output_47, kernel_47, bias_47, params_47);
  csinn_sigmoid(output_47, output_49, params_49);
  csinn_mul(output_47, output_49, output_50, params_50);
  csinn_conv2d(output_50, output_52, kernel_52, bias_52, params_52);
  csinn_add(output_39, output_52, output_53, params_53);
  csinn_conv2d(output_53, output_55, kernel_55, bias_55, params_55);
  csinn_sigmoid(output_55, output_57, params_57);
  csinn_mul(output_55, output_57, output_58, params_58);
  csinn_conv2d(output_58, output_60, kernel_60, bias_60, params_60);
  csinn_sigmoid(output_60, output_62, params_62);
  csinn_mul(output_60, output_62, output_63, params_63);
  csinn_conv2d(output_63, output_65, kernel_65, bias_65, params_65);
  csinn_conv2d(output_65, output_66, kernel_66, bias_66, params_66);
  csinn_sigmoid(output_66, output_68, params_68);
  csinn_mul(output_66, output_68, output_69, params_69);
  csinn_conv2d(output_69, output_71, kernel_71, bias_71, params_71);
  csinn_reshape(output_71, output_72, params_72);
  csinn_transpose(output_72, output_73, params_73);
  csinn_reshape(output_73, output_74, params_74);
  csinn_transpose(output_74, output_75, params_75);
  csinn_reshape(output_75, output_76, params_76);
  csinn_layer_norm(output_76, output_77, gamma_77, beta_77, params_77);
  csinn_matmul(output_77, data_b_79, output_79, params_79);
  csinn_add(output_79, rhs_81, output_81, params_81);
  csinn_reshape(output_81, output_83, params_83);
  csinn_transpose(output_83, output_84, params_84);
  csinn_gather(output_84, indices_85, output_85, params_85);
  csinn_mul(output_85, rhs_87, output_87, params_87);
  csinn_gather(output_84, indices_90, output_90, params_90);
  csinn_transpose(output_90, output_91, params_91);
  csinn_matmul(output_87, output_91, output_92, params_92);
  csinn_softmax(output_92, output_93, params_93);
  csinn_gather(output_84, indices_95, output_95, params_95);
  csinn_matmul(output_93, output_95, output_96, params_96);
  csinn_transpose(output_96, output_97, params_97);
  csinn_reshape(output_97, output_98, params_98);
  csinn_matmul(output_98, data_b_100, output_100, params_100);
  csinn_add(output_100, rhs_102, output_102, params_102);
  csinn_add(output_102, output_76, output_105, params_105);
  csinn_layer_norm(output_105, output_108, gamma_108, beta_108, params_108);
  csinn_matmul(output_108, data_b_110, output_110, params_110);
  csinn_add(output_110, rhs_112, output_112, params_112);
  csinn_sigmoid(output_112, output_115, params_115);
  csinn_mul(output_112, output_115, output_116, params_116);
  csinn_matmul(output_116, data_b_119, output_119, params_119);
  csinn_add(output_119, rhs_121, output_121, params_121);
  csinn_add(output_105, output_121, output_123, params_123);
  csinn_layer_norm(output_123, output_125, gamma_125, beta_125, params_125);
  csinn_matmul(output_125, data_b_127, output_127, params_127);
  csinn_add(output_127, rhs_129, output_129, params_129);
  csinn_reshape(output_129, output_131, params_131);
  csinn_transpose(output_131, output_132, params_132);
  csinn_gather(output_132, indices_133, output_133, params_133);
  csinn_mul(output_133, rhs_135, output_135, params_135);
  csinn_gather(output_132, indices_138, output_138, params_138);
  csinn_transpose(output_138, output_139, params_139);
  csinn_matmul(output_135, output_139, output_140, params_140);
  csinn_softmax(output_140, output_141, params_141);
  csinn_gather(output_132, indices_143, output_143, params_143);
  csinn_matmul(output_141, output_143, output_144, params_144);
  csinn_transpose(output_144, output_145, params_145);
  csinn_reshape(output_145, output_146, params_146);
  csinn_matmul(output_146, data_b_148, output_148, params_148);
  csinn_add(output_148, rhs_150, output_150, params_150);
  csinn_add(output_150, output_123, output_153, params_153);
  csinn_layer_norm(output_153, output_156, gamma_156, beta_156, params_156);
  csinn_matmul(output_156, data_b_158, output_158, params_158);
  csinn_add(output_158, rhs_160, output_160, params_160);
  csinn_sigmoid(output_160, output_163, params_163);
  csinn_mul(output_160, output_163, output_164, params_164);
  csinn_matmul(output_164, data_b_167, output_167, params_167);
  csinn_add(output_167, rhs_169, output_169, params_169);
  csinn_add(output_153, output_169, output_171, params_171);
  csinn_layer_norm(output_171, output_173, gamma_173, beta_173, params_173);
  csinn_reshape(output_173, output_174, params_174);
  csinn_transpose(output_174, output_175, params_175);
  csinn_reshape(output_175, output_176, params_176);
  csinn_transpose(output_176, output_177, params_177);
  csinn_reshape(output_177, output_178, params_178);
  csinn_conv2d(output_178, output_179, kernel_179, bias_179, params_179);
  csinn_sigmoid(output_179, output_181, params_181);
  csinn_mul(output_179, output_181, output_182, params_182);
  input_184_concat[0] = output_65;
  input_184_concat[1] = output_182;
  csinn_concat(input_184_concat, output_184, params_184);
  csinn_conv2d(output_184, output_185, kernel_185, bias_185, params_185);
  csinn_sigmoid(output_185, output_187, params_187);
  csinn_mul(output_185, output_187, output_188, params_188);
  csinn_conv2d(output_188, output_190, kernel_190, bias_190, params_190);
  csinn_sigmoid(output_190, output_192, params_192);
  csinn_mul(output_190, output_192, output_193, params_193);
  csinn_conv2d(output_193, output_195, kernel_195, bias_195, params_195);
  csinn_sigmoid(output_195, output_197, params_197);
  csinn_mul(output_195, output_197, output_198, params_198);
  csinn_conv2d(output_198, output_200, kernel_200, bias_200, params_200);
  csinn_conv2d(output_200, output_201, kernel_201, bias_201, params_201);
  csinn_sigmoid(output_201, output_203, params_203);
  csinn_mul(output_201, output_203, output_204, params_204);
  csinn_conv2d(output_204, output_206, kernel_206, bias_206, params_206);
  csinn_reshape(output_206, output_207, params_207);
  csinn_transpose(output_207, output_208, params_208);
  csinn_reshape(output_208, output_209, params_209);
  csinn_transpose(output_209, output_210, params_210);
  csinn_reshape(output_210, output_211, params_211);
  csinn_layer_norm(output_211, output_212, gamma_212, beta_212, params_212);
  csinn_matmul(output_212, data_b_214, output_214, params_214);
  csinn_add(output_214, rhs_216, output_216, params_216);
  csinn_reshape(output_216, output_218, params_218);
  csinn_transpose(output_218, output_219, params_219);
  csinn_gather(output_219, indices_220, output_220, params_220);
  csinn_mul(output_220, rhs_222, output_222, params_222);
  csinn_gather(output_219, indices_225, output_225, params_225);
  csinn_transpose(output_225, output_226, params_226);
  csinn_matmul(output_222, output_226, output_227, params_227);
  csinn_softmax(output_227, output_228, params_228);
  csinn_gather(output_219, indices_230, output_230, params_230);
  csinn_matmul(output_228, output_230, output_231, params_231);
  csinn_transpose(output_231, output_232, params_232);
  csinn_reshape(output_232, output_233, params_233);
  csinn_matmul(output_233, data_b_235, output_235, params_235);
  csinn_add(output_235, rhs_237, output_237, params_237);
  csinn_add(output_237, output_211, output_240, params_240);
  csinn_layer_norm(output_240, output_243, gamma_243, beta_243, params_243);
  csinn_matmul(output_243, data_b_245, output_245, params_245);
  csinn_add(output_245, rhs_247, output_247, params_247);
  csinn_sigmoid(output_247, output_250, params_250);
  csinn_mul(output_247, output_250, output_251, params_251);
  csinn_matmul(output_251, data_b_254, output_254, params_254);
  csinn_add(output_254, rhs_256, output_256, params_256);
  csinn_add(output_240, output_256, output_258, params_258);
  csinn_layer_norm(output_258, output_260, gamma_260, beta_260, params_260);
  csinn_matmul(output_260, data_b_262, output_262, params_262);
  csinn_add(output_262, rhs_264, output_264, params_264);
  csinn_reshape(output_264, output_266, params_266);
  csinn_transpose(output_266, output_267, params_267);
  csinn_gather(output_267, indices_268, output_268, params_268);
  csinn_mul(output_268, rhs_270, output_270, params_270);
  csinn_gather(output_267, indices_273, output_273, params_273);
  csinn_transpose(output_273, output_274, params_274);
  csinn_matmul(output_270, output_274, output_275, params_275);
  csinn_softmax(output_275, output_276, params_276);
  csinn_gather(output_267, indices_278, output_278, params_278);
  csinn_matmul(output_276, output_278, output_279, params_279);
  csinn_transpose(output_279, output_280, params_280);
  csinn_reshape(output_280, output_281, params_281);
  csinn_matmul(output_281, data_b_283, output_283, params_283);
  csinn_add(output_283, rhs_285, output_285, params_285);
  csinn_add(output_285, output_258, output_288, params_288);
  csinn_layer_norm(output_288, output_291, gamma_291, beta_291, params_291);
  csinn_matmul(output_291, data_b_293, output_293, params_293);
  csinn_add(output_293, rhs_295, output_295, params_295);
  csinn_sigmoid(output_295, output_298, params_298);
  csinn_mul(output_295, output_298, output_299, params_299);
  csinn_matmul(output_299, data_b_302, output_302, params_302);
  csinn_add(output_302, rhs_304, output_304, params_304);
  csinn_add(output_288, output_304, output_306, params_306);
  csinn_layer_norm(output_306, output_308, gamma_308, beta_308, params_308);
  csinn_matmul(output_308, data_b_310, output_310, params_310);
  csinn_add(output_310, rhs_312, output_312, params_312);
  csinn_reshape(output_312, output_314, params_314);
  csinn_transpose(output_314, output_315, params_315);
  csinn_gather(output_315, indices_316, output_316, params_316);
  csinn_mul(output_316, rhs_318, output_318, params_318);
  csinn_gather(output_315, indices_321, output_321, params_321);
  csinn_transpose(output_321, output_322, params_322);
  csinn_matmul(output_318, output_322, output_323, params_323);
  csinn_softmax(output_323, output_324, params_324);
  csinn_gather(output_315, indices_326, output_326, params_326);
  csinn_matmul(output_324, output_326, output_327, params_327);
  csinn_transpose(output_327, output_328, params_328);
  csinn_reshape(output_328, output_329, params_329);
  csinn_matmul(output_329, data_b_331, output_331, params_331);
  csinn_add(output_331, rhs_333, output_333, params_333);
  csinn_add(output_333, output_306, output_336, params_336);
  csinn_layer_norm(output_336, output_339, gamma_339, beta_339, params_339);
  csinn_matmul(output_339, data_b_341, output_341, params_341);
  csinn_add(output_341, rhs_343, output_343, params_343);
  csinn_sigmoid(output_343, output_346, params_346);
  csinn_mul(output_343, output_346, output_347, params_347);
  csinn_matmul(output_347, data_b_350, output_350, params_350);
  csinn_add(output_350, rhs_352, output_352, params_352);
  csinn_add(output_336, output_352, output_354, params_354);
  csinn_layer_norm(output_354, output_356, gamma_356, beta_356, params_356);
  csinn_matmul(output_356, data_b_358, output_358, params_358);
  csinn_add(output_358, rhs_360, output_360, params_360);
  csinn_reshape(output_360, output_362, params_362);
  csinn_transpose(output_362, output_363, params_363);
  csinn_gather(output_363, indices_364, output_364, params_364);
  csinn_mul(output_364, rhs_366, output_366, params_366);
  csinn_gather(output_363, indices_369, output_369, params_369);
  csinn_transpose(output_369, output_370, params_370);
  csinn_matmul(output_366, output_370, output_371, params_371);
  csinn_softmax(output_371, output_372, params_372);
  csinn_gather(output_363, indices_374, output_374, params_374);
  csinn_matmul(output_372, output_374, output_375, params_375);
  csinn_transpose(output_375, output_376, params_376);
  csinn_reshape(output_376, output_377, params_377);
  csinn_matmul(output_377, data_b_379, output_379, params_379);
  csinn_add(output_379, rhs_381, output_381, params_381);
  csinn_add(output_381, output_354, output_384, params_384);
  csinn_layer_norm(output_384, output_387, gamma_387, beta_387, params_387);
  csinn_matmul(output_387, data_b_389, output_389, params_389);
  csinn_add(output_389, rhs_391, output_391, params_391);
  csinn_sigmoid(output_391, output_394, params_394);
  csinn_mul(output_391, output_394, output_395, params_395);
  csinn_matmul(output_395, data_b_398, output_398, params_398);
  csinn_add(output_398, rhs_400, output_400, params_400);
  csinn_add(output_384, output_400, output_402, params_402);
  csinn_layer_norm(output_402, output_404, gamma_404, beta_404, params_404);
  csinn_reshape(output_404, output_405, params_405);
  csinn_transpose(output_405, output_406, params_406);
  csinn_reshape(output_406, output_407, params_407);
  csinn_transpose(output_407, output_408, params_408);
  csinn_reshape(output_408, output_409, params_409);
  csinn_conv2d(output_409, output_410, kernel_410, bias_410, params_410);
  csinn_sigmoid(output_410, output_412, params_412);
  csinn_mul(output_410, output_412, output_413, params_413);
  input_415_concat[0] = output_200;
  input_415_concat[1] = output_413;
  csinn_concat(input_415_concat, output_415, params_415);
  csinn_conv2d(output_415, output_416, kernel_416, bias_416, params_416);
  csinn_sigmoid(output_416, output_418, params_418);
  csinn_mul(output_416, output_418, output_419, params_419);
  csinn_conv2d(output_419, output_421, kernel_421, bias_421, params_421);
  csinn_sigmoid(output_421, output_423, params_423);
  csinn_mul(output_421, output_423, output_424, params_424);
  csinn_conv2d(output_424, output_426, kernel_426, bias_426, params_426);
  csinn_sigmoid(output_426, output_428, params_428);
  csinn_mul(output_426, output_428, output_429, params_429);
  csinn_conv2d(output_429, output_431, kernel_431, bias_431, params_431);
  csinn_conv2d(output_431, output_432, kernel_432, bias_432, params_432);
  csinn_sigmoid(output_432, output_434, params_434);
  csinn_mul(output_432, output_434, output_435, params_435);
  csinn_conv2d(output_435, output_437, kernel_437, bias_437, params_437);
  csinn_reshape(output_437, output_438, params_438);
  csinn_transpose(output_438, output_439, params_439);
  csinn_reshape(output_439, output_440, params_440);
  csinn_transpose(output_440, output_441, params_441);
  csinn_reshape(output_441, output_442, params_442);
  csinn_layer_norm(output_442, output_443, gamma_443, beta_443, params_443);
  csinn_matmul(output_443, data_b_445, output_445, params_445);
  csinn_add(output_445, rhs_447, output_447, params_447);
  csinn_reshape(output_447, output_449, params_449);
  csinn_transpose(output_449, output_450, params_450);
  csinn_gather(output_450, indices_451, output_451, params_451);
  csinn_mul(output_451, rhs_453, output_453, params_453);
  csinn_gather(output_450, indices_456, output_456, params_456);
  csinn_transpose(output_456, output_457, params_457);
  csinn_matmul(output_453, output_457, output_458, params_458);
  csinn_softmax(output_458, output_459, params_459);
  csinn_gather(output_450, indices_461, output_461, params_461);
  csinn_matmul(output_459, output_461, output_462, params_462);
  csinn_transpose(output_462, output_463, params_463);
  csinn_reshape(output_463, output_464, params_464);
  csinn_matmul(output_464, data_b_466, output_466, params_466);
  csinn_add(output_466, rhs_468, output_468, params_468);
  csinn_add(output_468, output_442, output_471, params_471);
  csinn_layer_norm(output_471, output_474, gamma_474, beta_474, params_474);
  csinn_matmul(output_474, data_b_476, output_476, params_476);
  csinn_add(output_476, rhs_478, output_478, params_478);
  csinn_sigmoid(output_478, output_481, params_481);
  csinn_mul(output_478, output_481, output_482, params_482);
  csinn_matmul(output_482, data_b_485, output_485, params_485);
  csinn_add(output_485, rhs_487, output_487, params_487);
  csinn_add(output_471, output_487, output_489, params_489);
  csinn_layer_norm(output_489, output_491, gamma_491, beta_491, params_491);
  csinn_matmul(output_491, data_b_493, output_493, params_493);
  csinn_add(output_493, rhs_495, output_495, params_495);
  csinn_reshape(output_495, output_497, params_497);
  csinn_transpose(output_497, output_498, params_498);
  csinn_gather(output_498, indices_499, output_499, params_499);
  csinn_mul(output_499, rhs_501, output_501, params_501);
  csinn_gather(output_498, indices_504, output_504, params_504);
  csinn_transpose(output_504, output_505, params_505);
  csinn_matmul(output_501, output_505, output_506, params_506);
  csinn_softmax(output_506, output_507, params_507);
  csinn_gather(output_498, indices_509, output_509, params_509);
  csinn_matmul(output_507, output_509, output_510, params_510);
  csinn_transpose(output_510, output_511, params_511);
  csinn_reshape(output_511, output_512, params_512);
  csinn_matmul(output_512, data_b_514, output_514, params_514);
  csinn_add(output_514, rhs_516, output_516, params_516);
  csinn_add(output_516, output_489, output_519, params_519);
  csinn_layer_norm(output_519, output_522, gamma_522, beta_522, params_522);
  csinn_matmul(output_522, data_b_524, output_524, params_524);
  csinn_add(output_524, rhs_526, output_526, params_526);
  csinn_sigmoid(output_526, output_529, params_529);
  csinn_mul(output_526, output_529, output_530, params_530);
  csinn_matmul(output_530, data_b_533, output_533, params_533);
  csinn_add(output_533, rhs_535, output_535, params_535);
  csinn_add(output_519, output_535, output_537, params_537);
  csinn_layer_norm(output_537, output_539, gamma_539, beta_539, params_539);
  csinn_matmul(output_539, data_b_541, output_541, params_541);
  csinn_add(output_541, rhs_543, output_543, params_543);
  csinn_reshape(output_543, output_545, params_545);
  csinn_transpose(output_545, output_546, params_546);
  csinn_gather(output_546, indices_547, output_547, params_547);
  csinn_mul(output_547, rhs_549, output_549, params_549);
  csinn_gather(output_546, indices_552, output_552, params_552);
  csinn_transpose(output_552, output_553, params_553);
  csinn_matmul(output_549, output_553, output_554, params_554);
  csinn_softmax(output_554, output_555, params_555);
  csinn_gather(output_546, indices_557, output_557, params_557);
  csinn_matmul(output_555, output_557, output_558, params_558);
  csinn_transpose(output_558, output_559, params_559);
  csinn_reshape(output_559, output_560, params_560);
  csinn_matmul(output_560, data_b_562, output_562, params_562);
  csinn_add(output_562, rhs_564, output_564, params_564);
  csinn_add(output_564, output_537, output_567, params_567);
  csinn_layer_norm(output_567, output_570, gamma_570, beta_570, params_570);
  csinn_matmul(output_570, data_b_572, output_572, params_572);
  csinn_add(output_572, rhs_574, output_574, params_574);
  csinn_sigmoid(output_574, output_577, params_577);
  csinn_mul(output_574, output_577, output_578, params_578);
  csinn_matmul(output_578, data_b_581, output_581, params_581);
  csinn_add(output_581, rhs_583, output_583, params_583);
  csinn_add(output_567, output_583, output_585, params_585);
  csinn_layer_norm(output_585, output_587, gamma_587, beta_587, params_587);
  csinn_reshape(output_587, output_588, params_588);
  csinn_transpose(output_588, output_589, params_589);
  csinn_reshape(output_589, output_590, params_590);
  csinn_transpose(output_590, output_591, params_591);
  csinn_reshape(output_591, output_592, params_592);
  csinn_conv2d(output_592, output_593, kernel_593, bias_593, params_593);
  csinn_sigmoid(output_593, output_595, params_595);
  csinn_mul(output_593, output_595, output_596, params_596);
  input_598_concat[0] = output_431;
  input_598_concat[1] = output_596;
  csinn_concat(input_598_concat, output_598, params_598);
  csinn_conv2d(output_598, output_599, kernel_599, bias_599, params_599);
  csinn_sigmoid(output_599, output_601, params_601);
  csinn_mul(output_599, output_601, output_602, params_602);
  csinn_conv2d(output_602, output_604, kernel_604, bias_604, params_604);
  csinn_sigmoid(output_604, output_606, params_606);
  csinn_mul(output_604, output_606, output_607, params_607);
  csinn_mean(output_607, output_609, params_609);
  csinn_fullyconnected(output_609, output_610, kernel_610, bias_610, params_610);
  csinn_set_output(0, output_610, sess);

  csinn_session_setup(sess);
  return sess;
}
void csinn_update_input_and_run(struct csinn_tensor **input_tensors , void *sess) {
  csinn_update_input(0, input_tensors[0], sess);
  csinn_session_run(sess);
}
