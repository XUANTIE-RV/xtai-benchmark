/* auto generate by HHB_VERSION 3.0.26-beta */

#include <csi_nn.h>

void *csinn_(char *params_base) {
  struct csinn_session *sess = csinn_alloc_session();
  sess->base_run_mode = CSINN_RM_CPU_GRAPH;
  sess->base_quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  sess->model.save_mode = CSINN_RUN_ONLY;
  sess->base_api = CSINN_C908;
  sess->base_dtype = CSINN_DTYPE_FLOAT16;
  sess->dynamic_shape = CSINN_FALSE;
  csinn_session_init(sess);
  csinn_set_input_number(1, sess);
  csinn_set_output_number(1, sess);

  struct csinn_tensor *data = csinn_alloc_tensor(sess);
  data->name = "data@@conv2d_resnetv17_conv0_fwd_1_fuse_multiply_2_fuse_add_resnetv17_batchnorm0_fwd_3_0";
  data->dtype = CSINN_DTYPE_FLOAT16;
  data->layout = CSINN_LAYOUT_NCHW;
  data->dim[0] = 1;
  data->dim[1] = 3;
  data->dim[2] = 224;
  data->dim[3] = 224;
  data->dim_count = 4;
  memcpy(data->qinfo, params_base + 0, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *output_0 = csinn_alloc_tensor(sess);
  output_0->name = "output_0";
  output_0->dtype = CSINN_DTYPE_FLOAT16;
  output_0->layout = CSINN_LAYOUT_NCHW;
  output_0->dim[0] = 1;
  output_0->dim[1] = 64;
  output_0->dim[2] = 112;
  output_0->dim[3] = 112;
  output_0->dim_count = 4;
  memcpy(output_0->qinfo, params_base + 24, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_0 = csinn_alloc_tensor(sess);
  kernel_0->name = "kernel_0";
  kernel_0->data = params_base + 1584;
  kernel_0->is_const = 1;
  kernel_0->dtype = CSINN_DTYPE_INT8;
  kernel_0->layout = CSINN_LAYOUT_OIHW;
  kernel_0->dim[0] = 64;
  kernel_0->dim[1] = 3;
  kernel_0->dim[2] = 7;
  kernel_0->dim[3] = 7;
  kernel_0->dim_count = 4;
  csinn_realloc_quant_info(kernel_0, 64);
  memcpy(kernel_0->qinfo, params_base + 48, sizeof(struct csinn_quant_info) * 64);
  struct csinn_tensor *bias_0 = csinn_alloc_tensor(sess);
  bias_0->name = "bias_0";
  bias_0->data = params_base + 12528;
  bias_0->is_const = 1;
  bias_0->dtype = CSINN_DTYPE_FLOAT16;
  bias_0->layout = CSINN_LAYOUT_O;
  bias_0->dim[0] = 64;
  bias_0->dim_count = 1;
  csinn_realloc_quant_info(bias_0, 64);
  memcpy(bias_0->qinfo, params_base + 10992, sizeof(struct csinn_quant_info) * 64);
  struct csinn_conv2d_params *params_0 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_0->group = 1;
  params_0->stride_height = 2;
  params_0->stride_width = 2;
  params_0->dilation_height = 1;
  params_0->dilation_width = 1;
  params_0->conv_extra.kernel_tm = NULL;
  params_0->conv_extra.conv_mode = CSINN_DIRECT;
  params_0->pad_top = 3;
  params_0->pad_left = 3;
  params_0->pad_down = 3;
  params_0->pad_right = 3;
  params_0->base.name = "conv2d_resnetv17_conv0_fwd_1_fuse_multiply_2_fuse_add_resnetv17_batchnorm0_fwd_3";
  params_0->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(data, output_0, kernel_0, bias_0, params_0);
  struct csinn_tensor *output_1 = csinn_alloc_tensor(sess);
  output_1->name = "output_1";
  output_1->dtype = CSINN_DTYPE_FLOAT16;
  output_1->layout = CSINN_LAYOUT_NCHW;
  output_1->dim[0] = 1;
  output_1->dim[1] = 64;
  output_1->dim[2] = 112;
  output_1->dim[3] = 112;
  output_1->dim_count = 4;
  memcpy(output_1->qinfo, params_base + 12656, sizeof(struct csinn_quant_info) * 1);
  struct csinn_relu_params *params_1 = csinn_alloc_params(sizeof(struct csinn_relu_params), sess);
  params_1->base.name = "relu_resnetv17_relu0_fwd_4";
  params_1->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_relu_init(output_0, output_1, params_1);
  struct csinn_tensor *output_2 = csinn_alloc_tensor(sess);
  output_2->name = "output_2";
  output_2->dtype = CSINN_DTYPE_FLOAT16;
  output_2->layout = CSINN_LAYOUT_NCHW;
  output_2->dim[0] = 1;
  output_2->dim[1] = 64;
  output_2->dim[2] = 56;
  output_2->dim[3] = 56;
  output_2->dim_count = 4;
  memcpy(output_2->qinfo, params_base + 12680, sizeof(struct csinn_quant_info) * 1);
  struct csinn_pool_params *params_2 = csinn_alloc_params(sizeof(struct csinn_pool_params), sess);
  params_2->stride_height = 2;
  params_2->stride_width = 2;
  params_2->filter_height = 3;
  params_2->filter_width = 3;
  params_2->ceil_mode = 0;
  params_2->pad_top = 1;
  params_2->pad_left = 1;
  params_2->pad_down = 1;
  params_2->pad_right = 1;
  params_2->base.name = "max_pool2d_resnetv17_pool0_fwd_5";
  params_2->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_maxpool2d_init(output_1, output_2, params_2);
  struct csinn_tensor *output_3 = csinn_alloc_tensor(sess);
  output_3->name = "output_3";
  output_3->dtype = CSINN_DTYPE_FLOAT16;
  output_3->layout = CSINN_LAYOUT_NCHW;
  output_3->dim[0] = 1;
  output_3->dim[1] = 64;
  output_3->dim[2] = 56;
  output_3->dim[3] = 56;
  output_3->dim_count = 4;
  memcpy(output_3->qinfo, params_base + 12704, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_3 = csinn_alloc_tensor(sess);
  kernel_3->name = "kernel_3";
  kernel_3->data = params_base + 14264;
  kernel_3->is_const = 1;
  kernel_3->dtype = CSINN_DTYPE_INT8;
  kernel_3->layout = CSINN_LAYOUT_OIHW;
  kernel_3->dim[0] = 64;
  kernel_3->dim[1] = 64;
  kernel_3->dim[2] = 1;
  kernel_3->dim[3] = 1;
  kernel_3->dim_count = 4;
  csinn_realloc_quant_info(kernel_3, 64);
  memcpy(kernel_3->qinfo, params_base + 12728, sizeof(struct csinn_quant_info) * 64);
  struct csinn_tensor *bias_3 = csinn_alloc_tensor(sess);
  bias_3->name = "bias_3";
  bias_3->data = params_base + 19896;
  bias_3->is_const = 1;
  bias_3->dtype = CSINN_DTYPE_FLOAT16;
  bias_3->layout = CSINN_LAYOUT_O;
  bias_3->dim[0] = 64;
  bias_3->dim_count = 1;
  csinn_realloc_quant_info(bias_3, 64);
  memcpy(bias_3->qinfo, params_base + 18360, sizeof(struct csinn_quant_info) * 64);
  struct csinn_conv2d_params *params_3 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_3->group = 1;
  params_3->stride_height = 1;
  params_3->stride_width = 1;
  params_3->dilation_height = 1;
  params_3->dilation_width = 1;
  params_3->conv_extra.kernel_tm = NULL;
  params_3->conv_extra.conv_mode = CSINN_DIRECT;
  params_3->pad_top = 0;
  params_3->pad_left = 0;
  params_3->pad_down = 0;
  params_3->pad_right = 0;
  params_3->base.name = "conv2d_resnetv17_stage1_conv0_fwd_6_fuse_bias_add_resnetv17_stage1_conv0_fwd_7_fuse_multiply_8_fuse_add_resnetv17_stage1_batchnorm0_fwd_9";
  params_3->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_2, output_3, kernel_3, bias_3, params_3);
  struct csinn_tensor *output_4 = csinn_alloc_tensor(sess);
  output_4->name = "output_4";
  output_4->dtype = CSINN_DTYPE_FLOAT16;
  output_4->layout = CSINN_LAYOUT_NCHW;
  output_4->dim[0] = 1;
  output_4->dim[1] = 64;
  output_4->dim[2] = 56;
  output_4->dim[3] = 56;
  output_4->dim_count = 4;
  memcpy(output_4->qinfo, params_base + 20024, sizeof(struct csinn_quant_info) * 1);
  struct csinn_relu_params *params_4 = csinn_alloc_params(sizeof(struct csinn_relu_params), sess);
  params_4->base.name = "relu_resnetv17_stage1_relu0_fwd_10";
  params_4->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_relu_init(output_3, output_4, params_4);
  struct csinn_tensor *output_5 = csinn_alloc_tensor(sess);
  output_5->name = "output_5";
  output_5->dtype = CSINN_DTYPE_FLOAT16;
  output_5->layout = CSINN_LAYOUT_NCHW;
  output_5->dim[0] = 1;
  output_5->dim[1] = 64;
  output_5->dim[2] = 56;
  output_5->dim[3] = 56;
  output_5->dim_count = 4;
  memcpy(output_5->qinfo, params_base + 20048, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_5 = csinn_alloc_tensor(sess);
  kernel_5->name = "kernel_5";
  kernel_5->data = params_base + 21608;
  kernel_5->is_const = 1;
  kernel_5->dtype = CSINN_DTYPE_INT8;
  kernel_5->layout = CSINN_LAYOUT_OIHW;
  kernel_5->dim[0] = 64;
  kernel_5->dim[1] = 64;
  kernel_5->dim[2] = 3;
  kernel_5->dim[3] = 3;
  kernel_5->dim_count = 4;
  csinn_realloc_quant_info(kernel_5, 64);
  memcpy(kernel_5->qinfo, params_base + 20072, sizeof(struct csinn_quant_info) * 64);
  struct csinn_tensor *bias_5 = csinn_alloc_tensor(sess);
  bias_5->name = "bias_5";
  bias_5->data = params_base + 60008;
  bias_5->is_const = 1;
  bias_5->dtype = CSINN_DTYPE_FLOAT16;
  bias_5->layout = CSINN_LAYOUT_O;
  bias_5->dim[0] = 64;
  bias_5->dim_count = 1;
  csinn_realloc_quant_info(bias_5, 64);
  memcpy(bias_5->qinfo, params_base + 58472, sizeof(struct csinn_quant_info) * 64);
  struct csinn_conv2d_params *params_5 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_5->group = 1;
  params_5->stride_height = 1;
  params_5->stride_width = 1;
  params_5->dilation_height = 1;
  params_5->dilation_width = 1;
  params_5->conv_extra.kernel_tm = NULL;
  params_5->conv_extra.conv_mode = CSINN_DIRECT;
  params_5->pad_top = 1;
  params_5->pad_left = 1;
  params_5->pad_down = 1;
  params_5->pad_right = 1;
  params_5->base.name = "conv2d_resnetv17_stage1_conv1_fwd_11_fuse_multiply_12_fuse_add_resnetv17_stage1_batchnorm1_fwd_13";
  params_5->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_4, output_5, kernel_5, bias_5, params_5);
  struct csinn_tensor *output_6 = csinn_alloc_tensor(sess);
  output_6->name = "output_6";
  output_6->dtype = CSINN_DTYPE_FLOAT16;
  output_6->layout = CSINN_LAYOUT_NCHW;
  output_6->dim[0] = 1;
  output_6->dim[1] = 64;
  output_6->dim[2] = 56;
  output_6->dim[3] = 56;
  output_6->dim_count = 4;
  memcpy(output_6->qinfo, params_base + 60136, sizeof(struct csinn_quant_info) * 1);
  struct csinn_relu_params *params_6 = csinn_alloc_params(sizeof(struct csinn_relu_params), sess);
  params_6->base.name = "relu_resnetv17_stage1_relu1_fwd_14";
  params_6->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_relu_init(output_5, output_6, params_6);
  struct csinn_tensor *output_7 = csinn_alloc_tensor(sess);
  output_7->name = "output_7";
  output_7->dtype = CSINN_DTYPE_FLOAT16;
  output_7->layout = CSINN_LAYOUT_NCHW;
  output_7->dim[0] = 1;
  output_7->dim[1] = 256;
  output_7->dim[2] = 56;
  output_7->dim[3] = 56;
  output_7->dim_count = 4;
  memcpy(output_7->qinfo, params_base + 60160, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_7 = csinn_alloc_tensor(sess);
  kernel_7->name = "kernel_7";
  kernel_7->data = params_base + 66328;
  kernel_7->is_const = 1;
  kernel_7->dtype = CSINN_DTYPE_INT8;
  kernel_7->layout = CSINN_LAYOUT_OIHW;
  kernel_7->dim[0] = 256;
  kernel_7->dim[1] = 64;
  kernel_7->dim[2] = 1;
  kernel_7->dim[3] = 1;
  kernel_7->dim_count = 4;
  csinn_realloc_quant_info(kernel_7, 256);
  memcpy(kernel_7->qinfo, params_base + 60184, sizeof(struct csinn_quant_info) * 256);
  struct csinn_tensor *bias_7 = csinn_alloc_tensor(sess);
  bias_7->name = "bias_7";
  bias_7->data = params_base + 88856;
  bias_7->is_const = 1;
  bias_7->dtype = CSINN_DTYPE_FLOAT16;
  bias_7->layout = CSINN_LAYOUT_O;
  bias_7->dim[0] = 256;
  bias_7->dim_count = 1;
  csinn_realloc_quant_info(bias_7, 256);
  memcpy(bias_7->qinfo, params_base + 82712, sizeof(struct csinn_quant_info) * 256);
  struct csinn_conv2d_params *params_7 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_7->group = 1;
  params_7->stride_height = 1;
  params_7->stride_width = 1;
  params_7->dilation_height = 1;
  params_7->dilation_width = 1;
  params_7->conv_extra.kernel_tm = NULL;
  params_7->conv_extra.conv_mode = CSINN_DIRECT;
  params_7->pad_top = 0;
  params_7->pad_left = 0;
  params_7->pad_down = 0;
  params_7->pad_right = 0;
  params_7->base.name = "conv2d_resnetv17_stage1_conv2_fwd_15_fuse_bias_add_resnetv17_stage1_conv2_fwd_16_fuse_multiply_17_fuse_add_resnetv17_stage1_batchnorm2_fwd_18";
  params_7->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_6, output_7, kernel_7, bias_7, params_7);
  struct csinn_tensor *output_9 = csinn_alloc_tensor(sess);
  output_9->name = "output_9";
  output_9->dtype = CSINN_DTYPE_FLOAT16;
  output_9->layout = CSINN_LAYOUT_NCHW;
  output_9->dim[0] = 1;
  output_9->dim[1] = 256;
  output_9->dim[2] = 56;
  output_9->dim[3] = 56;
  output_9->dim_count = 4;
  memcpy(output_9->qinfo, params_base + 89368, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_9 = csinn_alloc_tensor(sess);
  kernel_9->name = "kernel_9";
  kernel_9->data = params_base + 95536;
  kernel_9->is_const = 1;
  kernel_9->dtype = CSINN_DTYPE_INT8;
  kernel_9->layout = CSINN_LAYOUT_OIHW;
  kernel_9->dim[0] = 256;
  kernel_9->dim[1] = 64;
  kernel_9->dim[2] = 1;
  kernel_9->dim[3] = 1;
  kernel_9->dim_count = 4;
  csinn_realloc_quant_info(kernel_9, 256);
  memcpy(kernel_9->qinfo, params_base + 89392, sizeof(struct csinn_quant_info) * 256);
  struct csinn_tensor *bias_9 = csinn_alloc_tensor(sess);
  bias_9->name = "bias_9";
  bias_9->data = params_base + 118064;
  bias_9->is_const = 1;
  bias_9->dtype = CSINN_DTYPE_FLOAT16;
  bias_9->layout = CSINN_LAYOUT_O;
  bias_9->dim[0] = 256;
  bias_9->dim_count = 1;
  csinn_realloc_quant_info(bias_9, 256);
  memcpy(bias_9->qinfo, params_base + 111920, sizeof(struct csinn_quant_info) * 256);
  struct csinn_conv2d_params *params_9 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_9->group = 1;
  params_9->stride_height = 1;
  params_9->stride_width = 1;
  params_9->dilation_height = 1;
  params_9->dilation_width = 1;
  params_9->conv_extra.kernel_tm = NULL;
  params_9->conv_extra.conv_mode = CSINN_DIRECT;
  params_9->pad_top = 0;
  params_9->pad_left = 0;
  params_9->pad_down = 0;
  params_9->pad_right = 0;
  params_9->base.name = "conv2d_resnetv17_stage1_conv3_fwd_19_fuse_multiply_20_fuse_add_resnetv17_stage1_batchnorm3_fwd_21";
  params_9->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_2, output_9, kernel_9, bias_9, params_9);
  struct csinn_tensor *output_10 = csinn_alloc_tensor(sess);
  output_10->name = "output_10";
  output_10->dtype = CSINN_DTYPE_FLOAT16;
  output_10->layout = CSINN_LAYOUT_NCHW;
  output_10->dim[0] = 1;
  output_10->dim[1] = 256;
  output_10->dim[2] = 56;
  output_10->dim[3] = 56;
  output_10->dim_count = 4;
  memcpy(output_10->qinfo, params_base + 118576, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_10 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_10->base.name = "add_resnetv17_stage1__plus0_22";
  params_10->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_7, output_9, output_10, params_10);
  struct csinn_tensor *output_12 = csinn_alloc_tensor(sess);
  output_12->name = "output_12";
  output_12->dtype = CSINN_DTYPE_FLOAT16;
  output_12->layout = CSINN_LAYOUT_NCHW;
  output_12->dim[0] = 1;
  output_12->dim[1] = 256;
  output_12->dim[2] = 56;
  output_12->dim[3] = 56;
  output_12->dim_count = 4;
  memcpy(output_12->qinfo, params_base + 118600, sizeof(struct csinn_quant_info) * 1);
  struct csinn_relu_params *params_12 = csinn_alloc_params(sizeof(struct csinn_relu_params), sess);
  params_12->base.name = "relu_resnetv17_stage1_activation0_23";
  params_12->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_relu_init(output_10, output_12, params_12);
  struct csinn_tensor *output_13 = csinn_alloc_tensor(sess);
  output_13->name = "output_13";
  output_13->dtype = CSINN_DTYPE_FLOAT16;
  output_13->layout = CSINN_LAYOUT_NCHW;
  output_13->dim[0] = 1;
  output_13->dim[1] = 64;
  output_13->dim[2] = 56;
  output_13->dim[3] = 56;
  output_13->dim_count = 4;
  memcpy(output_13->qinfo, params_base + 118624, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_13 = csinn_alloc_tensor(sess);
  kernel_13->name = "kernel_13";
  kernel_13->data = params_base + 120184;
  kernel_13->is_const = 1;
  kernel_13->dtype = CSINN_DTYPE_INT8;
  kernel_13->layout = CSINN_LAYOUT_OIHW;
  kernel_13->dim[0] = 64;
  kernel_13->dim[1] = 256;
  kernel_13->dim[2] = 1;
  kernel_13->dim[3] = 1;
  kernel_13->dim_count = 4;
  csinn_realloc_quant_info(kernel_13, 64);
  memcpy(kernel_13->qinfo, params_base + 118648, sizeof(struct csinn_quant_info) * 64);
  struct csinn_tensor *bias_13 = csinn_alloc_tensor(sess);
  bias_13->name = "bias_13";
  bias_13->data = params_base + 138104;
  bias_13->is_const = 1;
  bias_13->dtype = CSINN_DTYPE_FLOAT16;
  bias_13->layout = CSINN_LAYOUT_O;
  bias_13->dim[0] = 64;
  bias_13->dim_count = 1;
  csinn_realloc_quant_info(bias_13, 64);
  memcpy(bias_13->qinfo, params_base + 136568, sizeof(struct csinn_quant_info) * 64);
  struct csinn_conv2d_params *params_13 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_13->group = 1;
  params_13->stride_height = 1;
  params_13->stride_width = 1;
  params_13->dilation_height = 1;
  params_13->dilation_width = 1;
  params_13->conv_extra.kernel_tm = NULL;
  params_13->conv_extra.conv_mode = CSINN_DIRECT;
  params_13->pad_top = 0;
  params_13->pad_left = 0;
  params_13->pad_down = 0;
  params_13->pad_right = 0;
  params_13->base.name = "conv2d_resnetv17_stage1_conv4_fwd_24_fuse_bias_add_resnetv17_stage1_conv4_fwd_25_fuse_multiply_26_fuse_add_resnetv17_stage1_batchnorm4_fwd_27";
  params_13->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_12, output_13, kernel_13, bias_13, params_13);
  struct csinn_tensor *output_14 = csinn_alloc_tensor(sess);
  output_14->name = "output_14";
  output_14->dtype = CSINN_DTYPE_FLOAT16;
  output_14->layout = CSINN_LAYOUT_NCHW;
  output_14->dim[0] = 1;
  output_14->dim[1] = 64;
  output_14->dim[2] = 56;
  output_14->dim[3] = 56;
  output_14->dim_count = 4;
  memcpy(output_14->qinfo, params_base + 138232, sizeof(struct csinn_quant_info) * 1);
  struct csinn_relu_params *params_14 = csinn_alloc_params(sizeof(struct csinn_relu_params), sess);
  params_14->base.name = "relu_resnetv17_stage1_relu2_fwd_28";
  params_14->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_relu_init(output_13, output_14, params_14);
  struct csinn_tensor *output_15 = csinn_alloc_tensor(sess);
  output_15->name = "output_15";
  output_15->dtype = CSINN_DTYPE_FLOAT16;
  output_15->layout = CSINN_LAYOUT_NCHW;
  output_15->dim[0] = 1;
  output_15->dim[1] = 64;
  output_15->dim[2] = 56;
  output_15->dim[3] = 56;
  output_15->dim_count = 4;
  memcpy(output_15->qinfo, params_base + 138256, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_15 = csinn_alloc_tensor(sess);
  kernel_15->name = "kernel_15";
  kernel_15->data = params_base + 139816;
  kernel_15->is_const = 1;
  kernel_15->dtype = CSINN_DTYPE_INT8;
  kernel_15->layout = CSINN_LAYOUT_OIHW;
  kernel_15->dim[0] = 64;
  kernel_15->dim[1] = 64;
  kernel_15->dim[2] = 3;
  kernel_15->dim[3] = 3;
  kernel_15->dim_count = 4;
  csinn_realloc_quant_info(kernel_15, 64);
  memcpy(kernel_15->qinfo, params_base + 138280, sizeof(struct csinn_quant_info) * 64);
  struct csinn_tensor *bias_15 = csinn_alloc_tensor(sess);
  bias_15->name = "bias_15";
  bias_15->data = params_base + 178216;
  bias_15->is_const = 1;
  bias_15->dtype = CSINN_DTYPE_FLOAT16;
  bias_15->layout = CSINN_LAYOUT_O;
  bias_15->dim[0] = 64;
  bias_15->dim_count = 1;
  csinn_realloc_quant_info(bias_15, 64);
  memcpy(bias_15->qinfo, params_base + 176680, sizeof(struct csinn_quant_info) * 64);
  struct csinn_conv2d_params *params_15 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_15->group = 1;
  params_15->stride_height = 1;
  params_15->stride_width = 1;
  params_15->dilation_height = 1;
  params_15->dilation_width = 1;
  params_15->conv_extra.kernel_tm = NULL;
  params_15->conv_extra.conv_mode = CSINN_DIRECT;
  params_15->pad_top = 1;
  params_15->pad_left = 1;
  params_15->pad_down = 1;
  params_15->pad_right = 1;
  params_15->base.name = "conv2d_resnetv17_stage1_conv5_fwd_29_fuse_multiply_30_fuse_add_resnetv17_stage1_batchnorm5_fwd_31";
  params_15->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_14, output_15, kernel_15, bias_15, params_15);
  struct csinn_tensor *output_16 = csinn_alloc_tensor(sess);
  output_16->name = "output_16";
  output_16->dtype = CSINN_DTYPE_FLOAT16;
  output_16->layout = CSINN_LAYOUT_NCHW;
  output_16->dim[0] = 1;
  output_16->dim[1] = 64;
  output_16->dim[2] = 56;
  output_16->dim[3] = 56;
  output_16->dim_count = 4;
  memcpy(output_16->qinfo, params_base + 178344, sizeof(struct csinn_quant_info) * 1);
  struct csinn_relu_params *params_16 = csinn_alloc_params(sizeof(struct csinn_relu_params), sess);
  params_16->base.name = "relu_resnetv17_stage1_relu3_fwd_32";
  params_16->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_relu_init(output_15, output_16, params_16);
  struct csinn_tensor *output_17 = csinn_alloc_tensor(sess);
  output_17->name = "output_17";
  output_17->dtype = CSINN_DTYPE_FLOAT16;
  output_17->layout = CSINN_LAYOUT_NCHW;
  output_17->dim[0] = 1;
  output_17->dim[1] = 256;
  output_17->dim[2] = 56;
  output_17->dim[3] = 56;
  output_17->dim_count = 4;
  memcpy(output_17->qinfo, params_base + 178368, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_17 = csinn_alloc_tensor(sess);
  kernel_17->name = "kernel_17";
  kernel_17->data = params_base + 184536;
  kernel_17->is_const = 1;
  kernel_17->dtype = CSINN_DTYPE_INT8;
  kernel_17->layout = CSINN_LAYOUT_OIHW;
  kernel_17->dim[0] = 256;
  kernel_17->dim[1] = 64;
  kernel_17->dim[2] = 1;
  kernel_17->dim[3] = 1;
  kernel_17->dim_count = 4;
  csinn_realloc_quant_info(kernel_17, 256);
  memcpy(kernel_17->qinfo, params_base + 178392, sizeof(struct csinn_quant_info) * 256);
  struct csinn_tensor *bias_17 = csinn_alloc_tensor(sess);
  bias_17->name = "bias_17";
  bias_17->data = params_base + 207064;
  bias_17->is_const = 1;
  bias_17->dtype = CSINN_DTYPE_FLOAT16;
  bias_17->layout = CSINN_LAYOUT_O;
  bias_17->dim[0] = 256;
  bias_17->dim_count = 1;
  csinn_realloc_quant_info(bias_17, 256);
  memcpy(bias_17->qinfo, params_base + 200920, sizeof(struct csinn_quant_info) * 256);
  struct csinn_conv2d_params *params_17 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_17->group = 1;
  params_17->stride_height = 1;
  params_17->stride_width = 1;
  params_17->dilation_height = 1;
  params_17->dilation_width = 1;
  params_17->conv_extra.kernel_tm = NULL;
  params_17->conv_extra.conv_mode = CSINN_DIRECT;
  params_17->pad_top = 0;
  params_17->pad_left = 0;
  params_17->pad_down = 0;
  params_17->pad_right = 0;
  params_17->base.name = "conv2d_resnetv17_stage1_conv6_fwd_33_fuse_bias_add_resnetv17_stage1_conv6_fwd_34_fuse_multiply_35_fuse_add_resnetv17_stage1_batchnorm6_fwd_36";
  params_17->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_16, output_17, kernel_17, bias_17, params_17);
  struct csinn_tensor *output_19 = csinn_alloc_tensor(sess);
  output_19->name = "output_19";
  output_19->dtype = CSINN_DTYPE_FLOAT16;
  output_19->layout = CSINN_LAYOUT_NCHW;
  output_19->dim[0] = 1;
  output_19->dim[1] = 256;
  output_19->dim[2] = 56;
  output_19->dim[3] = 56;
  output_19->dim_count = 4;
  memcpy(output_19->qinfo, params_base + 207576, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_19 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_19->base.name = "add_resnetv17_stage1__plus1_37";
  params_19->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_17, output_12, output_19, params_19);
  struct csinn_tensor *output_21 = csinn_alloc_tensor(sess);
  output_21->name = "output_21";
  output_21->dtype = CSINN_DTYPE_FLOAT16;
  output_21->layout = CSINN_LAYOUT_NCHW;
  output_21->dim[0] = 1;
  output_21->dim[1] = 256;
  output_21->dim[2] = 56;
  output_21->dim[3] = 56;
  output_21->dim_count = 4;
  memcpy(output_21->qinfo, params_base + 207600, sizeof(struct csinn_quant_info) * 1);
  struct csinn_relu_params *params_21 = csinn_alloc_params(sizeof(struct csinn_relu_params), sess);
  params_21->base.name = "relu_resnetv17_stage1_activation1_38";
  params_21->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_relu_init(output_19, output_21, params_21);
  struct csinn_tensor *output_22 = csinn_alloc_tensor(sess);
  output_22->name = "output_22";
  output_22->dtype = CSINN_DTYPE_FLOAT16;
  output_22->layout = CSINN_LAYOUT_NCHW;
  output_22->dim[0] = 1;
  output_22->dim[1] = 64;
  output_22->dim[2] = 56;
  output_22->dim[3] = 56;
  output_22->dim_count = 4;
  memcpy(output_22->qinfo, params_base + 207624, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_22 = csinn_alloc_tensor(sess);
  kernel_22->name = "kernel_22";
  kernel_22->data = params_base + 209184;
  kernel_22->is_const = 1;
  kernel_22->dtype = CSINN_DTYPE_INT8;
  kernel_22->layout = CSINN_LAYOUT_OIHW;
  kernel_22->dim[0] = 64;
  kernel_22->dim[1] = 256;
  kernel_22->dim[2] = 1;
  kernel_22->dim[3] = 1;
  kernel_22->dim_count = 4;
  csinn_realloc_quant_info(kernel_22, 64);
  memcpy(kernel_22->qinfo, params_base + 207648, sizeof(struct csinn_quant_info) * 64);
  struct csinn_tensor *bias_22 = csinn_alloc_tensor(sess);
  bias_22->name = "bias_22";
  bias_22->data = params_base + 227104;
  bias_22->is_const = 1;
  bias_22->dtype = CSINN_DTYPE_FLOAT16;
  bias_22->layout = CSINN_LAYOUT_O;
  bias_22->dim[0] = 64;
  bias_22->dim_count = 1;
  csinn_realloc_quant_info(bias_22, 64);
  memcpy(bias_22->qinfo, params_base + 225568, sizeof(struct csinn_quant_info) * 64);
  struct csinn_conv2d_params *params_22 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_22->group = 1;
  params_22->stride_height = 1;
  params_22->stride_width = 1;
  params_22->dilation_height = 1;
  params_22->dilation_width = 1;
  params_22->conv_extra.kernel_tm = NULL;
  params_22->conv_extra.conv_mode = CSINN_DIRECT;
  params_22->pad_top = 0;
  params_22->pad_left = 0;
  params_22->pad_down = 0;
  params_22->pad_right = 0;
  params_22->base.name = "conv2d_resnetv17_stage1_conv7_fwd_39_fuse_bias_add_resnetv17_stage1_conv7_fwd_40_fuse_multiply_41_fuse_add_resnetv17_stage1_batchnorm7_fwd_42";
  params_22->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_21, output_22, kernel_22, bias_22, params_22);
  struct csinn_tensor *output_23 = csinn_alloc_tensor(sess);
  output_23->name = "output_23";
  output_23->dtype = CSINN_DTYPE_FLOAT16;
  output_23->layout = CSINN_LAYOUT_NCHW;
  output_23->dim[0] = 1;
  output_23->dim[1] = 64;
  output_23->dim[2] = 56;
  output_23->dim[3] = 56;
  output_23->dim_count = 4;
  memcpy(output_23->qinfo, params_base + 227232, sizeof(struct csinn_quant_info) * 1);
  struct csinn_relu_params *params_23 = csinn_alloc_params(sizeof(struct csinn_relu_params), sess);
  params_23->base.name = "relu_resnetv17_stage1_relu4_fwd_43";
  params_23->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_relu_init(output_22, output_23, params_23);
  struct csinn_tensor *output_24 = csinn_alloc_tensor(sess);
  output_24->name = "output_24";
  output_24->dtype = CSINN_DTYPE_FLOAT16;
  output_24->layout = CSINN_LAYOUT_NCHW;
  output_24->dim[0] = 1;
  output_24->dim[1] = 64;
  output_24->dim[2] = 56;
  output_24->dim[3] = 56;
  output_24->dim_count = 4;
  memcpy(output_24->qinfo, params_base + 227256, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_24 = csinn_alloc_tensor(sess);
  kernel_24->name = "kernel_24";
  kernel_24->data = params_base + 228816;
  kernel_24->is_const = 1;
  kernel_24->dtype = CSINN_DTYPE_INT8;
  kernel_24->layout = CSINN_LAYOUT_OIHW;
  kernel_24->dim[0] = 64;
  kernel_24->dim[1] = 64;
  kernel_24->dim[2] = 3;
  kernel_24->dim[3] = 3;
  kernel_24->dim_count = 4;
  csinn_realloc_quant_info(kernel_24, 64);
  memcpy(kernel_24->qinfo, params_base + 227280, sizeof(struct csinn_quant_info) * 64);
  struct csinn_tensor *bias_24 = csinn_alloc_tensor(sess);
  bias_24->name = "bias_24";
  bias_24->data = params_base + 267216;
  bias_24->is_const = 1;
  bias_24->dtype = CSINN_DTYPE_FLOAT16;
  bias_24->layout = CSINN_LAYOUT_O;
  bias_24->dim[0] = 64;
  bias_24->dim_count = 1;
  csinn_realloc_quant_info(bias_24, 64);
  memcpy(bias_24->qinfo, params_base + 265680, sizeof(struct csinn_quant_info) * 64);
  struct csinn_conv2d_params *params_24 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_24->group = 1;
  params_24->stride_height = 1;
  params_24->stride_width = 1;
  params_24->dilation_height = 1;
  params_24->dilation_width = 1;
  params_24->conv_extra.kernel_tm = NULL;
  params_24->conv_extra.conv_mode = CSINN_DIRECT;
  params_24->pad_top = 1;
  params_24->pad_left = 1;
  params_24->pad_down = 1;
  params_24->pad_right = 1;
  params_24->base.name = "conv2d_resnetv17_stage1_conv8_fwd_44_fuse_multiply_45_fuse_add_resnetv17_stage1_batchnorm8_fwd_46";
  params_24->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_23, output_24, kernel_24, bias_24, params_24);
  struct csinn_tensor *output_25 = csinn_alloc_tensor(sess);
  output_25->name = "output_25";
  output_25->dtype = CSINN_DTYPE_FLOAT16;
  output_25->layout = CSINN_LAYOUT_NCHW;
  output_25->dim[0] = 1;
  output_25->dim[1] = 64;
  output_25->dim[2] = 56;
  output_25->dim[3] = 56;
  output_25->dim_count = 4;
  memcpy(output_25->qinfo, params_base + 267344, sizeof(struct csinn_quant_info) * 1);
  struct csinn_relu_params *params_25 = csinn_alloc_params(sizeof(struct csinn_relu_params), sess);
  params_25->base.name = "relu_resnetv17_stage1_relu5_fwd_47";
  params_25->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_relu_init(output_24, output_25, params_25);
  struct csinn_tensor *output_26 = csinn_alloc_tensor(sess);
  output_26->name = "output_26";
  output_26->dtype = CSINN_DTYPE_FLOAT16;
  output_26->layout = CSINN_LAYOUT_NCHW;
  output_26->dim[0] = 1;
  output_26->dim[1] = 256;
  output_26->dim[2] = 56;
  output_26->dim[3] = 56;
  output_26->dim_count = 4;
  memcpy(output_26->qinfo, params_base + 267368, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_26 = csinn_alloc_tensor(sess);
  kernel_26->name = "kernel_26";
  kernel_26->data = params_base + 273536;
  kernel_26->is_const = 1;
  kernel_26->dtype = CSINN_DTYPE_INT8;
  kernel_26->layout = CSINN_LAYOUT_OIHW;
  kernel_26->dim[0] = 256;
  kernel_26->dim[1] = 64;
  kernel_26->dim[2] = 1;
  kernel_26->dim[3] = 1;
  kernel_26->dim_count = 4;
  csinn_realloc_quant_info(kernel_26, 256);
  memcpy(kernel_26->qinfo, params_base + 267392, sizeof(struct csinn_quant_info) * 256);
  struct csinn_tensor *bias_26 = csinn_alloc_tensor(sess);
  bias_26->name = "bias_26";
  bias_26->data = params_base + 296064;
  bias_26->is_const = 1;
  bias_26->dtype = CSINN_DTYPE_FLOAT16;
  bias_26->layout = CSINN_LAYOUT_O;
  bias_26->dim[0] = 256;
  bias_26->dim_count = 1;
  csinn_realloc_quant_info(bias_26, 256);
  memcpy(bias_26->qinfo, params_base + 289920, sizeof(struct csinn_quant_info) * 256);
  struct csinn_conv2d_params *params_26 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_26->group = 1;
  params_26->stride_height = 1;
  params_26->stride_width = 1;
  params_26->dilation_height = 1;
  params_26->dilation_width = 1;
  params_26->conv_extra.kernel_tm = NULL;
  params_26->conv_extra.conv_mode = CSINN_DIRECT;
  params_26->pad_top = 0;
  params_26->pad_left = 0;
  params_26->pad_down = 0;
  params_26->pad_right = 0;
  params_26->base.name = "conv2d_resnetv17_stage1_conv9_fwd_48_fuse_bias_add_resnetv17_stage1_conv9_fwd_49_fuse_multiply_50_fuse_add_resnetv17_stage1_batchnorm9_fwd_51";
  params_26->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_25, output_26, kernel_26, bias_26, params_26);
  struct csinn_tensor *output_28 = csinn_alloc_tensor(sess);
  output_28->name = "output_28";
  output_28->dtype = CSINN_DTYPE_FLOAT16;
  output_28->layout = CSINN_LAYOUT_NCHW;
  output_28->dim[0] = 1;
  output_28->dim[1] = 256;
  output_28->dim[2] = 56;
  output_28->dim[3] = 56;
  output_28->dim_count = 4;
  memcpy(output_28->qinfo, params_base + 296576, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_28 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_28->base.name = "add_resnetv17_stage1__plus2_52";
  params_28->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_26, output_21, output_28, params_28);
  struct csinn_tensor *output_30 = csinn_alloc_tensor(sess);
  output_30->name = "output_30";
  output_30->dtype = CSINN_DTYPE_FLOAT16;
  output_30->layout = CSINN_LAYOUT_NCHW;
  output_30->dim[0] = 1;
  output_30->dim[1] = 256;
  output_30->dim[2] = 56;
  output_30->dim[3] = 56;
  output_30->dim_count = 4;
  memcpy(output_30->qinfo, params_base + 296600, sizeof(struct csinn_quant_info) * 1);
  struct csinn_relu_params *params_30 = csinn_alloc_params(sizeof(struct csinn_relu_params), sess);
  params_30->base.name = "relu_resnetv17_stage1_activation2_53";
  params_30->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_relu_init(output_28, output_30, params_30);
  struct csinn_tensor *output_31 = csinn_alloc_tensor(sess);
  output_31->name = "output_31";
  output_31->dtype = CSINN_DTYPE_FLOAT16;
  output_31->layout = CSINN_LAYOUT_NCHW;
  output_31->dim[0] = 1;
  output_31->dim[1] = 128;
  output_31->dim[2] = 28;
  output_31->dim[3] = 28;
  output_31->dim_count = 4;
  memcpy(output_31->qinfo, params_base + 296624, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_31 = csinn_alloc_tensor(sess);
  kernel_31->name = "kernel_31";
  kernel_31->data = params_base + 299720;
  kernel_31->is_const = 1;
  kernel_31->dtype = CSINN_DTYPE_INT8;
  kernel_31->layout = CSINN_LAYOUT_OIHW;
  kernel_31->dim[0] = 128;
  kernel_31->dim[1] = 256;
  kernel_31->dim[2] = 1;
  kernel_31->dim[3] = 1;
  kernel_31->dim_count = 4;
  csinn_realloc_quant_info(kernel_31, 128);
  memcpy(kernel_31->qinfo, params_base + 296648, sizeof(struct csinn_quant_info) * 128);
  struct csinn_tensor *bias_31 = csinn_alloc_tensor(sess);
  bias_31->name = "bias_31";
  bias_31->data = params_base + 335560;
  bias_31->is_const = 1;
  bias_31->dtype = CSINN_DTYPE_FLOAT16;
  bias_31->layout = CSINN_LAYOUT_O;
  bias_31->dim[0] = 128;
  bias_31->dim_count = 1;
  csinn_realloc_quant_info(bias_31, 128);
  memcpy(bias_31->qinfo, params_base + 332488, sizeof(struct csinn_quant_info) * 128);
  struct csinn_conv2d_params *params_31 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_31->group = 1;
  params_31->stride_height = 2;
  params_31->stride_width = 2;
  params_31->dilation_height = 1;
  params_31->dilation_width = 1;
  params_31->conv_extra.kernel_tm = NULL;
  params_31->conv_extra.conv_mode = CSINN_DIRECT;
  params_31->pad_top = 0;
  params_31->pad_left = 0;
  params_31->pad_down = 0;
  params_31->pad_right = 0;
  params_31->base.name = "conv2d_resnetv17_stage2_conv0_fwd_54_fuse_bias_add_resnetv17_stage2_conv0_fwd_55_fuse_multiply_56_fuse_add_resnetv17_stage2_batchnorm0_fwd_57";
  params_31->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_30, output_31, kernel_31, bias_31, params_31);
  struct csinn_tensor *output_32 = csinn_alloc_tensor(sess);
  output_32->name = "output_32";
  output_32->dtype = CSINN_DTYPE_FLOAT16;
  output_32->layout = CSINN_LAYOUT_NCHW;
  output_32->dim[0] = 1;
  output_32->dim[1] = 128;
  output_32->dim[2] = 28;
  output_32->dim[3] = 28;
  output_32->dim_count = 4;
  memcpy(output_32->qinfo, params_base + 335816, sizeof(struct csinn_quant_info) * 1);
  struct csinn_relu_params *params_32 = csinn_alloc_params(sizeof(struct csinn_relu_params), sess);
  params_32->base.name = "relu_resnetv17_stage2_relu0_fwd_58";
  params_32->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_relu_init(output_31, output_32, params_32);
  struct csinn_tensor *output_33 = csinn_alloc_tensor(sess);
  output_33->name = "output_33";
  output_33->dtype = CSINN_DTYPE_FLOAT16;
  output_33->layout = CSINN_LAYOUT_NCHW;
  output_33->dim[0] = 1;
  output_33->dim[1] = 128;
  output_33->dim[2] = 28;
  output_33->dim[3] = 28;
  output_33->dim_count = 4;
  memcpy(output_33->qinfo, params_base + 335840, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_33 = csinn_alloc_tensor(sess);
  kernel_33->name = "kernel_33";
  kernel_33->data = params_base + 338936;
  kernel_33->is_const = 1;
  kernel_33->dtype = CSINN_DTYPE_INT8;
  kernel_33->layout = CSINN_LAYOUT_OIHW;
  kernel_33->dim[0] = 128;
  kernel_33->dim[1] = 128;
  kernel_33->dim[2] = 3;
  kernel_33->dim[3] = 3;
  kernel_33->dim_count = 4;
  csinn_realloc_quant_info(kernel_33, 128);
  memcpy(kernel_33->qinfo, params_base + 335864, sizeof(struct csinn_quant_info) * 128);
  struct csinn_tensor *bias_33 = csinn_alloc_tensor(sess);
  bias_33->name = "bias_33";
  bias_33->data = params_base + 489464;
  bias_33->is_const = 1;
  bias_33->dtype = CSINN_DTYPE_FLOAT16;
  bias_33->layout = CSINN_LAYOUT_O;
  bias_33->dim[0] = 128;
  bias_33->dim_count = 1;
  csinn_realloc_quant_info(bias_33, 128);
  memcpy(bias_33->qinfo, params_base + 486392, sizeof(struct csinn_quant_info) * 128);
  struct csinn_conv2d_params *params_33 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_33->group = 1;
  params_33->stride_height = 1;
  params_33->stride_width = 1;
  params_33->dilation_height = 1;
  params_33->dilation_width = 1;
  params_33->conv_extra.kernel_tm = NULL;
  params_33->conv_extra.conv_mode = CSINN_DIRECT;
  params_33->pad_top = 1;
  params_33->pad_left = 1;
  params_33->pad_down = 1;
  params_33->pad_right = 1;
  params_33->base.name = "conv2d_resnetv17_stage2_conv1_fwd_59_fuse_multiply_60_fuse_add_resnetv17_stage2_batchnorm1_fwd_61";
  params_33->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_32, output_33, kernel_33, bias_33, params_33);
  struct csinn_tensor *output_34 = csinn_alloc_tensor(sess);
  output_34->name = "output_34";
  output_34->dtype = CSINN_DTYPE_FLOAT16;
  output_34->layout = CSINN_LAYOUT_NCHW;
  output_34->dim[0] = 1;
  output_34->dim[1] = 128;
  output_34->dim[2] = 28;
  output_34->dim[3] = 28;
  output_34->dim_count = 4;
  memcpy(output_34->qinfo, params_base + 489720, sizeof(struct csinn_quant_info) * 1);
  struct csinn_relu_params *params_34 = csinn_alloc_params(sizeof(struct csinn_relu_params), sess);
  params_34->base.name = "relu_resnetv17_stage2_relu1_fwd_62";
  params_34->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_relu_init(output_33, output_34, params_34);
  struct csinn_tensor *output_35 = csinn_alloc_tensor(sess);
  output_35->name = "output_35";
  output_35->dtype = CSINN_DTYPE_FLOAT16;
  output_35->layout = CSINN_LAYOUT_NCHW;
  output_35->dim[0] = 1;
  output_35->dim[1] = 512;
  output_35->dim[2] = 28;
  output_35->dim[3] = 28;
  output_35->dim_count = 4;
  memcpy(output_35->qinfo, params_base + 489744, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_35 = csinn_alloc_tensor(sess);
  kernel_35->name = "kernel_35";
  kernel_35->data = params_base + 502056;
  kernel_35->is_const = 1;
  kernel_35->dtype = CSINN_DTYPE_INT8;
  kernel_35->layout = CSINN_LAYOUT_OIHW;
  kernel_35->dim[0] = 512;
  kernel_35->dim[1] = 128;
  kernel_35->dim[2] = 1;
  kernel_35->dim[3] = 1;
  kernel_35->dim_count = 4;
  csinn_realloc_quant_info(kernel_35, 512);
  memcpy(kernel_35->qinfo, params_base + 489768, sizeof(struct csinn_quant_info) * 512);
  struct csinn_tensor *bias_35 = csinn_alloc_tensor(sess);
  bias_35->name = "bias_35";
  bias_35->data = params_base + 579880;
  bias_35->is_const = 1;
  bias_35->dtype = CSINN_DTYPE_FLOAT16;
  bias_35->layout = CSINN_LAYOUT_O;
  bias_35->dim[0] = 512;
  bias_35->dim_count = 1;
  csinn_realloc_quant_info(bias_35, 512);
  memcpy(bias_35->qinfo, params_base + 567592, sizeof(struct csinn_quant_info) * 512);
  struct csinn_conv2d_params *params_35 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_35->group = 1;
  params_35->stride_height = 1;
  params_35->stride_width = 1;
  params_35->dilation_height = 1;
  params_35->dilation_width = 1;
  params_35->conv_extra.kernel_tm = NULL;
  params_35->conv_extra.conv_mode = CSINN_DIRECT;
  params_35->pad_top = 0;
  params_35->pad_left = 0;
  params_35->pad_down = 0;
  params_35->pad_right = 0;
  params_35->base.name = "conv2d_resnetv17_stage2_conv2_fwd_63_fuse_bias_add_resnetv17_stage2_conv2_fwd_64_fuse_multiply_65_fuse_add_resnetv17_stage2_batchnorm2_fwd_66";
  params_35->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_34, output_35, kernel_35, bias_35, params_35);
  struct csinn_tensor *output_37 = csinn_alloc_tensor(sess);
  output_37->name = "output_37";
  output_37->dtype = CSINN_DTYPE_FLOAT16;
  output_37->layout = CSINN_LAYOUT_NCHW;
  output_37->dim[0] = 1;
  output_37->dim[1] = 512;
  output_37->dim[2] = 28;
  output_37->dim[3] = 28;
  output_37->dim_count = 4;
  memcpy(output_37->qinfo, params_base + 580904, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_37 = csinn_alloc_tensor(sess);
  kernel_37->name = "kernel_37";
  kernel_37->data = params_base + 593216;
  kernel_37->is_const = 1;
  kernel_37->dtype = CSINN_DTYPE_INT8;
  kernel_37->layout = CSINN_LAYOUT_OIHW;
  kernel_37->dim[0] = 512;
  kernel_37->dim[1] = 256;
  kernel_37->dim[2] = 1;
  kernel_37->dim[3] = 1;
  kernel_37->dim_count = 4;
  csinn_realloc_quant_info(kernel_37, 512);
  memcpy(kernel_37->qinfo, params_base + 580928, sizeof(struct csinn_quant_info) * 512);
  struct csinn_tensor *bias_37 = csinn_alloc_tensor(sess);
  bias_37->name = "bias_37";
  bias_37->data = params_base + 736576;
  bias_37->is_const = 1;
  bias_37->dtype = CSINN_DTYPE_FLOAT16;
  bias_37->layout = CSINN_LAYOUT_O;
  bias_37->dim[0] = 512;
  bias_37->dim_count = 1;
  csinn_realloc_quant_info(bias_37, 512);
  memcpy(bias_37->qinfo, params_base + 724288, sizeof(struct csinn_quant_info) * 512);
  struct csinn_conv2d_params *params_37 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_37->group = 1;
  params_37->stride_height = 2;
  params_37->stride_width = 2;
  params_37->dilation_height = 1;
  params_37->dilation_width = 1;
  params_37->conv_extra.kernel_tm = NULL;
  params_37->conv_extra.conv_mode = CSINN_DIRECT;
  params_37->pad_top = 0;
  params_37->pad_left = 0;
  params_37->pad_down = 0;
  params_37->pad_right = 0;
  params_37->base.name = "conv2d_resnetv17_stage2_conv3_fwd_67_fuse_multiply_68_fuse_add_resnetv17_stage2_batchnorm3_fwd_69";
  params_37->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_30, output_37, kernel_37, bias_37, params_37);
  struct csinn_tensor *output_38 = csinn_alloc_tensor(sess);
  output_38->name = "output_38";
  output_38->dtype = CSINN_DTYPE_FLOAT16;
  output_38->layout = CSINN_LAYOUT_NCHW;
  output_38->dim[0] = 1;
  output_38->dim[1] = 512;
  output_38->dim[2] = 28;
  output_38->dim[3] = 28;
  output_38->dim_count = 4;
  memcpy(output_38->qinfo, params_base + 737600, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_38 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_38->base.name = "add_resnetv17_stage2__plus0_70";
  params_38->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_35, output_37, output_38, params_38);
  struct csinn_tensor *output_40 = csinn_alloc_tensor(sess);
  output_40->name = "output_40";
  output_40->dtype = CSINN_DTYPE_FLOAT16;
  output_40->layout = CSINN_LAYOUT_NCHW;
  output_40->dim[0] = 1;
  output_40->dim[1] = 512;
  output_40->dim[2] = 28;
  output_40->dim[3] = 28;
  output_40->dim_count = 4;
  memcpy(output_40->qinfo, params_base + 737624, sizeof(struct csinn_quant_info) * 1);
  struct csinn_relu_params *params_40 = csinn_alloc_params(sizeof(struct csinn_relu_params), sess);
  params_40->base.name = "relu_resnetv17_stage2_activation0_71";
  params_40->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_relu_init(output_38, output_40, params_40);
  struct csinn_tensor *output_41 = csinn_alloc_tensor(sess);
  output_41->name = "output_41";
  output_41->dtype = CSINN_DTYPE_FLOAT16;
  output_41->layout = CSINN_LAYOUT_NCHW;
  output_41->dim[0] = 1;
  output_41->dim[1] = 128;
  output_41->dim[2] = 28;
  output_41->dim[3] = 28;
  output_41->dim_count = 4;
  memcpy(output_41->qinfo, params_base + 737648, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_41 = csinn_alloc_tensor(sess);
  kernel_41->name = "kernel_41";
  kernel_41->data = params_base + 740744;
  kernel_41->is_const = 1;
  kernel_41->dtype = CSINN_DTYPE_INT8;
  kernel_41->layout = CSINN_LAYOUT_OIHW;
  kernel_41->dim[0] = 128;
  kernel_41->dim[1] = 512;
  kernel_41->dim[2] = 1;
  kernel_41->dim[3] = 1;
  kernel_41->dim_count = 4;
  csinn_realloc_quant_info(kernel_41, 128);
  memcpy(kernel_41->qinfo, params_base + 737672, sizeof(struct csinn_quant_info) * 128);
  struct csinn_tensor *bias_41 = csinn_alloc_tensor(sess);
  bias_41->name = "bias_41";
  bias_41->data = params_base + 809352;
  bias_41->is_const = 1;
  bias_41->dtype = CSINN_DTYPE_FLOAT16;
  bias_41->layout = CSINN_LAYOUT_O;
  bias_41->dim[0] = 128;
  bias_41->dim_count = 1;
  csinn_realloc_quant_info(bias_41, 128);
  memcpy(bias_41->qinfo, params_base + 806280, sizeof(struct csinn_quant_info) * 128);
  struct csinn_conv2d_params *params_41 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_41->group = 1;
  params_41->stride_height = 1;
  params_41->stride_width = 1;
  params_41->dilation_height = 1;
  params_41->dilation_width = 1;
  params_41->conv_extra.kernel_tm = NULL;
  params_41->conv_extra.conv_mode = CSINN_DIRECT;
  params_41->pad_top = 0;
  params_41->pad_left = 0;
  params_41->pad_down = 0;
  params_41->pad_right = 0;
  params_41->base.name = "conv2d_resnetv17_stage2_conv4_fwd_72_fuse_bias_add_resnetv17_stage2_conv4_fwd_73_fuse_multiply_74_fuse_add_resnetv17_stage2_batchnorm4_fwd_75";
  params_41->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_40, output_41, kernel_41, bias_41, params_41);
  struct csinn_tensor *output_42 = csinn_alloc_tensor(sess);
  output_42->name = "output_42";
  output_42->dtype = CSINN_DTYPE_FLOAT16;
  output_42->layout = CSINN_LAYOUT_NCHW;
  output_42->dim[0] = 1;
  output_42->dim[1] = 128;
  output_42->dim[2] = 28;
  output_42->dim[3] = 28;
  output_42->dim_count = 4;
  memcpy(output_42->qinfo, params_base + 809608, sizeof(struct csinn_quant_info) * 1);
  struct csinn_relu_params *params_42 = csinn_alloc_params(sizeof(struct csinn_relu_params), sess);
  params_42->base.name = "relu_resnetv17_stage2_relu2_fwd_76";
  params_42->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_relu_init(output_41, output_42, params_42);
  struct csinn_tensor *output_43 = csinn_alloc_tensor(sess);
  output_43->name = "output_43";
  output_43->dtype = CSINN_DTYPE_FLOAT16;
  output_43->layout = CSINN_LAYOUT_NCHW;
  output_43->dim[0] = 1;
  output_43->dim[1] = 128;
  output_43->dim[2] = 28;
  output_43->dim[3] = 28;
  output_43->dim_count = 4;
  memcpy(output_43->qinfo, params_base + 809632, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_43 = csinn_alloc_tensor(sess);
  kernel_43->name = "kernel_43";
  kernel_43->data = params_base + 812728;
  kernel_43->is_const = 1;
  kernel_43->dtype = CSINN_DTYPE_INT8;
  kernel_43->layout = CSINN_LAYOUT_OIHW;
  kernel_43->dim[0] = 128;
  kernel_43->dim[1] = 128;
  kernel_43->dim[2] = 3;
  kernel_43->dim[3] = 3;
  kernel_43->dim_count = 4;
  csinn_realloc_quant_info(kernel_43, 128);
  memcpy(kernel_43->qinfo, params_base + 809656, sizeof(struct csinn_quant_info) * 128);
  struct csinn_tensor *bias_43 = csinn_alloc_tensor(sess);
  bias_43->name = "bias_43";
  bias_43->data = params_base + 963256;
  bias_43->is_const = 1;
  bias_43->dtype = CSINN_DTYPE_FLOAT16;
  bias_43->layout = CSINN_LAYOUT_O;
  bias_43->dim[0] = 128;
  bias_43->dim_count = 1;
  csinn_realloc_quant_info(bias_43, 128);
  memcpy(bias_43->qinfo, params_base + 960184, sizeof(struct csinn_quant_info) * 128);
  struct csinn_conv2d_params *params_43 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_43->group = 1;
  params_43->stride_height = 1;
  params_43->stride_width = 1;
  params_43->dilation_height = 1;
  params_43->dilation_width = 1;
  params_43->conv_extra.kernel_tm = NULL;
  params_43->conv_extra.conv_mode = CSINN_DIRECT;
  params_43->pad_top = 1;
  params_43->pad_left = 1;
  params_43->pad_down = 1;
  params_43->pad_right = 1;
  params_43->base.name = "conv2d_resnetv17_stage2_conv5_fwd_77_fuse_multiply_78_fuse_add_resnetv17_stage2_batchnorm5_fwd_79";
  params_43->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_42, output_43, kernel_43, bias_43, params_43);
  struct csinn_tensor *output_44 = csinn_alloc_tensor(sess);
  output_44->name = "output_44";
  output_44->dtype = CSINN_DTYPE_FLOAT16;
  output_44->layout = CSINN_LAYOUT_NCHW;
  output_44->dim[0] = 1;
  output_44->dim[1] = 128;
  output_44->dim[2] = 28;
  output_44->dim[3] = 28;
  output_44->dim_count = 4;
  memcpy(output_44->qinfo, params_base + 963512, sizeof(struct csinn_quant_info) * 1);
  struct csinn_relu_params *params_44 = csinn_alloc_params(sizeof(struct csinn_relu_params), sess);
  params_44->base.name = "relu_resnetv17_stage2_relu3_fwd_80";
  params_44->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_relu_init(output_43, output_44, params_44);
  struct csinn_tensor *output_45 = csinn_alloc_tensor(sess);
  output_45->name = "output_45";
  output_45->dtype = CSINN_DTYPE_FLOAT16;
  output_45->layout = CSINN_LAYOUT_NCHW;
  output_45->dim[0] = 1;
  output_45->dim[1] = 512;
  output_45->dim[2] = 28;
  output_45->dim[3] = 28;
  output_45->dim_count = 4;
  memcpy(output_45->qinfo, params_base + 963536, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_45 = csinn_alloc_tensor(sess);
  kernel_45->name = "kernel_45";
  kernel_45->data = params_base + 975848;
  kernel_45->is_const = 1;
  kernel_45->dtype = CSINN_DTYPE_INT8;
  kernel_45->layout = CSINN_LAYOUT_OIHW;
  kernel_45->dim[0] = 512;
  kernel_45->dim[1] = 128;
  kernel_45->dim[2] = 1;
  kernel_45->dim[3] = 1;
  kernel_45->dim_count = 4;
  csinn_realloc_quant_info(kernel_45, 512);
  memcpy(kernel_45->qinfo, params_base + 963560, sizeof(struct csinn_quant_info) * 512);
  struct csinn_tensor *bias_45 = csinn_alloc_tensor(sess);
  bias_45->name = "bias_45";
  bias_45->data = params_base + 1053672;
  bias_45->is_const = 1;
  bias_45->dtype = CSINN_DTYPE_FLOAT16;
  bias_45->layout = CSINN_LAYOUT_O;
  bias_45->dim[0] = 512;
  bias_45->dim_count = 1;
  csinn_realloc_quant_info(bias_45, 512);
  memcpy(bias_45->qinfo, params_base + 1041384, sizeof(struct csinn_quant_info) * 512);
  struct csinn_conv2d_params *params_45 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_45->group = 1;
  params_45->stride_height = 1;
  params_45->stride_width = 1;
  params_45->dilation_height = 1;
  params_45->dilation_width = 1;
  params_45->conv_extra.kernel_tm = NULL;
  params_45->conv_extra.conv_mode = CSINN_DIRECT;
  params_45->pad_top = 0;
  params_45->pad_left = 0;
  params_45->pad_down = 0;
  params_45->pad_right = 0;
  params_45->base.name = "conv2d_resnetv17_stage2_conv6_fwd_81_fuse_bias_add_resnetv17_stage2_conv6_fwd_82_fuse_multiply_83_fuse_add_resnetv17_stage2_batchnorm6_fwd_84";
  params_45->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_44, output_45, kernel_45, bias_45, params_45);
  struct csinn_tensor *output_47 = csinn_alloc_tensor(sess);
  output_47->name = "output_47";
  output_47->dtype = CSINN_DTYPE_FLOAT16;
  output_47->layout = CSINN_LAYOUT_NCHW;
  output_47->dim[0] = 1;
  output_47->dim[1] = 512;
  output_47->dim[2] = 28;
  output_47->dim[3] = 28;
  output_47->dim_count = 4;
  memcpy(output_47->qinfo, params_base + 1054696, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_47 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_47->base.name = "add_resnetv17_stage2__plus1_85";
  params_47->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_45, output_40, output_47, params_47);
  struct csinn_tensor *output_49 = csinn_alloc_tensor(sess);
  output_49->name = "output_49";
  output_49->dtype = CSINN_DTYPE_FLOAT16;
  output_49->layout = CSINN_LAYOUT_NCHW;
  output_49->dim[0] = 1;
  output_49->dim[1] = 512;
  output_49->dim[2] = 28;
  output_49->dim[3] = 28;
  output_49->dim_count = 4;
  memcpy(output_49->qinfo, params_base + 1054720, sizeof(struct csinn_quant_info) * 1);
  struct csinn_relu_params *params_49 = csinn_alloc_params(sizeof(struct csinn_relu_params), sess);
  params_49->base.name = "relu_resnetv17_stage2_activation1_86";
  params_49->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_relu_init(output_47, output_49, params_49);
  struct csinn_tensor *output_50 = csinn_alloc_tensor(sess);
  output_50->name = "output_50";
  output_50->dtype = CSINN_DTYPE_FLOAT16;
  output_50->layout = CSINN_LAYOUT_NCHW;
  output_50->dim[0] = 1;
  output_50->dim[1] = 128;
  output_50->dim[2] = 28;
  output_50->dim[3] = 28;
  output_50->dim_count = 4;
  memcpy(output_50->qinfo, params_base + 1054744, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_50 = csinn_alloc_tensor(sess);
  kernel_50->name = "kernel_50";
  kernel_50->data = params_base + 1057840;
  kernel_50->is_const = 1;
  kernel_50->dtype = CSINN_DTYPE_INT8;
  kernel_50->layout = CSINN_LAYOUT_OIHW;
  kernel_50->dim[0] = 128;
  kernel_50->dim[1] = 512;
  kernel_50->dim[2] = 1;
  kernel_50->dim[3] = 1;
  kernel_50->dim_count = 4;
  csinn_realloc_quant_info(kernel_50, 128);
  memcpy(kernel_50->qinfo, params_base + 1054768, sizeof(struct csinn_quant_info) * 128);
  struct csinn_tensor *bias_50 = csinn_alloc_tensor(sess);
  bias_50->name = "bias_50";
  bias_50->data = params_base + 1126448;
  bias_50->is_const = 1;
  bias_50->dtype = CSINN_DTYPE_FLOAT16;
  bias_50->layout = CSINN_LAYOUT_O;
  bias_50->dim[0] = 128;
  bias_50->dim_count = 1;
  csinn_realloc_quant_info(bias_50, 128);
  memcpy(bias_50->qinfo, params_base + 1123376, sizeof(struct csinn_quant_info) * 128);
  struct csinn_conv2d_params *params_50 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_50->group = 1;
  params_50->stride_height = 1;
  params_50->stride_width = 1;
  params_50->dilation_height = 1;
  params_50->dilation_width = 1;
  params_50->conv_extra.kernel_tm = NULL;
  params_50->conv_extra.conv_mode = CSINN_DIRECT;
  params_50->pad_top = 0;
  params_50->pad_left = 0;
  params_50->pad_down = 0;
  params_50->pad_right = 0;
  params_50->base.name = "conv2d_resnetv17_stage2_conv7_fwd_87_fuse_bias_add_resnetv17_stage2_conv7_fwd_88_fuse_multiply_89_fuse_add_resnetv17_stage2_batchnorm7_fwd_90";
  params_50->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_49, output_50, kernel_50, bias_50, params_50);
  struct csinn_tensor *output_51 = csinn_alloc_tensor(sess);
  output_51->name = "output_51";
  output_51->dtype = CSINN_DTYPE_FLOAT16;
  output_51->layout = CSINN_LAYOUT_NCHW;
  output_51->dim[0] = 1;
  output_51->dim[1] = 128;
  output_51->dim[2] = 28;
  output_51->dim[3] = 28;
  output_51->dim_count = 4;
  memcpy(output_51->qinfo, params_base + 1126704, sizeof(struct csinn_quant_info) * 1);
  struct csinn_relu_params *params_51 = csinn_alloc_params(sizeof(struct csinn_relu_params), sess);
  params_51->base.name = "relu_resnetv17_stage2_relu4_fwd_91";
  params_51->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_relu_init(output_50, output_51, params_51);
  struct csinn_tensor *output_52 = csinn_alloc_tensor(sess);
  output_52->name = "output_52";
  output_52->dtype = CSINN_DTYPE_FLOAT16;
  output_52->layout = CSINN_LAYOUT_NCHW;
  output_52->dim[0] = 1;
  output_52->dim[1] = 128;
  output_52->dim[2] = 28;
  output_52->dim[3] = 28;
  output_52->dim_count = 4;
  memcpy(output_52->qinfo, params_base + 1126728, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_52 = csinn_alloc_tensor(sess);
  kernel_52->name = "kernel_52";
  kernel_52->data = params_base + 1129824;
  kernel_52->is_const = 1;
  kernel_52->dtype = CSINN_DTYPE_INT8;
  kernel_52->layout = CSINN_LAYOUT_OIHW;
  kernel_52->dim[0] = 128;
  kernel_52->dim[1] = 128;
  kernel_52->dim[2] = 3;
  kernel_52->dim[3] = 3;
  kernel_52->dim_count = 4;
  csinn_realloc_quant_info(kernel_52, 128);
  memcpy(kernel_52->qinfo, params_base + 1126752, sizeof(struct csinn_quant_info) * 128);
  struct csinn_tensor *bias_52 = csinn_alloc_tensor(sess);
  bias_52->name = "bias_52";
  bias_52->data = params_base + 1280352;
  bias_52->is_const = 1;
  bias_52->dtype = CSINN_DTYPE_FLOAT16;
  bias_52->layout = CSINN_LAYOUT_O;
  bias_52->dim[0] = 128;
  bias_52->dim_count = 1;
  csinn_realloc_quant_info(bias_52, 128);
  memcpy(bias_52->qinfo, params_base + 1277280, sizeof(struct csinn_quant_info) * 128);
  struct csinn_conv2d_params *params_52 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_52->group = 1;
  params_52->stride_height = 1;
  params_52->stride_width = 1;
  params_52->dilation_height = 1;
  params_52->dilation_width = 1;
  params_52->conv_extra.kernel_tm = NULL;
  params_52->conv_extra.conv_mode = CSINN_DIRECT;
  params_52->pad_top = 1;
  params_52->pad_left = 1;
  params_52->pad_down = 1;
  params_52->pad_right = 1;
  params_52->base.name = "conv2d_resnetv17_stage2_conv8_fwd_92_fuse_multiply_93_fuse_add_resnetv17_stage2_batchnorm8_fwd_94";
  params_52->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_51, output_52, kernel_52, bias_52, params_52);
  struct csinn_tensor *output_53 = csinn_alloc_tensor(sess);
  output_53->name = "output_53";
  output_53->dtype = CSINN_DTYPE_FLOAT16;
  output_53->layout = CSINN_LAYOUT_NCHW;
  output_53->dim[0] = 1;
  output_53->dim[1] = 128;
  output_53->dim[2] = 28;
  output_53->dim[3] = 28;
  output_53->dim_count = 4;
  memcpy(output_53->qinfo, params_base + 1280608, sizeof(struct csinn_quant_info) * 1);
  struct csinn_relu_params *params_53 = csinn_alloc_params(sizeof(struct csinn_relu_params), sess);
  params_53->base.name = "relu_resnetv17_stage2_relu5_fwd_95";
  params_53->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_relu_init(output_52, output_53, params_53);
  struct csinn_tensor *output_54 = csinn_alloc_tensor(sess);
  output_54->name = "output_54";
  output_54->dtype = CSINN_DTYPE_FLOAT16;
  output_54->layout = CSINN_LAYOUT_NCHW;
  output_54->dim[0] = 1;
  output_54->dim[1] = 512;
  output_54->dim[2] = 28;
  output_54->dim[3] = 28;
  output_54->dim_count = 4;
  memcpy(output_54->qinfo, params_base + 1280632, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_54 = csinn_alloc_tensor(sess);
  kernel_54->name = "kernel_54";
  kernel_54->data = params_base + 1292944;
  kernel_54->is_const = 1;
  kernel_54->dtype = CSINN_DTYPE_INT8;
  kernel_54->layout = CSINN_LAYOUT_OIHW;
  kernel_54->dim[0] = 512;
  kernel_54->dim[1] = 128;
  kernel_54->dim[2] = 1;
  kernel_54->dim[3] = 1;
  kernel_54->dim_count = 4;
  csinn_realloc_quant_info(kernel_54, 512);
  memcpy(kernel_54->qinfo, params_base + 1280656, sizeof(struct csinn_quant_info) * 512);
  struct csinn_tensor *bias_54 = csinn_alloc_tensor(sess);
  bias_54->name = "bias_54";
  bias_54->data = params_base + 1370768;
  bias_54->is_const = 1;
  bias_54->dtype = CSINN_DTYPE_FLOAT16;
  bias_54->layout = CSINN_LAYOUT_O;
  bias_54->dim[0] = 512;
  bias_54->dim_count = 1;
  csinn_realloc_quant_info(bias_54, 512);
  memcpy(bias_54->qinfo, params_base + 1358480, sizeof(struct csinn_quant_info) * 512);
  struct csinn_conv2d_params *params_54 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_54->group = 1;
  params_54->stride_height = 1;
  params_54->stride_width = 1;
  params_54->dilation_height = 1;
  params_54->dilation_width = 1;
  params_54->conv_extra.kernel_tm = NULL;
  params_54->conv_extra.conv_mode = CSINN_DIRECT;
  params_54->pad_top = 0;
  params_54->pad_left = 0;
  params_54->pad_down = 0;
  params_54->pad_right = 0;
  params_54->base.name = "conv2d_resnetv17_stage2_conv9_fwd_96_fuse_bias_add_resnetv17_stage2_conv9_fwd_97_fuse_multiply_98_fuse_add_resnetv17_stage2_batchnorm9_fwd_99";
  params_54->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_53, output_54, kernel_54, bias_54, params_54);
  struct csinn_tensor *output_56 = csinn_alloc_tensor(sess);
  output_56->name = "output_56";
  output_56->dtype = CSINN_DTYPE_FLOAT16;
  output_56->layout = CSINN_LAYOUT_NCHW;
  output_56->dim[0] = 1;
  output_56->dim[1] = 512;
  output_56->dim[2] = 28;
  output_56->dim[3] = 28;
  output_56->dim_count = 4;
  memcpy(output_56->qinfo, params_base + 1371792, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_56 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_56->base.name = "add_resnetv17_stage2__plus2_100";
  params_56->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_54, output_49, output_56, params_56);
  struct csinn_tensor *output_58 = csinn_alloc_tensor(sess);
  output_58->name = "output_58";
  output_58->dtype = CSINN_DTYPE_FLOAT16;
  output_58->layout = CSINN_LAYOUT_NCHW;
  output_58->dim[0] = 1;
  output_58->dim[1] = 512;
  output_58->dim[2] = 28;
  output_58->dim[3] = 28;
  output_58->dim_count = 4;
  memcpy(output_58->qinfo, params_base + 1371816, sizeof(struct csinn_quant_info) * 1);
  struct csinn_relu_params *params_58 = csinn_alloc_params(sizeof(struct csinn_relu_params), sess);
  params_58->base.name = "relu_resnetv17_stage2_activation2_101";
  params_58->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_relu_init(output_56, output_58, params_58);
  struct csinn_tensor *output_59 = csinn_alloc_tensor(sess);
  output_59->name = "output_59";
  output_59->dtype = CSINN_DTYPE_FLOAT16;
  output_59->layout = CSINN_LAYOUT_NCHW;
  output_59->dim[0] = 1;
  output_59->dim[1] = 128;
  output_59->dim[2] = 28;
  output_59->dim[3] = 28;
  output_59->dim_count = 4;
  memcpy(output_59->qinfo, params_base + 1371840, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_59 = csinn_alloc_tensor(sess);
  kernel_59->name = "kernel_59";
  kernel_59->data = params_base + 1374936;
  kernel_59->is_const = 1;
  kernel_59->dtype = CSINN_DTYPE_INT8;
  kernel_59->layout = CSINN_LAYOUT_OIHW;
  kernel_59->dim[0] = 128;
  kernel_59->dim[1] = 512;
  kernel_59->dim[2] = 1;
  kernel_59->dim[3] = 1;
  kernel_59->dim_count = 4;
  csinn_realloc_quant_info(kernel_59, 128);
  memcpy(kernel_59->qinfo, params_base + 1371864, sizeof(struct csinn_quant_info) * 128);
  struct csinn_tensor *bias_59 = csinn_alloc_tensor(sess);
  bias_59->name = "bias_59";
  bias_59->data = params_base + 1443544;
  bias_59->is_const = 1;
  bias_59->dtype = CSINN_DTYPE_FLOAT16;
  bias_59->layout = CSINN_LAYOUT_O;
  bias_59->dim[0] = 128;
  bias_59->dim_count = 1;
  csinn_realloc_quant_info(bias_59, 128);
  memcpy(bias_59->qinfo, params_base + 1440472, sizeof(struct csinn_quant_info) * 128);
  struct csinn_conv2d_params *params_59 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_59->group = 1;
  params_59->stride_height = 1;
  params_59->stride_width = 1;
  params_59->dilation_height = 1;
  params_59->dilation_width = 1;
  params_59->conv_extra.kernel_tm = NULL;
  params_59->conv_extra.conv_mode = CSINN_DIRECT;
  params_59->pad_top = 0;
  params_59->pad_left = 0;
  params_59->pad_down = 0;
  params_59->pad_right = 0;
  params_59->base.name = "conv2d_resnetv17_stage2_conv10_fwd_102_fuse_bias_add_resnetv17_stage2_conv10_fwd_103_fuse_multiply_104_fuse_add_resnetv17_stage2_batchnorm10_fwd_105";
  params_59->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_58, output_59, kernel_59, bias_59, params_59);
  struct csinn_tensor *output_60 = csinn_alloc_tensor(sess);
  output_60->name = "output_60";
  output_60->dtype = CSINN_DTYPE_FLOAT16;
  output_60->layout = CSINN_LAYOUT_NCHW;
  output_60->dim[0] = 1;
  output_60->dim[1] = 128;
  output_60->dim[2] = 28;
  output_60->dim[3] = 28;
  output_60->dim_count = 4;
  memcpy(output_60->qinfo, params_base + 1443800, sizeof(struct csinn_quant_info) * 1);
  struct csinn_relu_params *params_60 = csinn_alloc_params(sizeof(struct csinn_relu_params), sess);
  params_60->base.name = "relu_resnetv17_stage2_relu6_fwd_106";
  params_60->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_relu_init(output_59, output_60, params_60);
  struct csinn_tensor *output_61 = csinn_alloc_tensor(sess);
  output_61->name = "output_61";
  output_61->dtype = CSINN_DTYPE_FLOAT16;
  output_61->layout = CSINN_LAYOUT_NCHW;
  output_61->dim[0] = 1;
  output_61->dim[1] = 128;
  output_61->dim[2] = 28;
  output_61->dim[3] = 28;
  output_61->dim_count = 4;
  memcpy(output_61->qinfo, params_base + 1443824, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_61 = csinn_alloc_tensor(sess);
  kernel_61->name = "kernel_61";
  kernel_61->data = params_base + 1446920;
  kernel_61->is_const = 1;
  kernel_61->dtype = CSINN_DTYPE_INT8;
  kernel_61->layout = CSINN_LAYOUT_OIHW;
  kernel_61->dim[0] = 128;
  kernel_61->dim[1] = 128;
  kernel_61->dim[2] = 3;
  kernel_61->dim[3] = 3;
  kernel_61->dim_count = 4;
  csinn_realloc_quant_info(kernel_61, 128);
  memcpy(kernel_61->qinfo, params_base + 1443848, sizeof(struct csinn_quant_info) * 128);
  struct csinn_tensor *bias_61 = csinn_alloc_tensor(sess);
  bias_61->name = "bias_61";
  bias_61->data = params_base + 1597448;
  bias_61->is_const = 1;
  bias_61->dtype = CSINN_DTYPE_FLOAT16;
  bias_61->layout = CSINN_LAYOUT_O;
  bias_61->dim[0] = 128;
  bias_61->dim_count = 1;
  csinn_realloc_quant_info(bias_61, 128);
  memcpy(bias_61->qinfo, params_base + 1594376, sizeof(struct csinn_quant_info) * 128);
  struct csinn_conv2d_params *params_61 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_61->group = 1;
  params_61->stride_height = 1;
  params_61->stride_width = 1;
  params_61->dilation_height = 1;
  params_61->dilation_width = 1;
  params_61->conv_extra.kernel_tm = NULL;
  params_61->conv_extra.conv_mode = CSINN_DIRECT;
  params_61->pad_top = 1;
  params_61->pad_left = 1;
  params_61->pad_down = 1;
  params_61->pad_right = 1;
  params_61->base.name = "conv2d_resnetv17_stage2_conv11_fwd_107_fuse_multiply_108_fuse_add_resnetv17_stage2_batchnorm11_fwd_109";
  params_61->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_60, output_61, kernel_61, bias_61, params_61);
  struct csinn_tensor *output_62 = csinn_alloc_tensor(sess);
  output_62->name = "output_62";
  output_62->dtype = CSINN_DTYPE_FLOAT16;
  output_62->layout = CSINN_LAYOUT_NCHW;
  output_62->dim[0] = 1;
  output_62->dim[1] = 128;
  output_62->dim[2] = 28;
  output_62->dim[3] = 28;
  output_62->dim_count = 4;
  memcpy(output_62->qinfo, params_base + 1597704, sizeof(struct csinn_quant_info) * 1);
  struct csinn_relu_params *params_62 = csinn_alloc_params(sizeof(struct csinn_relu_params), sess);
  params_62->base.name = "relu_resnetv17_stage2_relu7_fwd_110";
  params_62->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_relu_init(output_61, output_62, params_62);
  struct csinn_tensor *output_63 = csinn_alloc_tensor(sess);
  output_63->name = "output_63";
  output_63->dtype = CSINN_DTYPE_FLOAT16;
  output_63->layout = CSINN_LAYOUT_NCHW;
  output_63->dim[0] = 1;
  output_63->dim[1] = 512;
  output_63->dim[2] = 28;
  output_63->dim[3] = 28;
  output_63->dim_count = 4;
  memcpy(output_63->qinfo, params_base + 1597728, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_63 = csinn_alloc_tensor(sess);
  kernel_63->name = "kernel_63";
  kernel_63->data = params_base + 1610040;
  kernel_63->is_const = 1;
  kernel_63->dtype = CSINN_DTYPE_INT8;
  kernel_63->layout = CSINN_LAYOUT_OIHW;
  kernel_63->dim[0] = 512;
  kernel_63->dim[1] = 128;
  kernel_63->dim[2] = 1;
  kernel_63->dim[3] = 1;
  kernel_63->dim_count = 4;
  csinn_realloc_quant_info(kernel_63, 512);
  memcpy(kernel_63->qinfo, params_base + 1597752, sizeof(struct csinn_quant_info) * 512);
  struct csinn_tensor *bias_63 = csinn_alloc_tensor(sess);
  bias_63->name = "bias_63";
  bias_63->data = params_base + 1687864;
  bias_63->is_const = 1;
  bias_63->dtype = CSINN_DTYPE_FLOAT16;
  bias_63->layout = CSINN_LAYOUT_O;
  bias_63->dim[0] = 512;
  bias_63->dim_count = 1;
  csinn_realloc_quant_info(bias_63, 512);
  memcpy(bias_63->qinfo, params_base + 1675576, sizeof(struct csinn_quant_info) * 512);
  struct csinn_conv2d_params *params_63 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_63->group = 1;
  params_63->stride_height = 1;
  params_63->stride_width = 1;
  params_63->dilation_height = 1;
  params_63->dilation_width = 1;
  params_63->conv_extra.kernel_tm = NULL;
  params_63->conv_extra.conv_mode = CSINN_DIRECT;
  params_63->pad_top = 0;
  params_63->pad_left = 0;
  params_63->pad_down = 0;
  params_63->pad_right = 0;
  params_63->base.name = "conv2d_resnetv17_stage2_conv12_fwd_111_fuse_bias_add_resnetv17_stage2_conv12_fwd_112_fuse_multiply_113_fuse_add_resnetv17_stage2_batchnorm12_fwd_114";
  params_63->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_62, output_63, kernel_63, bias_63, params_63);
  struct csinn_tensor *output_65 = csinn_alloc_tensor(sess);
  output_65->name = "output_65";
  output_65->dtype = CSINN_DTYPE_FLOAT16;
  output_65->layout = CSINN_LAYOUT_NCHW;
  output_65->dim[0] = 1;
  output_65->dim[1] = 512;
  output_65->dim[2] = 28;
  output_65->dim[3] = 28;
  output_65->dim_count = 4;
  memcpy(output_65->qinfo, params_base + 1688888, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_65 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_65->base.name = "add_resnetv17_stage2__plus3_115";
  params_65->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_63, output_58, output_65, params_65);
  struct csinn_tensor *output_67 = csinn_alloc_tensor(sess);
  output_67->name = "output_67";
  output_67->dtype = CSINN_DTYPE_FLOAT16;
  output_67->layout = CSINN_LAYOUT_NCHW;
  output_67->dim[0] = 1;
  output_67->dim[1] = 512;
  output_67->dim[2] = 28;
  output_67->dim[3] = 28;
  output_67->dim_count = 4;
  memcpy(output_67->qinfo, params_base + 1688912, sizeof(struct csinn_quant_info) * 1);
  struct csinn_relu_params *params_67 = csinn_alloc_params(sizeof(struct csinn_relu_params), sess);
  params_67->base.name = "relu_resnetv17_stage2_activation3_116";
  params_67->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_relu_init(output_65, output_67, params_67);
  struct csinn_tensor *output_68 = csinn_alloc_tensor(sess);
  output_68->name = "output_68";
  output_68->dtype = CSINN_DTYPE_FLOAT16;
  output_68->layout = CSINN_LAYOUT_NCHW;
  output_68->dim[0] = 1;
  output_68->dim[1] = 256;
  output_68->dim[2] = 14;
  output_68->dim[3] = 14;
  output_68->dim_count = 4;
  memcpy(output_68->qinfo, params_base + 1688936, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_68 = csinn_alloc_tensor(sess);
  kernel_68->name = "kernel_68";
  kernel_68->data = params_base + 1695104;
  kernel_68->is_const = 1;
  kernel_68->dtype = CSINN_DTYPE_INT8;
  kernel_68->layout = CSINN_LAYOUT_OIHW;
  kernel_68->dim[0] = 256;
  kernel_68->dim[1] = 512;
  kernel_68->dim[2] = 1;
  kernel_68->dim[3] = 1;
  kernel_68->dim_count = 4;
  csinn_realloc_quant_info(kernel_68, 256);
  memcpy(kernel_68->qinfo, params_base + 1688960, sizeof(struct csinn_quant_info) * 256);
  struct csinn_tensor *bias_68 = csinn_alloc_tensor(sess);
  bias_68->name = "bias_68";
  bias_68->data = params_base + 1832320;
  bias_68->is_const = 1;
  bias_68->dtype = CSINN_DTYPE_FLOAT16;
  bias_68->layout = CSINN_LAYOUT_O;
  bias_68->dim[0] = 256;
  bias_68->dim_count = 1;
  csinn_realloc_quant_info(bias_68, 256);
  memcpy(bias_68->qinfo, params_base + 1826176, sizeof(struct csinn_quant_info) * 256);
  struct csinn_conv2d_params *params_68 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_68->group = 1;
  params_68->stride_height = 2;
  params_68->stride_width = 2;
  params_68->dilation_height = 1;
  params_68->dilation_width = 1;
  params_68->conv_extra.kernel_tm = NULL;
  params_68->conv_extra.conv_mode = CSINN_DIRECT;
  params_68->pad_top = 0;
  params_68->pad_left = 0;
  params_68->pad_down = 0;
  params_68->pad_right = 0;
  params_68->base.name = "conv2d_resnetv17_stage3_conv0_fwd_117_fuse_bias_add_resnetv17_stage3_conv0_fwd_118_fuse_multiply_119_fuse_add_resnetv17_stage3_batchnorm0_fwd_120";
  params_68->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_67, output_68, kernel_68, bias_68, params_68);
  struct csinn_tensor *output_69 = csinn_alloc_tensor(sess);
  output_69->name = "output_69";
  output_69->dtype = CSINN_DTYPE_FLOAT16;
  output_69->layout = CSINN_LAYOUT_NCHW;
  output_69->dim[0] = 1;
  output_69->dim[1] = 256;
  output_69->dim[2] = 14;
  output_69->dim[3] = 14;
  output_69->dim_count = 4;
  memcpy(output_69->qinfo, params_base + 1832832, sizeof(struct csinn_quant_info) * 1);
  struct csinn_relu_params *params_69 = csinn_alloc_params(sizeof(struct csinn_relu_params), sess);
  params_69->base.name = "relu_resnetv17_stage3_relu0_fwd_121";
  params_69->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_relu_init(output_68, output_69, params_69);
  struct csinn_tensor *output_70 = csinn_alloc_tensor(sess);
  output_70->name = "output_70";
  output_70->dtype = CSINN_DTYPE_FLOAT16;
  output_70->layout = CSINN_LAYOUT_NCHW;
  output_70->dim[0] = 1;
  output_70->dim[1] = 256;
  output_70->dim[2] = 14;
  output_70->dim[3] = 14;
  output_70->dim_count = 4;
  memcpy(output_70->qinfo, params_base + 1832856, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_70 = csinn_alloc_tensor(sess);
  kernel_70->name = "kernel_70";
  kernel_70->data = params_base + 1839024;
  kernel_70->is_const = 1;
  kernel_70->dtype = CSINN_DTYPE_INT8;
  kernel_70->layout = CSINN_LAYOUT_OIHW;
  kernel_70->dim[0] = 256;
  kernel_70->dim[1] = 256;
  kernel_70->dim[2] = 3;
  kernel_70->dim[3] = 3;
  kernel_70->dim_count = 4;
  csinn_realloc_quant_info(kernel_70, 256);
  memcpy(kernel_70->qinfo, params_base + 1832880, sizeof(struct csinn_quant_info) * 256);
  struct csinn_tensor *bias_70 = csinn_alloc_tensor(sess);
  bias_70->name = "bias_70";
  bias_70->data = params_base + 2434992;
  bias_70->is_const = 1;
  bias_70->dtype = CSINN_DTYPE_FLOAT16;
  bias_70->layout = CSINN_LAYOUT_O;
  bias_70->dim[0] = 256;
  bias_70->dim_count = 1;
  csinn_realloc_quant_info(bias_70, 256);
  memcpy(bias_70->qinfo, params_base + 2428848, sizeof(struct csinn_quant_info) * 256);
  struct csinn_conv2d_params *params_70 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_70->group = 1;
  params_70->stride_height = 1;
  params_70->stride_width = 1;
  params_70->dilation_height = 1;
  params_70->dilation_width = 1;
  params_70->conv_extra.kernel_tm = NULL;
  params_70->conv_extra.conv_mode = CSINN_DIRECT;
  params_70->pad_top = 1;
  params_70->pad_left = 1;
  params_70->pad_down = 1;
  params_70->pad_right = 1;
  params_70->base.name = "conv2d_resnetv17_stage3_conv1_fwd_122_fuse_multiply_123_fuse_add_resnetv17_stage3_batchnorm1_fwd_124";
  params_70->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_69, output_70, kernel_70, bias_70, params_70);
  struct csinn_tensor *output_71 = csinn_alloc_tensor(sess);
  output_71->name = "output_71";
  output_71->dtype = CSINN_DTYPE_FLOAT16;
  output_71->layout = CSINN_LAYOUT_NCHW;
  output_71->dim[0] = 1;
  output_71->dim[1] = 256;
  output_71->dim[2] = 14;
  output_71->dim[3] = 14;
  output_71->dim_count = 4;
  memcpy(output_71->qinfo, params_base + 2435504, sizeof(struct csinn_quant_info) * 1);
  struct csinn_relu_params *params_71 = csinn_alloc_params(sizeof(struct csinn_relu_params), sess);
  params_71->base.name = "relu_resnetv17_stage3_relu1_fwd_125";
  params_71->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_relu_init(output_70, output_71, params_71);
  struct csinn_tensor *output_72 = csinn_alloc_tensor(sess);
  output_72->name = "output_72";
  output_72->dtype = CSINN_DTYPE_FLOAT16;
  output_72->layout = CSINN_LAYOUT_NCHW;
  output_72->dim[0] = 1;
  output_72->dim[1] = 1024;
  output_72->dim[2] = 14;
  output_72->dim[3] = 14;
  output_72->dim_count = 4;
  memcpy(output_72->qinfo, params_base + 2435528, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_72 = csinn_alloc_tensor(sess);
  kernel_72->name = "kernel_72";
  kernel_72->data = params_base + 2460128;
  kernel_72->is_const = 1;
  kernel_72->dtype = CSINN_DTYPE_INT8;
  kernel_72->layout = CSINN_LAYOUT_OIHW;
  kernel_72->dim[0] = 1024;
  kernel_72->dim[1] = 256;
  kernel_72->dim[2] = 1;
  kernel_72->dim[3] = 1;
  kernel_72->dim_count = 4;
  csinn_realloc_quant_info(kernel_72, 1024);
  memcpy(kernel_72->qinfo, params_base + 2435552, sizeof(struct csinn_quant_info) * 1024);
  struct csinn_tensor *bias_72 = csinn_alloc_tensor(sess);
  bias_72->name = "bias_72";
  bias_72->data = params_base + 2746848;
  bias_72->is_const = 1;
  bias_72->dtype = CSINN_DTYPE_FLOAT16;
  bias_72->layout = CSINN_LAYOUT_O;
  bias_72->dim[0] = 1024;
  bias_72->dim_count = 1;
  csinn_realloc_quant_info(bias_72, 1024);
  memcpy(bias_72->qinfo, params_base + 2722272, sizeof(struct csinn_quant_info) * 1024);
  struct csinn_conv2d_params *params_72 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_72->group = 1;
  params_72->stride_height = 1;
  params_72->stride_width = 1;
  params_72->dilation_height = 1;
  params_72->dilation_width = 1;
  params_72->conv_extra.kernel_tm = NULL;
  params_72->conv_extra.conv_mode = CSINN_DIRECT;
  params_72->pad_top = 0;
  params_72->pad_left = 0;
  params_72->pad_down = 0;
  params_72->pad_right = 0;
  params_72->base.name = "conv2d_resnetv17_stage3_conv2_fwd_126_fuse_bias_add_resnetv17_stage3_conv2_fwd_127_fuse_multiply_128_fuse_add_resnetv17_stage3_batchnorm2_fwd_129";
  params_72->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_71, output_72, kernel_72, bias_72, params_72);
  struct csinn_tensor *output_74 = csinn_alloc_tensor(sess);
  output_74->name = "output_74";
  output_74->dtype = CSINN_DTYPE_FLOAT16;
  output_74->layout = CSINN_LAYOUT_NCHW;
  output_74->dim[0] = 1;
  output_74->dim[1] = 1024;
  output_74->dim[2] = 14;
  output_74->dim[3] = 14;
  output_74->dim_count = 4;
  memcpy(output_74->qinfo, params_base + 2748896, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_74 = csinn_alloc_tensor(sess);
  kernel_74->name = "kernel_74";
  kernel_74->data = params_base + 2773496;
  kernel_74->is_const = 1;
  kernel_74->dtype = CSINN_DTYPE_INT8;
  kernel_74->layout = CSINN_LAYOUT_OIHW;
  kernel_74->dim[0] = 1024;
  kernel_74->dim[1] = 512;
  kernel_74->dim[2] = 1;
  kernel_74->dim[3] = 1;
  kernel_74->dim_count = 4;
  csinn_realloc_quant_info(kernel_74, 1024);
  memcpy(kernel_74->qinfo, params_base + 2748920, sizeof(struct csinn_quant_info) * 1024);
  struct csinn_tensor *bias_74 = csinn_alloc_tensor(sess);
  bias_74->name = "bias_74";
  bias_74->data = params_base + 3322360;
  bias_74->is_const = 1;
  bias_74->dtype = CSINN_DTYPE_FLOAT16;
  bias_74->layout = CSINN_LAYOUT_O;
  bias_74->dim[0] = 1024;
  bias_74->dim_count = 1;
  csinn_realloc_quant_info(bias_74, 1024);
  memcpy(bias_74->qinfo, params_base + 3297784, sizeof(struct csinn_quant_info) * 1024);
  struct csinn_conv2d_params *params_74 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_74->group = 1;
  params_74->stride_height = 2;
  params_74->stride_width = 2;
  params_74->dilation_height = 1;
  params_74->dilation_width = 1;
  params_74->conv_extra.kernel_tm = NULL;
  params_74->conv_extra.conv_mode = CSINN_DIRECT;
  params_74->pad_top = 0;
  params_74->pad_left = 0;
  params_74->pad_down = 0;
  params_74->pad_right = 0;
  params_74->base.name = "conv2d_resnetv17_stage3_conv3_fwd_130_fuse_multiply_131_fuse_add_resnetv17_stage3_batchnorm3_fwd_132";
  params_74->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_67, output_74, kernel_74, bias_74, params_74);
  struct csinn_tensor *output_75 = csinn_alloc_tensor(sess);
  output_75->name = "output_75";
  output_75->dtype = CSINN_DTYPE_FLOAT16;
  output_75->layout = CSINN_LAYOUT_NCHW;
  output_75->dim[0] = 1;
  output_75->dim[1] = 1024;
  output_75->dim[2] = 14;
  output_75->dim[3] = 14;
  output_75->dim_count = 4;
  memcpy(output_75->qinfo, params_base + 3324408, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_75 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_75->base.name = "add_resnetv17_stage3__plus0_133";
  params_75->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_72, output_74, output_75, params_75);
  struct csinn_tensor *output_77 = csinn_alloc_tensor(sess);
  output_77->name = "output_77";
  output_77->dtype = CSINN_DTYPE_FLOAT16;
  output_77->layout = CSINN_LAYOUT_NCHW;
  output_77->dim[0] = 1;
  output_77->dim[1] = 1024;
  output_77->dim[2] = 14;
  output_77->dim[3] = 14;
  output_77->dim_count = 4;
  memcpy(output_77->qinfo, params_base + 3324432, sizeof(struct csinn_quant_info) * 1);
  struct csinn_relu_params *params_77 = csinn_alloc_params(sizeof(struct csinn_relu_params), sess);
  params_77->base.name = "relu_resnetv17_stage3_activation0_134";
  params_77->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_relu_init(output_75, output_77, params_77);
  struct csinn_tensor *output_78 = csinn_alloc_tensor(sess);
  output_78->name = "output_78";
  output_78->dtype = CSINN_DTYPE_FLOAT16;
  output_78->layout = CSINN_LAYOUT_NCHW;
  output_78->dim[0] = 1;
  output_78->dim[1] = 256;
  output_78->dim[2] = 14;
  output_78->dim[3] = 14;
  output_78->dim_count = 4;
  memcpy(output_78->qinfo, params_base + 3324456, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_78 = csinn_alloc_tensor(sess);
  kernel_78->name = "kernel_78";
  kernel_78->data = params_base + 3330624;
  kernel_78->is_const = 1;
  kernel_78->dtype = CSINN_DTYPE_INT8;
  kernel_78->layout = CSINN_LAYOUT_OIHW;
  kernel_78->dim[0] = 256;
  kernel_78->dim[1] = 1024;
  kernel_78->dim[2] = 1;
  kernel_78->dim[3] = 1;
  kernel_78->dim_count = 4;
  csinn_realloc_quant_info(kernel_78, 256);
  memcpy(kernel_78->qinfo, params_base + 3324480, sizeof(struct csinn_quant_info) * 256);
  struct csinn_tensor *bias_78 = csinn_alloc_tensor(sess);
  bias_78->name = "bias_78";
  bias_78->data = params_base + 3598912;
  bias_78->is_const = 1;
  bias_78->dtype = CSINN_DTYPE_FLOAT16;
  bias_78->layout = CSINN_LAYOUT_O;
  bias_78->dim[0] = 256;
  bias_78->dim_count = 1;
  csinn_realloc_quant_info(bias_78, 256);
  memcpy(bias_78->qinfo, params_base + 3592768, sizeof(struct csinn_quant_info) * 256);
  struct csinn_conv2d_params *params_78 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_78->group = 1;
  params_78->stride_height = 1;
  params_78->stride_width = 1;
  params_78->dilation_height = 1;
  params_78->dilation_width = 1;
  params_78->conv_extra.kernel_tm = NULL;
  params_78->conv_extra.conv_mode = CSINN_DIRECT;
  params_78->pad_top = 0;
  params_78->pad_left = 0;
  params_78->pad_down = 0;
  params_78->pad_right = 0;
  params_78->base.name = "conv2d_resnetv17_stage3_conv4_fwd_135_fuse_bias_add_resnetv17_stage3_conv4_fwd_136_fuse_multiply_137_fuse_add_resnetv17_stage3_batchnorm4_fwd_138";
  params_78->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_77, output_78, kernel_78, bias_78, params_78);
  struct csinn_tensor *output_79 = csinn_alloc_tensor(sess);
  output_79->name = "output_79";
  output_79->dtype = CSINN_DTYPE_FLOAT16;
  output_79->layout = CSINN_LAYOUT_NCHW;
  output_79->dim[0] = 1;
  output_79->dim[1] = 256;
  output_79->dim[2] = 14;
  output_79->dim[3] = 14;
  output_79->dim_count = 4;
  memcpy(output_79->qinfo, params_base + 3599424, sizeof(struct csinn_quant_info) * 1);
  struct csinn_relu_params *params_79 = csinn_alloc_params(sizeof(struct csinn_relu_params), sess);
  params_79->base.name = "relu_resnetv17_stage3_relu2_fwd_139";
  params_79->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_relu_init(output_78, output_79, params_79);
  struct csinn_tensor *output_80 = csinn_alloc_tensor(sess);
  output_80->name = "output_80";
  output_80->dtype = CSINN_DTYPE_FLOAT16;
  output_80->layout = CSINN_LAYOUT_NCHW;
  output_80->dim[0] = 1;
  output_80->dim[1] = 256;
  output_80->dim[2] = 14;
  output_80->dim[3] = 14;
  output_80->dim_count = 4;
  memcpy(output_80->qinfo, params_base + 3599448, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_80 = csinn_alloc_tensor(sess);
  kernel_80->name = "kernel_80";
  kernel_80->data = params_base + 3605616;
  kernel_80->is_const = 1;
  kernel_80->dtype = CSINN_DTYPE_INT8;
  kernel_80->layout = CSINN_LAYOUT_OIHW;
  kernel_80->dim[0] = 256;
  kernel_80->dim[1] = 256;
  kernel_80->dim[2] = 3;
  kernel_80->dim[3] = 3;
  kernel_80->dim_count = 4;
  csinn_realloc_quant_info(kernel_80, 256);
  memcpy(kernel_80->qinfo, params_base + 3599472, sizeof(struct csinn_quant_info) * 256);
  struct csinn_tensor *bias_80 = csinn_alloc_tensor(sess);
  bias_80->name = "bias_80";
  bias_80->data = params_base + 4201584;
  bias_80->is_const = 1;
  bias_80->dtype = CSINN_DTYPE_FLOAT16;
  bias_80->layout = CSINN_LAYOUT_O;
  bias_80->dim[0] = 256;
  bias_80->dim_count = 1;
  csinn_realloc_quant_info(bias_80, 256);
  memcpy(bias_80->qinfo, params_base + 4195440, sizeof(struct csinn_quant_info) * 256);
  struct csinn_conv2d_params *params_80 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_80->group = 1;
  params_80->stride_height = 1;
  params_80->stride_width = 1;
  params_80->dilation_height = 1;
  params_80->dilation_width = 1;
  params_80->conv_extra.kernel_tm = NULL;
  params_80->conv_extra.conv_mode = CSINN_DIRECT;
  params_80->pad_top = 1;
  params_80->pad_left = 1;
  params_80->pad_down = 1;
  params_80->pad_right = 1;
  params_80->base.name = "conv2d_resnetv17_stage3_conv5_fwd_140_fuse_multiply_141_fuse_add_resnetv17_stage3_batchnorm5_fwd_142";
  params_80->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_79, output_80, kernel_80, bias_80, params_80);
  struct csinn_tensor *output_81 = csinn_alloc_tensor(sess);
  output_81->name = "output_81";
  output_81->dtype = CSINN_DTYPE_FLOAT16;
  output_81->layout = CSINN_LAYOUT_NCHW;
  output_81->dim[0] = 1;
  output_81->dim[1] = 256;
  output_81->dim[2] = 14;
  output_81->dim[3] = 14;
  output_81->dim_count = 4;
  memcpy(output_81->qinfo, params_base + 4202096, sizeof(struct csinn_quant_info) * 1);
  struct csinn_relu_params *params_81 = csinn_alloc_params(sizeof(struct csinn_relu_params), sess);
  params_81->base.name = "relu_resnetv17_stage3_relu3_fwd_143";
  params_81->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_relu_init(output_80, output_81, params_81);
  struct csinn_tensor *output_82 = csinn_alloc_tensor(sess);
  output_82->name = "output_82";
  output_82->dtype = CSINN_DTYPE_FLOAT16;
  output_82->layout = CSINN_LAYOUT_NCHW;
  output_82->dim[0] = 1;
  output_82->dim[1] = 1024;
  output_82->dim[2] = 14;
  output_82->dim[3] = 14;
  output_82->dim_count = 4;
  memcpy(output_82->qinfo, params_base + 4202120, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_82 = csinn_alloc_tensor(sess);
  kernel_82->name = "kernel_82";
  kernel_82->data = params_base + 4226720;
  kernel_82->is_const = 1;
  kernel_82->dtype = CSINN_DTYPE_INT8;
  kernel_82->layout = CSINN_LAYOUT_OIHW;
  kernel_82->dim[0] = 1024;
  kernel_82->dim[1] = 256;
  kernel_82->dim[2] = 1;
  kernel_82->dim[3] = 1;
  kernel_82->dim_count = 4;
  csinn_realloc_quant_info(kernel_82, 1024);
  memcpy(kernel_82->qinfo, params_base + 4202144, sizeof(struct csinn_quant_info) * 1024);
  struct csinn_tensor *bias_82 = csinn_alloc_tensor(sess);
  bias_82->name = "bias_82";
  bias_82->data = params_base + 4513440;
  bias_82->is_const = 1;
  bias_82->dtype = CSINN_DTYPE_FLOAT16;
  bias_82->layout = CSINN_LAYOUT_O;
  bias_82->dim[0] = 1024;
  bias_82->dim_count = 1;
  csinn_realloc_quant_info(bias_82, 1024);
  memcpy(bias_82->qinfo, params_base + 4488864, sizeof(struct csinn_quant_info) * 1024);
  struct csinn_conv2d_params *params_82 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_82->group = 1;
  params_82->stride_height = 1;
  params_82->stride_width = 1;
  params_82->dilation_height = 1;
  params_82->dilation_width = 1;
  params_82->conv_extra.kernel_tm = NULL;
  params_82->conv_extra.conv_mode = CSINN_DIRECT;
  params_82->pad_top = 0;
  params_82->pad_left = 0;
  params_82->pad_down = 0;
  params_82->pad_right = 0;
  params_82->base.name = "conv2d_resnetv17_stage3_conv6_fwd_144_fuse_bias_add_resnetv17_stage3_conv6_fwd_145_fuse_multiply_146_fuse_add_resnetv17_stage3_batchnorm6_fwd_147";
  params_82->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_81, output_82, kernel_82, bias_82, params_82);
  struct csinn_tensor *output_84 = csinn_alloc_tensor(sess);
  output_84->name = "output_84";
  output_84->dtype = CSINN_DTYPE_FLOAT16;
  output_84->layout = CSINN_LAYOUT_NCHW;
  output_84->dim[0] = 1;
  output_84->dim[1] = 1024;
  output_84->dim[2] = 14;
  output_84->dim[3] = 14;
  output_84->dim_count = 4;
  memcpy(output_84->qinfo, params_base + 4515488, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_84 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_84->base.name = "add_resnetv17_stage3__plus1_148";
  params_84->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_82, output_77, output_84, params_84);
  struct csinn_tensor *output_86 = csinn_alloc_tensor(sess);
  output_86->name = "output_86";
  output_86->dtype = CSINN_DTYPE_FLOAT16;
  output_86->layout = CSINN_LAYOUT_NCHW;
  output_86->dim[0] = 1;
  output_86->dim[1] = 1024;
  output_86->dim[2] = 14;
  output_86->dim[3] = 14;
  output_86->dim_count = 4;
  memcpy(output_86->qinfo, params_base + 4515512, sizeof(struct csinn_quant_info) * 1);
  struct csinn_relu_params *params_86 = csinn_alloc_params(sizeof(struct csinn_relu_params), sess);
  params_86->base.name = "relu_resnetv17_stage3_activation1_149";
  params_86->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_relu_init(output_84, output_86, params_86);
  struct csinn_tensor *output_87 = csinn_alloc_tensor(sess);
  output_87->name = "output_87";
  output_87->dtype = CSINN_DTYPE_FLOAT16;
  output_87->layout = CSINN_LAYOUT_NCHW;
  output_87->dim[0] = 1;
  output_87->dim[1] = 256;
  output_87->dim[2] = 14;
  output_87->dim[3] = 14;
  output_87->dim_count = 4;
  memcpy(output_87->qinfo, params_base + 4515536, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_87 = csinn_alloc_tensor(sess);
  kernel_87->name = "kernel_87";
  kernel_87->data = params_base + 4521704;
  kernel_87->is_const = 1;
  kernel_87->dtype = CSINN_DTYPE_INT8;
  kernel_87->layout = CSINN_LAYOUT_OIHW;
  kernel_87->dim[0] = 256;
  kernel_87->dim[1] = 1024;
  kernel_87->dim[2] = 1;
  kernel_87->dim[3] = 1;
  kernel_87->dim_count = 4;
  csinn_realloc_quant_info(kernel_87, 256);
  memcpy(kernel_87->qinfo, params_base + 4515560, sizeof(struct csinn_quant_info) * 256);
  struct csinn_tensor *bias_87 = csinn_alloc_tensor(sess);
  bias_87->name = "bias_87";
  bias_87->data = params_base + 4789992;
  bias_87->is_const = 1;
  bias_87->dtype = CSINN_DTYPE_FLOAT16;
  bias_87->layout = CSINN_LAYOUT_O;
  bias_87->dim[0] = 256;
  bias_87->dim_count = 1;
  csinn_realloc_quant_info(bias_87, 256);
  memcpy(bias_87->qinfo, params_base + 4783848, sizeof(struct csinn_quant_info) * 256);
  struct csinn_conv2d_params *params_87 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_87->group = 1;
  params_87->stride_height = 1;
  params_87->stride_width = 1;
  params_87->dilation_height = 1;
  params_87->dilation_width = 1;
  params_87->conv_extra.kernel_tm = NULL;
  params_87->conv_extra.conv_mode = CSINN_DIRECT;
  params_87->pad_top = 0;
  params_87->pad_left = 0;
  params_87->pad_down = 0;
  params_87->pad_right = 0;
  params_87->base.name = "conv2d_resnetv17_stage3_conv7_fwd_150_fuse_bias_add_resnetv17_stage3_conv7_fwd_151_fuse_multiply_152_fuse_add_resnetv17_stage3_batchnorm7_fwd_153";
  params_87->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_86, output_87, kernel_87, bias_87, params_87);
  struct csinn_tensor *output_88 = csinn_alloc_tensor(sess);
  output_88->name = "output_88";
  output_88->dtype = CSINN_DTYPE_FLOAT16;
  output_88->layout = CSINN_LAYOUT_NCHW;
  output_88->dim[0] = 1;
  output_88->dim[1] = 256;
  output_88->dim[2] = 14;
  output_88->dim[3] = 14;
  output_88->dim_count = 4;
  memcpy(output_88->qinfo, params_base + 4790504, sizeof(struct csinn_quant_info) * 1);
  struct csinn_relu_params *params_88 = csinn_alloc_params(sizeof(struct csinn_relu_params), sess);
  params_88->base.name = "relu_resnetv17_stage3_relu4_fwd_154";
  params_88->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_relu_init(output_87, output_88, params_88);
  struct csinn_tensor *output_89 = csinn_alloc_tensor(sess);
  output_89->name = "output_89";
  output_89->dtype = CSINN_DTYPE_FLOAT16;
  output_89->layout = CSINN_LAYOUT_NCHW;
  output_89->dim[0] = 1;
  output_89->dim[1] = 256;
  output_89->dim[2] = 14;
  output_89->dim[3] = 14;
  output_89->dim_count = 4;
  memcpy(output_89->qinfo, params_base + 4790528, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_89 = csinn_alloc_tensor(sess);
  kernel_89->name = "kernel_89";
  kernel_89->data = params_base + 4796696;
  kernel_89->is_const = 1;
  kernel_89->dtype = CSINN_DTYPE_INT8;
  kernel_89->layout = CSINN_LAYOUT_OIHW;
  kernel_89->dim[0] = 256;
  kernel_89->dim[1] = 256;
  kernel_89->dim[2] = 3;
  kernel_89->dim[3] = 3;
  kernel_89->dim_count = 4;
  csinn_realloc_quant_info(kernel_89, 256);
  memcpy(kernel_89->qinfo, params_base + 4790552, sizeof(struct csinn_quant_info) * 256);
  struct csinn_tensor *bias_89 = csinn_alloc_tensor(sess);
  bias_89->name = "bias_89";
  bias_89->data = params_base + 5392664;
  bias_89->is_const = 1;
  bias_89->dtype = CSINN_DTYPE_FLOAT16;
  bias_89->layout = CSINN_LAYOUT_O;
  bias_89->dim[0] = 256;
  bias_89->dim_count = 1;
  csinn_realloc_quant_info(bias_89, 256);
  memcpy(bias_89->qinfo, params_base + 5386520, sizeof(struct csinn_quant_info) * 256);
  struct csinn_conv2d_params *params_89 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_89->group = 1;
  params_89->stride_height = 1;
  params_89->stride_width = 1;
  params_89->dilation_height = 1;
  params_89->dilation_width = 1;
  params_89->conv_extra.kernel_tm = NULL;
  params_89->conv_extra.conv_mode = CSINN_DIRECT;
  params_89->pad_top = 1;
  params_89->pad_left = 1;
  params_89->pad_down = 1;
  params_89->pad_right = 1;
  params_89->base.name = "conv2d_resnetv17_stage3_conv8_fwd_155_fuse_multiply_156_fuse_add_resnetv17_stage3_batchnorm8_fwd_157";
  params_89->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_88, output_89, kernel_89, bias_89, params_89);
  struct csinn_tensor *output_90 = csinn_alloc_tensor(sess);
  output_90->name = "output_90";
  output_90->dtype = CSINN_DTYPE_FLOAT16;
  output_90->layout = CSINN_LAYOUT_NCHW;
  output_90->dim[0] = 1;
  output_90->dim[1] = 256;
  output_90->dim[2] = 14;
  output_90->dim[3] = 14;
  output_90->dim_count = 4;
  memcpy(output_90->qinfo, params_base + 5393176, sizeof(struct csinn_quant_info) * 1);
  struct csinn_relu_params *params_90 = csinn_alloc_params(sizeof(struct csinn_relu_params), sess);
  params_90->base.name = "relu_resnetv17_stage3_relu5_fwd_158";
  params_90->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_relu_init(output_89, output_90, params_90);
  struct csinn_tensor *output_91 = csinn_alloc_tensor(sess);
  output_91->name = "output_91";
  output_91->dtype = CSINN_DTYPE_FLOAT16;
  output_91->layout = CSINN_LAYOUT_NCHW;
  output_91->dim[0] = 1;
  output_91->dim[1] = 1024;
  output_91->dim[2] = 14;
  output_91->dim[3] = 14;
  output_91->dim_count = 4;
  memcpy(output_91->qinfo, params_base + 5393200, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_91 = csinn_alloc_tensor(sess);
  kernel_91->name = "kernel_91";
  kernel_91->data = params_base + 5417800;
  kernel_91->is_const = 1;
  kernel_91->dtype = CSINN_DTYPE_INT8;
  kernel_91->layout = CSINN_LAYOUT_OIHW;
  kernel_91->dim[0] = 1024;
  kernel_91->dim[1] = 256;
  kernel_91->dim[2] = 1;
  kernel_91->dim[3] = 1;
  kernel_91->dim_count = 4;
  csinn_realloc_quant_info(kernel_91, 1024);
  memcpy(kernel_91->qinfo, params_base + 5393224, sizeof(struct csinn_quant_info) * 1024);
  struct csinn_tensor *bias_91 = csinn_alloc_tensor(sess);
  bias_91->name = "bias_91";
  bias_91->data = params_base + 5704520;
  bias_91->is_const = 1;
  bias_91->dtype = CSINN_DTYPE_FLOAT16;
  bias_91->layout = CSINN_LAYOUT_O;
  bias_91->dim[0] = 1024;
  bias_91->dim_count = 1;
  csinn_realloc_quant_info(bias_91, 1024);
  memcpy(bias_91->qinfo, params_base + 5679944, sizeof(struct csinn_quant_info) * 1024);
  struct csinn_conv2d_params *params_91 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_91->group = 1;
  params_91->stride_height = 1;
  params_91->stride_width = 1;
  params_91->dilation_height = 1;
  params_91->dilation_width = 1;
  params_91->conv_extra.kernel_tm = NULL;
  params_91->conv_extra.conv_mode = CSINN_DIRECT;
  params_91->pad_top = 0;
  params_91->pad_left = 0;
  params_91->pad_down = 0;
  params_91->pad_right = 0;
  params_91->base.name = "conv2d_resnetv17_stage3_conv9_fwd_159_fuse_bias_add_resnetv17_stage3_conv9_fwd_160_fuse_multiply_161_fuse_add_resnetv17_stage3_batchnorm9_fwd_162";
  params_91->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_90, output_91, kernel_91, bias_91, params_91);
  struct csinn_tensor *output_93 = csinn_alloc_tensor(sess);
  output_93->name = "output_93";
  output_93->dtype = CSINN_DTYPE_FLOAT16;
  output_93->layout = CSINN_LAYOUT_NCHW;
  output_93->dim[0] = 1;
  output_93->dim[1] = 1024;
  output_93->dim[2] = 14;
  output_93->dim[3] = 14;
  output_93->dim_count = 4;
  memcpy(output_93->qinfo, params_base + 5706568, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_93 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_93->base.name = "add_resnetv17_stage3__plus2_163";
  params_93->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_91, output_86, output_93, params_93);
  struct csinn_tensor *output_95 = csinn_alloc_tensor(sess);
  output_95->name = "output_95";
  output_95->dtype = CSINN_DTYPE_FLOAT16;
  output_95->layout = CSINN_LAYOUT_NCHW;
  output_95->dim[0] = 1;
  output_95->dim[1] = 1024;
  output_95->dim[2] = 14;
  output_95->dim[3] = 14;
  output_95->dim_count = 4;
  memcpy(output_95->qinfo, params_base + 5706592, sizeof(struct csinn_quant_info) * 1);
  struct csinn_relu_params *params_95 = csinn_alloc_params(sizeof(struct csinn_relu_params), sess);
  params_95->base.name = "relu_resnetv17_stage3_activation2_164";
  params_95->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_relu_init(output_93, output_95, params_95);
  struct csinn_tensor *output_96 = csinn_alloc_tensor(sess);
  output_96->name = "output_96";
  output_96->dtype = CSINN_DTYPE_FLOAT16;
  output_96->layout = CSINN_LAYOUT_NCHW;
  output_96->dim[0] = 1;
  output_96->dim[1] = 256;
  output_96->dim[2] = 14;
  output_96->dim[3] = 14;
  output_96->dim_count = 4;
  memcpy(output_96->qinfo, params_base + 5706616, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_96 = csinn_alloc_tensor(sess);
  kernel_96->name = "kernel_96";
  kernel_96->data = params_base + 5712784;
  kernel_96->is_const = 1;
  kernel_96->dtype = CSINN_DTYPE_INT8;
  kernel_96->layout = CSINN_LAYOUT_OIHW;
  kernel_96->dim[0] = 256;
  kernel_96->dim[1] = 1024;
  kernel_96->dim[2] = 1;
  kernel_96->dim[3] = 1;
  kernel_96->dim_count = 4;
  csinn_realloc_quant_info(kernel_96, 256);
  memcpy(kernel_96->qinfo, params_base + 5706640, sizeof(struct csinn_quant_info) * 256);
  struct csinn_tensor *bias_96 = csinn_alloc_tensor(sess);
  bias_96->name = "bias_96";
  bias_96->data = params_base + 5981072;
  bias_96->is_const = 1;
  bias_96->dtype = CSINN_DTYPE_FLOAT16;
  bias_96->layout = CSINN_LAYOUT_O;
  bias_96->dim[0] = 256;
  bias_96->dim_count = 1;
  csinn_realloc_quant_info(bias_96, 256);
  memcpy(bias_96->qinfo, params_base + 5974928, sizeof(struct csinn_quant_info) * 256);
  struct csinn_conv2d_params *params_96 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_96->group = 1;
  params_96->stride_height = 1;
  params_96->stride_width = 1;
  params_96->dilation_height = 1;
  params_96->dilation_width = 1;
  params_96->conv_extra.kernel_tm = NULL;
  params_96->conv_extra.conv_mode = CSINN_DIRECT;
  params_96->pad_top = 0;
  params_96->pad_left = 0;
  params_96->pad_down = 0;
  params_96->pad_right = 0;
  params_96->base.name = "conv2d_resnetv17_stage3_conv10_fwd_165_fuse_bias_add_resnetv17_stage3_conv10_fwd_166_fuse_multiply_167_fuse_add_resnetv17_stage3_batchnorm10_fwd_168";
  params_96->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_95, output_96, kernel_96, bias_96, params_96);
  struct csinn_tensor *output_97 = csinn_alloc_tensor(sess);
  output_97->name = "output_97";
  output_97->dtype = CSINN_DTYPE_FLOAT16;
  output_97->layout = CSINN_LAYOUT_NCHW;
  output_97->dim[0] = 1;
  output_97->dim[1] = 256;
  output_97->dim[2] = 14;
  output_97->dim[3] = 14;
  output_97->dim_count = 4;
  memcpy(output_97->qinfo, params_base + 5981584, sizeof(struct csinn_quant_info) * 1);
  struct csinn_relu_params *params_97 = csinn_alloc_params(sizeof(struct csinn_relu_params), sess);
  params_97->base.name = "relu_resnetv17_stage3_relu6_fwd_169";
  params_97->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_relu_init(output_96, output_97, params_97);
  struct csinn_tensor *output_98 = csinn_alloc_tensor(sess);
  output_98->name = "output_98";
  output_98->dtype = CSINN_DTYPE_FLOAT16;
  output_98->layout = CSINN_LAYOUT_NCHW;
  output_98->dim[0] = 1;
  output_98->dim[1] = 256;
  output_98->dim[2] = 14;
  output_98->dim[3] = 14;
  output_98->dim_count = 4;
  memcpy(output_98->qinfo, params_base + 5981608, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_98 = csinn_alloc_tensor(sess);
  kernel_98->name = "kernel_98";
  kernel_98->data = params_base + 5987776;
  kernel_98->is_const = 1;
  kernel_98->dtype = CSINN_DTYPE_INT8;
  kernel_98->layout = CSINN_LAYOUT_OIHW;
  kernel_98->dim[0] = 256;
  kernel_98->dim[1] = 256;
  kernel_98->dim[2] = 3;
  kernel_98->dim[3] = 3;
  kernel_98->dim_count = 4;
  csinn_realloc_quant_info(kernel_98, 256);
  memcpy(kernel_98->qinfo, params_base + 5981632, sizeof(struct csinn_quant_info) * 256);
  struct csinn_tensor *bias_98 = csinn_alloc_tensor(sess);
  bias_98->name = "bias_98";
  bias_98->data = params_base + 6583744;
  bias_98->is_const = 1;
  bias_98->dtype = CSINN_DTYPE_FLOAT16;
  bias_98->layout = CSINN_LAYOUT_O;
  bias_98->dim[0] = 256;
  bias_98->dim_count = 1;
  csinn_realloc_quant_info(bias_98, 256);
  memcpy(bias_98->qinfo, params_base + 6577600, sizeof(struct csinn_quant_info) * 256);
  struct csinn_conv2d_params *params_98 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_98->group = 1;
  params_98->stride_height = 1;
  params_98->stride_width = 1;
  params_98->dilation_height = 1;
  params_98->dilation_width = 1;
  params_98->conv_extra.kernel_tm = NULL;
  params_98->conv_extra.conv_mode = CSINN_DIRECT;
  params_98->pad_top = 1;
  params_98->pad_left = 1;
  params_98->pad_down = 1;
  params_98->pad_right = 1;
  params_98->base.name = "conv2d_resnetv17_stage3_conv11_fwd_170_fuse_multiply_171_fuse_add_resnetv17_stage3_batchnorm11_fwd_172";
  params_98->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_97, output_98, kernel_98, bias_98, params_98);
  struct csinn_tensor *output_99 = csinn_alloc_tensor(sess);
  output_99->name = "output_99";
  output_99->dtype = CSINN_DTYPE_FLOAT16;
  output_99->layout = CSINN_LAYOUT_NCHW;
  output_99->dim[0] = 1;
  output_99->dim[1] = 256;
  output_99->dim[2] = 14;
  output_99->dim[3] = 14;
  output_99->dim_count = 4;
  memcpy(output_99->qinfo, params_base + 6584256, sizeof(struct csinn_quant_info) * 1);
  struct csinn_relu_params *params_99 = csinn_alloc_params(sizeof(struct csinn_relu_params), sess);
  params_99->base.name = "relu_resnetv17_stage3_relu7_fwd_173";
  params_99->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_relu_init(output_98, output_99, params_99);
  struct csinn_tensor *output_100 = csinn_alloc_tensor(sess);
  output_100->name = "output_100";
  output_100->dtype = CSINN_DTYPE_FLOAT16;
  output_100->layout = CSINN_LAYOUT_NCHW;
  output_100->dim[0] = 1;
  output_100->dim[1] = 1024;
  output_100->dim[2] = 14;
  output_100->dim[3] = 14;
  output_100->dim_count = 4;
  memcpy(output_100->qinfo, params_base + 6584280, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_100 = csinn_alloc_tensor(sess);
  kernel_100->name = "kernel_100";
  kernel_100->data = params_base + 6608880;
  kernel_100->is_const = 1;
  kernel_100->dtype = CSINN_DTYPE_INT8;
  kernel_100->layout = CSINN_LAYOUT_OIHW;
  kernel_100->dim[0] = 1024;
  kernel_100->dim[1] = 256;
  kernel_100->dim[2] = 1;
  kernel_100->dim[3] = 1;
  kernel_100->dim_count = 4;
  csinn_realloc_quant_info(kernel_100, 1024);
  memcpy(kernel_100->qinfo, params_base + 6584304, sizeof(struct csinn_quant_info) * 1024);
  struct csinn_tensor *bias_100 = csinn_alloc_tensor(sess);
  bias_100->name = "bias_100";
  bias_100->data = params_base + 6895600;
  bias_100->is_const = 1;
  bias_100->dtype = CSINN_DTYPE_FLOAT16;
  bias_100->layout = CSINN_LAYOUT_O;
  bias_100->dim[0] = 1024;
  bias_100->dim_count = 1;
  csinn_realloc_quant_info(bias_100, 1024);
  memcpy(bias_100->qinfo, params_base + 6871024, sizeof(struct csinn_quant_info) * 1024);
  struct csinn_conv2d_params *params_100 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_100->group = 1;
  params_100->stride_height = 1;
  params_100->stride_width = 1;
  params_100->dilation_height = 1;
  params_100->dilation_width = 1;
  params_100->conv_extra.kernel_tm = NULL;
  params_100->conv_extra.conv_mode = CSINN_DIRECT;
  params_100->pad_top = 0;
  params_100->pad_left = 0;
  params_100->pad_down = 0;
  params_100->pad_right = 0;
  params_100->base.name = "conv2d_resnetv17_stage3_conv12_fwd_174_fuse_bias_add_resnetv17_stage3_conv12_fwd_175_fuse_multiply_176_fuse_add_resnetv17_stage3_batchnorm12_fwd_177";
  params_100->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_99, output_100, kernel_100, bias_100, params_100);
  struct csinn_tensor *output_102 = csinn_alloc_tensor(sess);
  output_102->name = "output_102";
  output_102->dtype = CSINN_DTYPE_FLOAT16;
  output_102->layout = CSINN_LAYOUT_NCHW;
  output_102->dim[0] = 1;
  output_102->dim[1] = 1024;
  output_102->dim[2] = 14;
  output_102->dim[3] = 14;
  output_102->dim_count = 4;
  memcpy(output_102->qinfo, params_base + 6897648, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_102 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_102->base.name = "add_resnetv17_stage3__plus3_178";
  params_102->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_100, output_95, output_102, params_102);
  struct csinn_tensor *output_104 = csinn_alloc_tensor(sess);
  output_104->name = "output_104";
  output_104->dtype = CSINN_DTYPE_FLOAT16;
  output_104->layout = CSINN_LAYOUT_NCHW;
  output_104->dim[0] = 1;
  output_104->dim[1] = 1024;
  output_104->dim[2] = 14;
  output_104->dim[3] = 14;
  output_104->dim_count = 4;
  memcpy(output_104->qinfo, params_base + 6897672, sizeof(struct csinn_quant_info) * 1);
  struct csinn_relu_params *params_104 = csinn_alloc_params(sizeof(struct csinn_relu_params), sess);
  params_104->base.name = "relu_resnetv17_stage3_activation3_179";
  params_104->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_relu_init(output_102, output_104, params_104);
  struct csinn_tensor *output_105 = csinn_alloc_tensor(sess);
  output_105->name = "output_105";
  output_105->dtype = CSINN_DTYPE_FLOAT16;
  output_105->layout = CSINN_LAYOUT_NCHW;
  output_105->dim[0] = 1;
  output_105->dim[1] = 256;
  output_105->dim[2] = 14;
  output_105->dim[3] = 14;
  output_105->dim_count = 4;
  memcpy(output_105->qinfo, params_base + 6897696, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_105 = csinn_alloc_tensor(sess);
  kernel_105->name = "kernel_105";
  kernel_105->data = params_base + 6903864;
  kernel_105->is_const = 1;
  kernel_105->dtype = CSINN_DTYPE_INT8;
  kernel_105->layout = CSINN_LAYOUT_OIHW;
  kernel_105->dim[0] = 256;
  kernel_105->dim[1] = 1024;
  kernel_105->dim[2] = 1;
  kernel_105->dim[3] = 1;
  kernel_105->dim_count = 4;
  csinn_realloc_quant_info(kernel_105, 256);
  memcpy(kernel_105->qinfo, params_base + 6897720, sizeof(struct csinn_quant_info) * 256);
  struct csinn_tensor *bias_105 = csinn_alloc_tensor(sess);
  bias_105->name = "bias_105";
  bias_105->data = params_base + 7172152;
  bias_105->is_const = 1;
  bias_105->dtype = CSINN_DTYPE_FLOAT16;
  bias_105->layout = CSINN_LAYOUT_O;
  bias_105->dim[0] = 256;
  bias_105->dim_count = 1;
  csinn_realloc_quant_info(bias_105, 256);
  memcpy(bias_105->qinfo, params_base + 7166008, sizeof(struct csinn_quant_info) * 256);
  struct csinn_conv2d_params *params_105 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_105->group = 1;
  params_105->stride_height = 1;
  params_105->stride_width = 1;
  params_105->dilation_height = 1;
  params_105->dilation_width = 1;
  params_105->conv_extra.kernel_tm = NULL;
  params_105->conv_extra.conv_mode = CSINN_DIRECT;
  params_105->pad_top = 0;
  params_105->pad_left = 0;
  params_105->pad_down = 0;
  params_105->pad_right = 0;
  params_105->base.name = "conv2d_resnetv17_stage3_conv13_fwd_180_fuse_bias_add_resnetv17_stage3_conv13_fwd_181_fuse_multiply_182_fuse_add_resnetv17_stage3_batchnorm13_fwd_183";
  params_105->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_104, output_105, kernel_105, bias_105, params_105);
  struct csinn_tensor *output_106 = csinn_alloc_tensor(sess);
  output_106->name = "output_106";
  output_106->dtype = CSINN_DTYPE_FLOAT16;
  output_106->layout = CSINN_LAYOUT_NCHW;
  output_106->dim[0] = 1;
  output_106->dim[1] = 256;
  output_106->dim[2] = 14;
  output_106->dim[3] = 14;
  output_106->dim_count = 4;
  memcpy(output_106->qinfo, params_base + 7172664, sizeof(struct csinn_quant_info) * 1);
  struct csinn_relu_params *params_106 = csinn_alloc_params(sizeof(struct csinn_relu_params), sess);
  params_106->base.name = "relu_resnetv17_stage3_relu8_fwd_184";
  params_106->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_relu_init(output_105, output_106, params_106);
  struct csinn_tensor *output_107 = csinn_alloc_tensor(sess);
  output_107->name = "output_107";
  output_107->dtype = CSINN_DTYPE_FLOAT16;
  output_107->layout = CSINN_LAYOUT_NCHW;
  output_107->dim[0] = 1;
  output_107->dim[1] = 256;
  output_107->dim[2] = 14;
  output_107->dim[3] = 14;
  output_107->dim_count = 4;
  memcpy(output_107->qinfo, params_base + 7172688, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_107 = csinn_alloc_tensor(sess);
  kernel_107->name = "kernel_107";
  kernel_107->data = params_base + 7178856;
  kernel_107->is_const = 1;
  kernel_107->dtype = CSINN_DTYPE_INT8;
  kernel_107->layout = CSINN_LAYOUT_OIHW;
  kernel_107->dim[0] = 256;
  kernel_107->dim[1] = 256;
  kernel_107->dim[2] = 3;
  kernel_107->dim[3] = 3;
  kernel_107->dim_count = 4;
  csinn_realloc_quant_info(kernel_107, 256);
  memcpy(kernel_107->qinfo, params_base + 7172712, sizeof(struct csinn_quant_info) * 256);
  struct csinn_tensor *bias_107 = csinn_alloc_tensor(sess);
  bias_107->name = "bias_107";
  bias_107->data = params_base + 7774824;
  bias_107->is_const = 1;
  bias_107->dtype = CSINN_DTYPE_FLOAT16;
  bias_107->layout = CSINN_LAYOUT_O;
  bias_107->dim[0] = 256;
  bias_107->dim_count = 1;
  csinn_realloc_quant_info(bias_107, 256);
  memcpy(bias_107->qinfo, params_base + 7768680, sizeof(struct csinn_quant_info) * 256);
  struct csinn_conv2d_params *params_107 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_107->group = 1;
  params_107->stride_height = 1;
  params_107->stride_width = 1;
  params_107->dilation_height = 1;
  params_107->dilation_width = 1;
  params_107->conv_extra.kernel_tm = NULL;
  params_107->conv_extra.conv_mode = CSINN_DIRECT;
  params_107->pad_top = 1;
  params_107->pad_left = 1;
  params_107->pad_down = 1;
  params_107->pad_right = 1;
  params_107->base.name = "conv2d_resnetv17_stage3_conv14_fwd_185_fuse_multiply_186_fuse_add_resnetv17_stage3_batchnorm14_fwd_187";
  params_107->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_106, output_107, kernel_107, bias_107, params_107);
  struct csinn_tensor *output_108 = csinn_alloc_tensor(sess);
  output_108->name = "output_108";
  output_108->dtype = CSINN_DTYPE_FLOAT16;
  output_108->layout = CSINN_LAYOUT_NCHW;
  output_108->dim[0] = 1;
  output_108->dim[1] = 256;
  output_108->dim[2] = 14;
  output_108->dim[3] = 14;
  output_108->dim_count = 4;
  memcpy(output_108->qinfo, params_base + 7775336, sizeof(struct csinn_quant_info) * 1);
  struct csinn_relu_params *params_108 = csinn_alloc_params(sizeof(struct csinn_relu_params), sess);
  params_108->base.name = "relu_resnetv17_stage3_relu9_fwd_188";
  params_108->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_relu_init(output_107, output_108, params_108);
  struct csinn_tensor *output_109 = csinn_alloc_tensor(sess);
  output_109->name = "output_109";
  output_109->dtype = CSINN_DTYPE_FLOAT16;
  output_109->layout = CSINN_LAYOUT_NCHW;
  output_109->dim[0] = 1;
  output_109->dim[1] = 1024;
  output_109->dim[2] = 14;
  output_109->dim[3] = 14;
  output_109->dim_count = 4;
  memcpy(output_109->qinfo, params_base + 7775360, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_109 = csinn_alloc_tensor(sess);
  kernel_109->name = "kernel_109";
  kernel_109->data = params_base + 7799960;
  kernel_109->is_const = 1;
  kernel_109->dtype = CSINN_DTYPE_INT8;
  kernel_109->layout = CSINN_LAYOUT_OIHW;
  kernel_109->dim[0] = 1024;
  kernel_109->dim[1] = 256;
  kernel_109->dim[2] = 1;
  kernel_109->dim[3] = 1;
  kernel_109->dim_count = 4;
  csinn_realloc_quant_info(kernel_109, 1024);
  memcpy(kernel_109->qinfo, params_base + 7775384, sizeof(struct csinn_quant_info) * 1024);
  struct csinn_tensor *bias_109 = csinn_alloc_tensor(sess);
  bias_109->name = "bias_109";
  bias_109->data = params_base + 8086680;
  bias_109->is_const = 1;
  bias_109->dtype = CSINN_DTYPE_FLOAT16;
  bias_109->layout = CSINN_LAYOUT_O;
  bias_109->dim[0] = 1024;
  bias_109->dim_count = 1;
  csinn_realloc_quant_info(bias_109, 1024);
  memcpy(bias_109->qinfo, params_base + 8062104, sizeof(struct csinn_quant_info) * 1024);
  struct csinn_conv2d_params *params_109 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_109->group = 1;
  params_109->stride_height = 1;
  params_109->stride_width = 1;
  params_109->dilation_height = 1;
  params_109->dilation_width = 1;
  params_109->conv_extra.kernel_tm = NULL;
  params_109->conv_extra.conv_mode = CSINN_DIRECT;
  params_109->pad_top = 0;
  params_109->pad_left = 0;
  params_109->pad_down = 0;
  params_109->pad_right = 0;
  params_109->base.name = "conv2d_resnetv17_stage3_conv15_fwd_189_fuse_bias_add_resnetv17_stage3_conv15_fwd_190_fuse_multiply_191_fuse_add_resnetv17_stage3_batchnorm15_fwd_192";
  params_109->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_108, output_109, kernel_109, bias_109, params_109);
  struct csinn_tensor *output_111 = csinn_alloc_tensor(sess);
  output_111->name = "output_111";
  output_111->dtype = CSINN_DTYPE_FLOAT16;
  output_111->layout = CSINN_LAYOUT_NCHW;
  output_111->dim[0] = 1;
  output_111->dim[1] = 1024;
  output_111->dim[2] = 14;
  output_111->dim[3] = 14;
  output_111->dim_count = 4;
  memcpy(output_111->qinfo, params_base + 8088728, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_111 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_111->base.name = "add_resnetv17_stage3__plus4_193";
  params_111->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_109, output_104, output_111, params_111);
  struct csinn_tensor *output_113 = csinn_alloc_tensor(sess);
  output_113->name = "output_113";
  output_113->dtype = CSINN_DTYPE_FLOAT16;
  output_113->layout = CSINN_LAYOUT_NCHW;
  output_113->dim[0] = 1;
  output_113->dim[1] = 1024;
  output_113->dim[2] = 14;
  output_113->dim[3] = 14;
  output_113->dim_count = 4;
  memcpy(output_113->qinfo, params_base + 8088752, sizeof(struct csinn_quant_info) * 1);
  struct csinn_relu_params *params_113 = csinn_alloc_params(sizeof(struct csinn_relu_params), sess);
  params_113->base.name = "relu_resnetv17_stage3_activation4_194";
  params_113->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_relu_init(output_111, output_113, params_113);
  struct csinn_tensor *output_114 = csinn_alloc_tensor(sess);
  output_114->name = "output_114";
  output_114->dtype = CSINN_DTYPE_FLOAT16;
  output_114->layout = CSINN_LAYOUT_NCHW;
  output_114->dim[0] = 1;
  output_114->dim[1] = 256;
  output_114->dim[2] = 14;
  output_114->dim[3] = 14;
  output_114->dim_count = 4;
  memcpy(output_114->qinfo, params_base + 8088776, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_114 = csinn_alloc_tensor(sess);
  kernel_114->name = "kernel_114";
  kernel_114->data = params_base + 8094944;
  kernel_114->is_const = 1;
  kernel_114->dtype = CSINN_DTYPE_INT8;
  kernel_114->layout = CSINN_LAYOUT_OIHW;
  kernel_114->dim[0] = 256;
  kernel_114->dim[1] = 1024;
  kernel_114->dim[2] = 1;
  kernel_114->dim[3] = 1;
  kernel_114->dim_count = 4;
  csinn_realloc_quant_info(kernel_114, 256);
  memcpy(kernel_114->qinfo, params_base + 8088800, sizeof(struct csinn_quant_info) * 256);
  struct csinn_tensor *bias_114 = csinn_alloc_tensor(sess);
  bias_114->name = "bias_114";
  bias_114->data = params_base + 8363232;
  bias_114->is_const = 1;
  bias_114->dtype = CSINN_DTYPE_FLOAT16;
  bias_114->layout = CSINN_LAYOUT_O;
  bias_114->dim[0] = 256;
  bias_114->dim_count = 1;
  csinn_realloc_quant_info(bias_114, 256);
  memcpy(bias_114->qinfo, params_base + 8357088, sizeof(struct csinn_quant_info) * 256);
  struct csinn_conv2d_params *params_114 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_114->group = 1;
  params_114->stride_height = 1;
  params_114->stride_width = 1;
  params_114->dilation_height = 1;
  params_114->dilation_width = 1;
  params_114->conv_extra.kernel_tm = NULL;
  params_114->conv_extra.conv_mode = CSINN_DIRECT;
  params_114->pad_top = 0;
  params_114->pad_left = 0;
  params_114->pad_down = 0;
  params_114->pad_right = 0;
  params_114->base.name = "conv2d_resnetv17_stage3_conv16_fwd_195_fuse_bias_add_resnetv17_stage3_conv16_fwd_196_fuse_multiply_197_fuse_add_resnetv17_stage3_batchnorm16_fwd_198";
  params_114->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_113, output_114, kernel_114, bias_114, params_114);
  struct csinn_tensor *output_115 = csinn_alloc_tensor(sess);
  output_115->name = "output_115";
  output_115->dtype = CSINN_DTYPE_FLOAT16;
  output_115->layout = CSINN_LAYOUT_NCHW;
  output_115->dim[0] = 1;
  output_115->dim[1] = 256;
  output_115->dim[2] = 14;
  output_115->dim[3] = 14;
  output_115->dim_count = 4;
  memcpy(output_115->qinfo, params_base + 8363744, sizeof(struct csinn_quant_info) * 1);
  struct csinn_relu_params *params_115 = csinn_alloc_params(sizeof(struct csinn_relu_params), sess);
  params_115->base.name = "relu_resnetv17_stage3_relu10_fwd_199";
  params_115->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_relu_init(output_114, output_115, params_115);
  struct csinn_tensor *output_116 = csinn_alloc_tensor(sess);
  output_116->name = "output_116";
  output_116->dtype = CSINN_DTYPE_FLOAT16;
  output_116->layout = CSINN_LAYOUT_NCHW;
  output_116->dim[0] = 1;
  output_116->dim[1] = 256;
  output_116->dim[2] = 14;
  output_116->dim[3] = 14;
  output_116->dim_count = 4;
  memcpy(output_116->qinfo, params_base + 8363768, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_116 = csinn_alloc_tensor(sess);
  kernel_116->name = "kernel_116";
  kernel_116->data = params_base + 8369936;
  kernel_116->is_const = 1;
  kernel_116->dtype = CSINN_DTYPE_INT8;
  kernel_116->layout = CSINN_LAYOUT_OIHW;
  kernel_116->dim[0] = 256;
  kernel_116->dim[1] = 256;
  kernel_116->dim[2] = 3;
  kernel_116->dim[3] = 3;
  kernel_116->dim_count = 4;
  csinn_realloc_quant_info(kernel_116, 256);
  memcpy(kernel_116->qinfo, params_base + 8363792, sizeof(struct csinn_quant_info) * 256);
  struct csinn_tensor *bias_116 = csinn_alloc_tensor(sess);
  bias_116->name = "bias_116";
  bias_116->data = params_base + 8965904;
  bias_116->is_const = 1;
  bias_116->dtype = CSINN_DTYPE_FLOAT16;
  bias_116->layout = CSINN_LAYOUT_O;
  bias_116->dim[0] = 256;
  bias_116->dim_count = 1;
  csinn_realloc_quant_info(bias_116, 256);
  memcpy(bias_116->qinfo, params_base + 8959760, sizeof(struct csinn_quant_info) * 256);
  struct csinn_conv2d_params *params_116 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_116->group = 1;
  params_116->stride_height = 1;
  params_116->stride_width = 1;
  params_116->dilation_height = 1;
  params_116->dilation_width = 1;
  params_116->conv_extra.kernel_tm = NULL;
  params_116->conv_extra.conv_mode = CSINN_DIRECT;
  params_116->pad_top = 1;
  params_116->pad_left = 1;
  params_116->pad_down = 1;
  params_116->pad_right = 1;
  params_116->base.name = "conv2d_resnetv17_stage3_conv17_fwd_200_fuse_multiply_201_fuse_add_resnetv17_stage3_batchnorm17_fwd_202";
  params_116->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_115, output_116, kernel_116, bias_116, params_116);
  struct csinn_tensor *output_117 = csinn_alloc_tensor(sess);
  output_117->name = "output_117";
  output_117->dtype = CSINN_DTYPE_FLOAT16;
  output_117->layout = CSINN_LAYOUT_NCHW;
  output_117->dim[0] = 1;
  output_117->dim[1] = 256;
  output_117->dim[2] = 14;
  output_117->dim[3] = 14;
  output_117->dim_count = 4;
  memcpy(output_117->qinfo, params_base + 8966416, sizeof(struct csinn_quant_info) * 1);
  struct csinn_relu_params *params_117 = csinn_alloc_params(sizeof(struct csinn_relu_params), sess);
  params_117->base.name = "relu_resnetv17_stage3_relu11_fwd_203";
  params_117->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_relu_init(output_116, output_117, params_117);
  struct csinn_tensor *output_118 = csinn_alloc_tensor(sess);
  output_118->name = "output_118";
  output_118->dtype = CSINN_DTYPE_FLOAT16;
  output_118->layout = CSINN_LAYOUT_NCHW;
  output_118->dim[0] = 1;
  output_118->dim[1] = 1024;
  output_118->dim[2] = 14;
  output_118->dim[3] = 14;
  output_118->dim_count = 4;
  memcpy(output_118->qinfo, params_base + 8966440, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_118 = csinn_alloc_tensor(sess);
  kernel_118->name = "kernel_118";
  kernel_118->data = params_base + 8991040;
  kernel_118->is_const = 1;
  kernel_118->dtype = CSINN_DTYPE_INT8;
  kernel_118->layout = CSINN_LAYOUT_OIHW;
  kernel_118->dim[0] = 1024;
  kernel_118->dim[1] = 256;
  kernel_118->dim[2] = 1;
  kernel_118->dim[3] = 1;
  kernel_118->dim_count = 4;
  csinn_realloc_quant_info(kernel_118, 1024);
  memcpy(kernel_118->qinfo, params_base + 8966464, sizeof(struct csinn_quant_info) * 1024);
  struct csinn_tensor *bias_118 = csinn_alloc_tensor(sess);
  bias_118->name = "bias_118";
  bias_118->data = params_base + 9277760;
  bias_118->is_const = 1;
  bias_118->dtype = CSINN_DTYPE_FLOAT16;
  bias_118->layout = CSINN_LAYOUT_O;
  bias_118->dim[0] = 1024;
  bias_118->dim_count = 1;
  csinn_realloc_quant_info(bias_118, 1024);
  memcpy(bias_118->qinfo, params_base + 9253184, sizeof(struct csinn_quant_info) * 1024);
  struct csinn_conv2d_params *params_118 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_118->group = 1;
  params_118->stride_height = 1;
  params_118->stride_width = 1;
  params_118->dilation_height = 1;
  params_118->dilation_width = 1;
  params_118->conv_extra.kernel_tm = NULL;
  params_118->conv_extra.conv_mode = CSINN_DIRECT;
  params_118->pad_top = 0;
  params_118->pad_left = 0;
  params_118->pad_down = 0;
  params_118->pad_right = 0;
  params_118->base.name = "conv2d_resnetv17_stage3_conv18_fwd_204_fuse_bias_add_resnetv17_stage3_conv18_fwd_205_fuse_multiply_206_fuse_add_resnetv17_stage3_batchnorm18_fwd_207";
  params_118->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_117, output_118, kernel_118, bias_118, params_118);
  struct csinn_tensor *output_120 = csinn_alloc_tensor(sess);
  output_120->name = "output_120";
  output_120->dtype = CSINN_DTYPE_FLOAT16;
  output_120->layout = CSINN_LAYOUT_NCHW;
  output_120->dim[0] = 1;
  output_120->dim[1] = 1024;
  output_120->dim[2] = 14;
  output_120->dim[3] = 14;
  output_120->dim_count = 4;
  memcpy(output_120->qinfo, params_base + 9279808, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_120 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_120->base.name = "add_resnetv17_stage3__plus5_208";
  params_120->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_118, output_113, output_120, params_120);
  struct csinn_tensor *output_122 = csinn_alloc_tensor(sess);
  output_122->name = "output_122";
  output_122->dtype = CSINN_DTYPE_FLOAT16;
  output_122->layout = CSINN_LAYOUT_NCHW;
  output_122->dim[0] = 1;
  output_122->dim[1] = 1024;
  output_122->dim[2] = 14;
  output_122->dim[3] = 14;
  output_122->dim_count = 4;
  memcpy(output_122->qinfo, params_base + 9279832, sizeof(struct csinn_quant_info) * 1);
  struct csinn_relu_params *params_122 = csinn_alloc_params(sizeof(struct csinn_relu_params), sess);
  params_122->base.name = "relu_resnetv17_stage3_activation5_209";
  params_122->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_relu_init(output_120, output_122, params_122);
  struct csinn_tensor *output_123 = csinn_alloc_tensor(sess);
  output_123->name = "output_123";
  output_123->dtype = CSINN_DTYPE_FLOAT16;
  output_123->layout = CSINN_LAYOUT_NCHW;
  output_123->dim[0] = 1;
  output_123->dim[1] = 512;
  output_123->dim[2] = 7;
  output_123->dim[3] = 7;
  output_123->dim_count = 4;
  memcpy(output_123->qinfo, params_base + 9279856, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_123 = csinn_alloc_tensor(sess);
  kernel_123->name = "kernel_123";
  kernel_123->data = params_base + 9292168;
  kernel_123->is_const = 1;
  kernel_123->dtype = CSINN_DTYPE_INT8;
  kernel_123->layout = CSINN_LAYOUT_OIHW;
  kernel_123->dim[0] = 512;
  kernel_123->dim[1] = 1024;
  kernel_123->dim[2] = 1;
  kernel_123->dim[3] = 1;
  kernel_123->dim_count = 4;
  csinn_realloc_quant_info(kernel_123, 512);
  memcpy(kernel_123->qinfo, params_base + 9279880, sizeof(struct csinn_quant_info) * 512);
  struct csinn_tensor *bias_123 = csinn_alloc_tensor(sess);
  bias_123->name = "bias_123";
  bias_123->data = params_base + 9828744;
  bias_123->is_const = 1;
  bias_123->dtype = CSINN_DTYPE_FLOAT16;
  bias_123->layout = CSINN_LAYOUT_O;
  bias_123->dim[0] = 512;
  bias_123->dim_count = 1;
  csinn_realloc_quant_info(bias_123, 512);
  memcpy(bias_123->qinfo, params_base + 9816456, sizeof(struct csinn_quant_info) * 512);
  struct csinn_conv2d_params *params_123 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_123->group = 1;
  params_123->stride_height = 2;
  params_123->stride_width = 2;
  params_123->dilation_height = 1;
  params_123->dilation_width = 1;
  params_123->conv_extra.kernel_tm = NULL;
  params_123->conv_extra.conv_mode = CSINN_DIRECT;
  params_123->pad_top = 0;
  params_123->pad_left = 0;
  params_123->pad_down = 0;
  params_123->pad_right = 0;
  params_123->base.name = "conv2d_resnetv17_stage4_conv0_fwd_210_fuse_bias_add_resnetv17_stage4_conv0_fwd_211_fuse_multiply_212_fuse_add_resnetv17_stage4_batchnorm0_fwd_213";
  params_123->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_122, output_123, kernel_123, bias_123, params_123);
  struct csinn_tensor *output_124 = csinn_alloc_tensor(sess);
  output_124->name = "output_124";
  output_124->dtype = CSINN_DTYPE_FLOAT16;
  output_124->layout = CSINN_LAYOUT_NCHW;
  output_124->dim[0] = 1;
  output_124->dim[1] = 512;
  output_124->dim[2] = 7;
  output_124->dim[3] = 7;
  output_124->dim_count = 4;
  memcpy(output_124->qinfo, params_base + 9829768, sizeof(struct csinn_quant_info) * 1);
  struct csinn_relu_params *params_124 = csinn_alloc_params(sizeof(struct csinn_relu_params), sess);
  params_124->base.name = "relu_resnetv17_stage4_relu0_fwd_214";
  params_124->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_relu_init(output_123, output_124, params_124);
  struct csinn_tensor *output_125 = csinn_alloc_tensor(sess);
  output_125->name = "output_125";
  output_125->dtype = CSINN_DTYPE_FLOAT16;
  output_125->layout = CSINN_LAYOUT_NCHW;
  output_125->dim[0] = 1;
  output_125->dim[1] = 512;
  output_125->dim[2] = 7;
  output_125->dim[3] = 7;
  output_125->dim_count = 4;
  memcpy(output_125->qinfo, params_base + 9829792, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_125 = csinn_alloc_tensor(sess);
  kernel_125->name = "kernel_125";
  kernel_125->data = params_base + 9842104;
  kernel_125->is_const = 1;
  kernel_125->dtype = CSINN_DTYPE_INT8;
  kernel_125->layout = CSINN_LAYOUT_OIHW;
  kernel_125->dim[0] = 512;
  kernel_125->dim[1] = 512;
  kernel_125->dim[2] = 3;
  kernel_125->dim[3] = 3;
  kernel_125->dim_count = 4;
  csinn_realloc_quant_info(kernel_125, 512);
  memcpy(kernel_125->qinfo, params_base + 9829816, sizeof(struct csinn_quant_info) * 512);
  struct csinn_tensor *bias_125 = csinn_alloc_tensor(sess);
  bias_125->name = "bias_125";
  bias_125->data = params_base + 12213688;
  bias_125->is_const = 1;
  bias_125->dtype = CSINN_DTYPE_FLOAT16;
  bias_125->layout = CSINN_LAYOUT_O;
  bias_125->dim[0] = 512;
  bias_125->dim_count = 1;
  csinn_realloc_quant_info(bias_125, 512);
  memcpy(bias_125->qinfo, params_base + 12201400, sizeof(struct csinn_quant_info) * 512);
  struct csinn_conv2d_params *params_125 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_125->group = 1;
  params_125->stride_height = 1;
  params_125->stride_width = 1;
  params_125->dilation_height = 1;
  params_125->dilation_width = 1;
  params_125->conv_extra.kernel_tm = NULL;
  params_125->conv_extra.conv_mode = CSINN_DIRECT;
  params_125->pad_top = 1;
  params_125->pad_left = 1;
  params_125->pad_down = 1;
  params_125->pad_right = 1;
  params_125->base.name = "conv2d_resnetv17_stage4_conv1_fwd_215_fuse_multiply_216_fuse_add_resnetv17_stage4_batchnorm1_fwd_217";
  params_125->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_124, output_125, kernel_125, bias_125, params_125);
  struct csinn_tensor *output_126 = csinn_alloc_tensor(sess);
  output_126->name = "output_126";
  output_126->dtype = CSINN_DTYPE_FLOAT16;
  output_126->layout = CSINN_LAYOUT_NCHW;
  output_126->dim[0] = 1;
  output_126->dim[1] = 512;
  output_126->dim[2] = 7;
  output_126->dim[3] = 7;
  output_126->dim_count = 4;
  memcpy(output_126->qinfo, params_base + 12214712, sizeof(struct csinn_quant_info) * 1);
  struct csinn_relu_params *params_126 = csinn_alloc_params(sizeof(struct csinn_relu_params), sess);
  params_126->base.name = "relu_resnetv17_stage4_relu1_fwd_218";
  params_126->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_relu_init(output_125, output_126, params_126);
  struct csinn_tensor *output_127 = csinn_alloc_tensor(sess);
  output_127->name = "output_127";
  output_127->dtype = CSINN_DTYPE_FLOAT16;
  output_127->layout = CSINN_LAYOUT_NCHW;
  output_127->dim[0] = 1;
  output_127->dim[1] = 2048;
  output_127->dim[2] = 7;
  output_127->dim[3] = 7;
  output_127->dim_count = 4;
  memcpy(output_127->qinfo, params_base + 12214736, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_127 = csinn_alloc_tensor(sess);
  kernel_127->name = "kernel_127";
  kernel_127->data = params_base + 12263912;
  kernel_127->is_const = 1;
  kernel_127->dtype = CSINN_DTYPE_INT8;
  kernel_127->layout = CSINN_LAYOUT_OIHW;
  kernel_127->dim[0] = 2048;
  kernel_127->dim[1] = 512;
  kernel_127->dim[2] = 1;
  kernel_127->dim[3] = 1;
  kernel_127->dim_count = 4;
  csinn_realloc_quant_info(kernel_127, 2048);
  memcpy(kernel_127->qinfo, params_base + 12214760, sizeof(struct csinn_quant_info) * 2048);
  struct csinn_tensor *bias_127 = csinn_alloc_tensor(sess);
  bias_127->name = "bias_127";
  bias_127->data = params_base + 13361640;
  bias_127->is_const = 1;
  bias_127->dtype = CSINN_DTYPE_FLOAT16;
  bias_127->layout = CSINN_LAYOUT_O;
  bias_127->dim[0] = 2048;
  bias_127->dim_count = 1;
  csinn_realloc_quant_info(bias_127, 2048);
  memcpy(bias_127->qinfo, params_base + 13312488, sizeof(struct csinn_quant_info) * 2048);
  struct csinn_conv2d_params *params_127 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_127->group = 1;
  params_127->stride_height = 1;
  params_127->stride_width = 1;
  params_127->dilation_height = 1;
  params_127->dilation_width = 1;
  params_127->conv_extra.kernel_tm = NULL;
  params_127->conv_extra.conv_mode = CSINN_DIRECT;
  params_127->pad_top = 0;
  params_127->pad_left = 0;
  params_127->pad_down = 0;
  params_127->pad_right = 0;
  params_127->base.name = "conv2d_resnetv17_stage4_conv2_fwd_219_fuse_bias_add_resnetv17_stage4_conv2_fwd_220_fuse_multiply_221_fuse_add_resnetv17_stage4_batchnorm2_fwd_222";
  params_127->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_126, output_127, kernel_127, bias_127, params_127);
  struct csinn_tensor *output_129 = csinn_alloc_tensor(sess);
  output_129->name = "output_129";
  output_129->dtype = CSINN_DTYPE_FLOAT16;
  output_129->layout = CSINN_LAYOUT_NCHW;
  output_129->dim[0] = 1;
  output_129->dim[1] = 2048;
  output_129->dim[2] = 7;
  output_129->dim[3] = 7;
  output_129->dim_count = 4;
  memcpy(output_129->qinfo, params_base + 13365736, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_129 = csinn_alloc_tensor(sess);
  kernel_129->name = "kernel_129";
  kernel_129->data = params_base + 13414912;
  kernel_129->is_const = 1;
  kernel_129->dtype = CSINN_DTYPE_INT8;
  kernel_129->layout = CSINN_LAYOUT_OIHW;
  kernel_129->dim[0] = 2048;
  kernel_129->dim[1] = 1024;
  kernel_129->dim[2] = 1;
  kernel_129->dim[3] = 1;
  kernel_129->dim_count = 4;
  csinn_realloc_quant_info(kernel_129, 2048);
  memcpy(kernel_129->qinfo, params_base + 13365760, sizeof(struct csinn_quant_info) * 2048);
  struct csinn_tensor *bias_129 = csinn_alloc_tensor(sess);
  bias_129->name = "bias_129";
  bias_129->data = params_base + 15561216;
  bias_129->is_const = 1;
  bias_129->dtype = CSINN_DTYPE_FLOAT16;
  bias_129->layout = CSINN_LAYOUT_O;
  bias_129->dim[0] = 2048;
  bias_129->dim_count = 1;
  csinn_realloc_quant_info(bias_129, 2048);
  memcpy(bias_129->qinfo, params_base + 15512064, sizeof(struct csinn_quant_info) * 2048);
  struct csinn_conv2d_params *params_129 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_129->group = 1;
  params_129->stride_height = 2;
  params_129->stride_width = 2;
  params_129->dilation_height = 1;
  params_129->dilation_width = 1;
  params_129->conv_extra.kernel_tm = NULL;
  params_129->conv_extra.conv_mode = CSINN_DIRECT;
  params_129->pad_top = 0;
  params_129->pad_left = 0;
  params_129->pad_down = 0;
  params_129->pad_right = 0;
  params_129->base.name = "conv2d_resnetv17_stage4_conv3_fwd_223_fuse_multiply_224_fuse_add_resnetv17_stage4_batchnorm3_fwd_225";
  params_129->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_122, output_129, kernel_129, bias_129, params_129);
  struct csinn_tensor *output_130 = csinn_alloc_tensor(sess);
  output_130->name = "output_130";
  output_130->dtype = CSINN_DTYPE_FLOAT16;
  output_130->layout = CSINN_LAYOUT_NCHW;
  output_130->dim[0] = 1;
  output_130->dim[1] = 2048;
  output_130->dim[2] = 7;
  output_130->dim[3] = 7;
  output_130->dim_count = 4;
  memcpy(output_130->qinfo, params_base + 15565312, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_130 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_130->base.name = "add_resnetv17_stage4__plus0_226";
  params_130->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_127, output_129, output_130, params_130);
  struct csinn_tensor *output_132 = csinn_alloc_tensor(sess);
  output_132->name = "output_132";
  output_132->dtype = CSINN_DTYPE_FLOAT16;
  output_132->layout = CSINN_LAYOUT_NCHW;
  output_132->dim[0] = 1;
  output_132->dim[1] = 2048;
  output_132->dim[2] = 7;
  output_132->dim[3] = 7;
  output_132->dim_count = 4;
  memcpy(output_132->qinfo, params_base + 15565336, sizeof(struct csinn_quant_info) * 1);
  struct csinn_relu_params *params_132 = csinn_alloc_params(sizeof(struct csinn_relu_params), sess);
  params_132->base.name = "relu_resnetv17_stage4_activation0_227";
  params_132->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_relu_init(output_130, output_132, params_132);
  struct csinn_tensor *output_133 = csinn_alloc_tensor(sess);
  output_133->name = "output_133";
  output_133->dtype = CSINN_DTYPE_FLOAT16;
  output_133->layout = CSINN_LAYOUT_NCHW;
  output_133->dim[0] = 1;
  output_133->dim[1] = 512;
  output_133->dim[2] = 7;
  output_133->dim[3] = 7;
  output_133->dim_count = 4;
  memcpy(output_133->qinfo, params_base + 15565360, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_133 = csinn_alloc_tensor(sess);
  kernel_133->name = "kernel_133";
  kernel_133->data = params_base + 15577672;
  kernel_133->is_const = 1;
  kernel_133->dtype = CSINN_DTYPE_INT8;
  kernel_133->layout = CSINN_LAYOUT_OIHW;
  kernel_133->dim[0] = 512;
  kernel_133->dim[1] = 2048;
  kernel_133->dim[2] = 1;
  kernel_133->dim[3] = 1;
  kernel_133->dim_count = 4;
  csinn_realloc_quant_info(kernel_133, 512);
  memcpy(kernel_133->qinfo, params_base + 15565384, sizeof(struct csinn_quant_info) * 512);
  struct csinn_tensor *bias_133 = csinn_alloc_tensor(sess);
  bias_133->name = "bias_133";
  bias_133->data = params_base + 16638536;
  bias_133->is_const = 1;
  bias_133->dtype = CSINN_DTYPE_FLOAT16;
  bias_133->layout = CSINN_LAYOUT_O;
  bias_133->dim[0] = 512;
  bias_133->dim_count = 1;
  csinn_realloc_quant_info(bias_133, 512);
  memcpy(bias_133->qinfo, params_base + 16626248, sizeof(struct csinn_quant_info) * 512);
  struct csinn_conv2d_params *params_133 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_133->group = 1;
  params_133->stride_height = 1;
  params_133->stride_width = 1;
  params_133->dilation_height = 1;
  params_133->dilation_width = 1;
  params_133->conv_extra.kernel_tm = NULL;
  params_133->conv_extra.conv_mode = CSINN_DIRECT;
  params_133->pad_top = 0;
  params_133->pad_left = 0;
  params_133->pad_down = 0;
  params_133->pad_right = 0;
  params_133->base.name = "conv2d_resnetv17_stage4_conv4_fwd_228_fuse_bias_add_resnetv17_stage4_conv4_fwd_229_fuse_multiply_230_fuse_add_resnetv17_stage4_batchnorm4_fwd_231";
  params_133->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_132, output_133, kernel_133, bias_133, params_133);
  struct csinn_tensor *output_134 = csinn_alloc_tensor(sess);
  output_134->name = "output_134";
  output_134->dtype = CSINN_DTYPE_FLOAT16;
  output_134->layout = CSINN_LAYOUT_NCHW;
  output_134->dim[0] = 1;
  output_134->dim[1] = 512;
  output_134->dim[2] = 7;
  output_134->dim[3] = 7;
  output_134->dim_count = 4;
  memcpy(output_134->qinfo, params_base + 16639560, sizeof(struct csinn_quant_info) * 1);
  struct csinn_relu_params *params_134 = csinn_alloc_params(sizeof(struct csinn_relu_params), sess);
  params_134->base.name = "relu_resnetv17_stage4_relu2_fwd_232";
  params_134->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_relu_init(output_133, output_134, params_134);
  struct csinn_tensor *output_135 = csinn_alloc_tensor(sess);
  output_135->name = "output_135";
  output_135->dtype = CSINN_DTYPE_FLOAT16;
  output_135->layout = CSINN_LAYOUT_NCHW;
  output_135->dim[0] = 1;
  output_135->dim[1] = 512;
  output_135->dim[2] = 7;
  output_135->dim[3] = 7;
  output_135->dim_count = 4;
  memcpy(output_135->qinfo, params_base + 16639584, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_135 = csinn_alloc_tensor(sess);
  kernel_135->name = "kernel_135";
  kernel_135->data = params_base + 16651896;
  kernel_135->is_const = 1;
  kernel_135->dtype = CSINN_DTYPE_INT8;
  kernel_135->layout = CSINN_LAYOUT_OIHW;
  kernel_135->dim[0] = 512;
  kernel_135->dim[1] = 512;
  kernel_135->dim[2] = 3;
  kernel_135->dim[3] = 3;
  kernel_135->dim_count = 4;
  csinn_realloc_quant_info(kernel_135, 512);
  memcpy(kernel_135->qinfo, params_base + 16639608, sizeof(struct csinn_quant_info) * 512);
  struct csinn_tensor *bias_135 = csinn_alloc_tensor(sess);
  bias_135->name = "bias_135";
  bias_135->data = params_base + 19023480;
  bias_135->is_const = 1;
  bias_135->dtype = CSINN_DTYPE_FLOAT16;
  bias_135->layout = CSINN_LAYOUT_O;
  bias_135->dim[0] = 512;
  bias_135->dim_count = 1;
  csinn_realloc_quant_info(bias_135, 512);
  memcpy(bias_135->qinfo, params_base + 19011192, sizeof(struct csinn_quant_info) * 512);
  struct csinn_conv2d_params *params_135 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_135->group = 1;
  params_135->stride_height = 1;
  params_135->stride_width = 1;
  params_135->dilation_height = 1;
  params_135->dilation_width = 1;
  params_135->conv_extra.kernel_tm = NULL;
  params_135->conv_extra.conv_mode = CSINN_DIRECT;
  params_135->pad_top = 1;
  params_135->pad_left = 1;
  params_135->pad_down = 1;
  params_135->pad_right = 1;
  params_135->base.name = "conv2d_resnetv17_stage4_conv5_fwd_233_fuse_multiply_234_fuse_add_resnetv17_stage4_batchnorm5_fwd_235";
  params_135->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_134, output_135, kernel_135, bias_135, params_135);
  struct csinn_tensor *output_136 = csinn_alloc_tensor(sess);
  output_136->name = "output_136";
  output_136->dtype = CSINN_DTYPE_FLOAT16;
  output_136->layout = CSINN_LAYOUT_NCHW;
  output_136->dim[0] = 1;
  output_136->dim[1] = 512;
  output_136->dim[2] = 7;
  output_136->dim[3] = 7;
  output_136->dim_count = 4;
  memcpy(output_136->qinfo, params_base + 19024504, sizeof(struct csinn_quant_info) * 1);
  struct csinn_relu_params *params_136 = csinn_alloc_params(sizeof(struct csinn_relu_params), sess);
  params_136->base.name = "relu_resnetv17_stage4_relu3_fwd_236";
  params_136->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_relu_init(output_135, output_136, params_136);
  struct csinn_tensor *output_137 = csinn_alloc_tensor(sess);
  output_137->name = "output_137";
  output_137->dtype = CSINN_DTYPE_FLOAT16;
  output_137->layout = CSINN_LAYOUT_NCHW;
  output_137->dim[0] = 1;
  output_137->dim[1] = 2048;
  output_137->dim[2] = 7;
  output_137->dim[3] = 7;
  output_137->dim_count = 4;
  memcpy(output_137->qinfo, params_base + 19024528, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_137 = csinn_alloc_tensor(sess);
  kernel_137->name = "kernel_137";
  kernel_137->data = params_base + 19073704;
  kernel_137->is_const = 1;
  kernel_137->dtype = CSINN_DTYPE_INT8;
  kernel_137->layout = CSINN_LAYOUT_OIHW;
  kernel_137->dim[0] = 2048;
  kernel_137->dim[1] = 512;
  kernel_137->dim[2] = 1;
  kernel_137->dim[3] = 1;
  kernel_137->dim_count = 4;
  csinn_realloc_quant_info(kernel_137, 2048);
  memcpy(kernel_137->qinfo, params_base + 19024552, sizeof(struct csinn_quant_info) * 2048);
  struct csinn_tensor *bias_137 = csinn_alloc_tensor(sess);
  bias_137->name = "bias_137";
  bias_137->data = params_base + 20171432;
  bias_137->is_const = 1;
  bias_137->dtype = CSINN_DTYPE_FLOAT16;
  bias_137->layout = CSINN_LAYOUT_O;
  bias_137->dim[0] = 2048;
  bias_137->dim_count = 1;
  csinn_realloc_quant_info(bias_137, 2048);
  memcpy(bias_137->qinfo, params_base + 20122280, sizeof(struct csinn_quant_info) * 2048);
  struct csinn_conv2d_params *params_137 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_137->group = 1;
  params_137->stride_height = 1;
  params_137->stride_width = 1;
  params_137->dilation_height = 1;
  params_137->dilation_width = 1;
  params_137->conv_extra.kernel_tm = NULL;
  params_137->conv_extra.conv_mode = CSINN_DIRECT;
  params_137->pad_top = 0;
  params_137->pad_left = 0;
  params_137->pad_down = 0;
  params_137->pad_right = 0;
  params_137->base.name = "conv2d_resnetv17_stage4_conv6_fwd_237_fuse_bias_add_resnetv17_stage4_conv6_fwd_238_fuse_multiply_239_fuse_add_resnetv17_stage4_batchnorm6_fwd_240";
  params_137->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_136, output_137, kernel_137, bias_137, params_137);
  struct csinn_tensor *output_139 = csinn_alloc_tensor(sess);
  output_139->name = "output_139";
  output_139->dtype = CSINN_DTYPE_FLOAT16;
  output_139->layout = CSINN_LAYOUT_NCHW;
  output_139->dim[0] = 1;
  output_139->dim[1] = 2048;
  output_139->dim[2] = 7;
  output_139->dim[3] = 7;
  output_139->dim_count = 4;
  memcpy(output_139->qinfo, params_base + 20175528, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_139 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_139->base.name = "add_resnetv17_stage4__plus1_241";
  params_139->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_137, output_132, output_139, params_139);
  struct csinn_tensor *output_141 = csinn_alloc_tensor(sess);
  output_141->name = "output_141";
  output_141->dtype = CSINN_DTYPE_FLOAT16;
  output_141->layout = CSINN_LAYOUT_NCHW;
  output_141->dim[0] = 1;
  output_141->dim[1] = 2048;
  output_141->dim[2] = 7;
  output_141->dim[3] = 7;
  output_141->dim_count = 4;
  memcpy(output_141->qinfo, params_base + 20175552, sizeof(struct csinn_quant_info) * 1);
  struct csinn_relu_params *params_141 = csinn_alloc_params(sizeof(struct csinn_relu_params), sess);
  params_141->base.name = "relu_resnetv17_stage4_activation1_242";
  params_141->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_relu_init(output_139, output_141, params_141);
  struct csinn_tensor *output_142 = csinn_alloc_tensor(sess);
  output_142->name = "output_142";
  output_142->dtype = CSINN_DTYPE_FLOAT16;
  output_142->layout = CSINN_LAYOUT_NCHW;
  output_142->dim[0] = 1;
  output_142->dim[1] = 512;
  output_142->dim[2] = 7;
  output_142->dim[3] = 7;
  output_142->dim_count = 4;
  memcpy(output_142->qinfo, params_base + 20175576, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_142 = csinn_alloc_tensor(sess);
  kernel_142->name = "kernel_142";
  kernel_142->data = params_base + 20187888;
  kernel_142->is_const = 1;
  kernel_142->dtype = CSINN_DTYPE_INT8;
  kernel_142->layout = CSINN_LAYOUT_OIHW;
  kernel_142->dim[0] = 512;
  kernel_142->dim[1] = 2048;
  kernel_142->dim[2] = 1;
  kernel_142->dim[3] = 1;
  kernel_142->dim_count = 4;
  csinn_realloc_quant_info(kernel_142, 512);
  memcpy(kernel_142->qinfo, params_base + 20175600, sizeof(struct csinn_quant_info) * 512);
  struct csinn_tensor *bias_142 = csinn_alloc_tensor(sess);
  bias_142->name = "bias_142";
  bias_142->data = params_base + 21248752;
  bias_142->is_const = 1;
  bias_142->dtype = CSINN_DTYPE_FLOAT16;
  bias_142->layout = CSINN_LAYOUT_O;
  bias_142->dim[0] = 512;
  bias_142->dim_count = 1;
  csinn_realloc_quant_info(bias_142, 512);
  memcpy(bias_142->qinfo, params_base + 21236464, sizeof(struct csinn_quant_info) * 512);
  struct csinn_conv2d_params *params_142 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_142->group = 1;
  params_142->stride_height = 1;
  params_142->stride_width = 1;
  params_142->dilation_height = 1;
  params_142->dilation_width = 1;
  params_142->conv_extra.kernel_tm = NULL;
  params_142->conv_extra.conv_mode = CSINN_DIRECT;
  params_142->pad_top = 0;
  params_142->pad_left = 0;
  params_142->pad_down = 0;
  params_142->pad_right = 0;
  params_142->base.name = "conv2d_resnetv17_stage4_conv7_fwd_243_fuse_bias_add_resnetv17_stage4_conv7_fwd_244_fuse_multiply_245_fuse_add_resnetv17_stage4_batchnorm7_fwd_246";
  params_142->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_141, output_142, kernel_142, bias_142, params_142);
  struct csinn_tensor *output_143 = csinn_alloc_tensor(sess);
  output_143->name = "output_143";
  output_143->dtype = CSINN_DTYPE_FLOAT16;
  output_143->layout = CSINN_LAYOUT_NCHW;
  output_143->dim[0] = 1;
  output_143->dim[1] = 512;
  output_143->dim[2] = 7;
  output_143->dim[3] = 7;
  output_143->dim_count = 4;
  memcpy(output_143->qinfo, params_base + 21249776, sizeof(struct csinn_quant_info) * 1);
  struct csinn_relu_params *params_143 = csinn_alloc_params(sizeof(struct csinn_relu_params), sess);
  params_143->base.name = "relu_resnetv17_stage4_relu4_fwd_247";
  params_143->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_relu_init(output_142, output_143, params_143);
  struct csinn_tensor *output_144 = csinn_alloc_tensor(sess);
  output_144->name = "output_144";
  output_144->dtype = CSINN_DTYPE_FLOAT16;
  output_144->layout = CSINN_LAYOUT_NCHW;
  output_144->dim[0] = 1;
  output_144->dim[1] = 512;
  output_144->dim[2] = 7;
  output_144->dim[3] = 7;
  output_144->dim_count = 4;
  memcpy(output_144->qinfo, params_base + 21249800, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_144 = csinn_alloc_tensor(sess);
  kernel_144->name = "kernel_144";
  kernel_144->data = params_base + 21262112;
  kernel_144->is_const = 1;
  kernel_144->dtype = CSINN_DTYPE_INT8;
  kernel_144->layout = CSINN_LAYOUT_OIHW;
  kernel_144->dim[0] = 512;
  kernel_144->dim[1] = 512;
  kernel_144->dim[2] = 3;
  kernel_144->dim[3] = 3;
  kernel_144->dim_count = 4;
  csinn_realloc_quant_info(kernel_144, 512);
  memcpy(kernel_144->qinfo, params_base + 21249824, sizeof(struct csinn_quant_info) * 512);
  struct csinn_tensor *bias_144 = csinn_alloc_tensor(sess);
  bias_144->name = "bias_144";
  bias_144->data = params_base + 23633696;
  bias_144->is_const = 1;
  bias_144->dtype = CSINN_DTYPE_FLOAT16;
  bias_144->layout = CSINN_LAYOUT_O;
  bias_144->dim[0] = 512;
  bias_144->dim_count = 1;
  csinn_realloc_quant_info(bias_144, 512);
  memcpy(bias_144->qinfo, params_base + 23621408, sizeof(struct csinn_quant_info) * 512);
  struct csinn_conv2d_params *params_144 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_144->group = 1;
  params_144->stride_height = 1;
  params_144->stride_width = 1;
  params_144->dilation_height = 1;
  params_144->dilation_width = 1;
  params_144->conv_extra.kernel_tm = NULL;
  params_144->conv_extra.conv_mode = CSINN_DIRECT;
  params_144->pad_top = 1;
  params_144->pad_left = 1;
  params_144->pad_down = 1;
  params_144->pad_right = 1;
  params_144->base.name = "conv2d_resnetv17_stage4_conv8_fwd_248_fuse_multiply_249_fuse_add_resnetv17_stage4_batchnorm8_fwd_250";
  params_144->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_143, output_144, kernel_144, bias_144, params_144);
  struct csinn_tensor *output_145 = csinn_alloc_tensor(sess);
  output_145->name = "output_145";
  output_145->dtype = CSINN_DTYPE_FLOAT16;
  output_145->layout = CSINN_LAYOUT_NCHW;
  output_145->dim[0] = 1;
  output_145->dim[1] = 512;
  output_145->dim[2] = 7;
  output_145->dim[3] = 7;
  output_145->dim_count = 4;
  memcpy(output_145->qinfo, params_base + 23634720, sizeof(struct csinn_quant_info) * 1);
  struct csinn_relu_params *params_145 = csinn_alloc_params(sizeof(struct csinn_relu_params), sess);
  params_145->base.name = "relu_resnetv17_stage4_relu5_fwd_251";
  params_145->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_relu_init(output_144, output_145, params_145);
  struct csinn_tensor *output_146 = csinn_alloc_tensor(sess);
  output_146->name = "output_146";
  output_146->dtype = CSINN_DTYPE_FLOAT16;
  output_146->layout = CSINN_LAYOUT_NCHW;
  output_146->dim[0] = 1;
  output_146->dim[1] = 2048;
  output_146->dim[2] = 7;
  output_146->dim[3] = 7;
  output_146->dim_count = 4;
  memcpy(output_146->qinfo, params_base + 23634744, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_146 = csinn_alloc_tensor(sess);
  kernel_146->name = "kernel_146";
  kernel_146->data = params_base + 23683920;
  kernel_146->is_const = 1;
  kernel_146->dtype = CSINN_DTYPE_INT8;
  kernel_146->layout = CSINN_LAYOUT_OIHW;
  kernel_146->dim[0] = 2048;
  kernel_146->dim[1] = 512;
  kernel_146->dim[2] = 1;
  kernel_146->dim[3] = 1;
  kernel_146->dim_count = 4;
  csinn_realloc_quant_info(kernel_146, 2048);
  memcpy(kernel_146->qinfo, params_base + 23634768, sizeof(struct csinn_quant_info) * 2048);
  struct csinn_tensor *bias_146 = csinn_alloc_tensor(sess);
  bias_146->name = "bias_146";
  bias_146->data = params_base + 24781648;
  bias_146->is_const = 1;
  bias_146->dtype = CSINN_DTYPE_FLOAT16;
  bias_146->layout = CSINN_LAYOUT_O;
  bias_146->dim[0] = 2048;
  bias_146->dim_count = 1;
  csinn_realloc_quant_info(bias_146, 2048);
  memcpy(bias_146->qinfo, params_base + 24732496, sizeof(struct csinn_quant_info) * 2048);
  struct csinn_conv2d_params *params_146 = csinn_alloc_params(sizeof(struct csinn_conv2d_params), sess);
  params_146->group = 1;
  params_146->stride_height = 1;
  params_146->stride_width = 1;
  params_146->dilation_height = 1;
  params_146->dilation_width = 1;
  params_146->conv_extra.kernel_tm = NULL;
  params_146->conv_extra.conv_mode = CSINN_DIRECT;
  params_146->pad_top = 0;
  params_146->pad_left = 0;
  params_146->pad_down = 0;
  params_146->pad_right = 0;
  params_146->base.name = "conv2d_resnetv17_stage4_conv9_fwd_252_fuse_bias_add_resnetv17_stage4_conv9_fwd_253_fuse_multiply_254_fuse_add_resnetv17_stage4_batchnorm9_fwd_255";
  params_146->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_conv2d_init(output_145, output_146, kernel_146, bias_146, params_146);
  struct csinn_tensor *output_148 = csinn_alloc_tensor(sess);
  output_148->name = "output_148";
  output_148->dtype = CSINN_DTYPE_FLOAT16;
  output_148->layout = CSINN_LAYOUT_NCHW;
  output_148->dim[0] = 1;
  output_148->dim[1] = 2048;
  output_148->dim[2] = 7;
  output_148->dim[3] = 7;
  output_148->dim_count = 4;
  memcpy(output_148->qinfo, params_base + 24785744, sizeof(struct csinn_quant_info) * 1);
  struct csinn_diso_params *params_148 = csinn_alloc_params(sizeof(struct csinn_diso_params), sess);
  params_148->base.name = "add_resnetv17_stage4__plus2_256";
  params_148->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_add_init(output_146, output_141, output_148, params_148);
  struct csinn_tensor *output_150 = csinn_alloc_tensor(sess);
  output_150->name = "output_150";
  output_150->dtype = CSINN_DTYPE_FLOAT16;
  output_150->layout = CSINN_LAYOUT_NCHW;
  output_150->dim[0] = 1;
  output_150->dim[1] = 2048;
  output_150->dim[2] = 7;
  output_150->dim[3] = 7;
  output_150->dim_count = 4;
  memcpy(output_150->qinfo, params_base + 24785768, sizeof(struct csinn_quant_info) * 1);
  struct csinn_relu_params *params_150 = csinn_alloc_params(sizeof(struct csinn_relu_params), sess);
  params_150->base.name = "relu_resnetv17_stage4_activation2_257";
  params_150->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_relu_init(output_148, output_150, params_150);
  struct csinn_tensor *output_151 = csinn_alloc_tensor(sess);
  output_151->name = "output_151";
  output_151->dtype = CSINN_DTYPE_FLOAT16;
  output_151->layout = CSINN_LAYOUT_NCHW;
  output_151->dim[0] = 1;
  output_151->dim[1] = 2048;
  output_151->dim[2] = 1;
  output_151->dim[3] = 1;
  output_151->dim_count = 4;
  memcpy(output_151->qinfo, params_base + 24785792, sizeof(struct csinn_quant_info) * 1);
  struct csinn_pool_params *params_151 = csinn_alloc_params(sizeof(struct csinn_pool_params), sess);
  params_151->base.name = "global_avg_pool2d_resnetv17_pool1_fwd_258";
  params_151->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_global_avgpool2d_init(output_150, output_151, params_151);
  int32_t *shape_152 = malloc(2 * 4);
  shape_152[0] = 1;
  shape_152[1] = -1;
  struct csinn_tensor *output_152 = csinn_alloc_tensor(sess);
  output_152->name = "output_152";
  output_152->dtype = CSINN_DTYPE_FLOAT16;
  output_152->layout = CSINN_LAYOUT_NC;
  output_152->dim[0] = 1;
  output_152->dim[1] = 2048;
  output_152->dim_count = 2;
  memcpy(output_152->qinfo, params_base + 24785816, sizeof(struct csinn_quant_info) * 1);
  struct csinn_reshape_params *params_152 = csinn_alloc_params(sizeof(struct csinn_reshape_params), sess);
  params_152->shape = shape_152;
  params_152->shape_num = 2;
  params_152->base.name = "batch_flatten_flatten_473_259";
  params_152->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_reshape_init(output_151, output_152, params_152);
  struct csinn_tensor *output_153 = csinn_alloc_tensor(sess);
  output_153->name = "dense_resnetv17_dense0_fwd_260_fuse_add_resnetv17_dense0_fwd@@resnetv17_dense0_fwd_261_153";
  output_153->dtype = CSINN_DTYPE_FLOAT16;
  output_153->layout = CSINN_LAYOUT_NC;
  output_153->dim[0] = 1;
  output_153->dim[1] = 1000;
  output_153->dim_count = 2;
  memcpy(output_153->qinfo, params_base + 24785840, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *kernel_153 = csinn_alloc_tensor(sess);
  kernel_153->name = "kernel_153";
  kernel_153->data = params_base + 24785888;
  kernel_153->is_const = 1;
  kernel_153->dtype = CSINN_DTYPE_INT8;
  kernel_153->layout = CSINN_LAYOUT_OI;
  kernel_153->dim[0] = 1000;
  kernel_153->dim[1] = 2048;
  kernel_153->dim_count = 2;
  memcpy(kernel_153->qinfo, params_base + 24785864, sizeof(struct csinn_quant_info) * 1);
  struct csinn_tensor *bias_153 = csinn_alloc_tensor(sess);
  bias_153->name = "bias_153";
  bias_153->data = params_base + 26833912;
  bias_153->is_const = 1;
  bias_153->dtype = CSINN_DTYPE_FLOAT16;
  bias_153->layout = CSINN_LAYOUT_O;
  bias_153->dim[0] = 1000;
  bias_153->dim_count = 1;
  memcpy(bias_153->qinfo, params_base + 26833888, sizeof(struct csinn_quant_info) * 1);
  struct csinn_fc_params *params_153 = csinn_alloc_params(sizeof(struct csinn_fc_params), sess);
  params_153->units = 1000;
  params_153->base.name = "dense_resnetv17_dense0_fwd_260_fuse_add_resnetv17_dense0_fwd@@resnetv17_dense0_fwd_261";
  params_153->base.quant_type = CSINN_QUANT_FLOAT16_W_INT8;
  csinn_fullyconnected_init(output_152, output_153, kernel_153, bias_153, params_153);
  csinn_set_tensor_entry(data, sess);
  csinn_set_input(0, data, sess);

  csinn_conv2d(data, output_0, kernel_0, bias_0, params_0);
  csinn_relu(output_0, output_1, params_1);
  csinn_maxpool2d(output_1, output_2, params_2);
  csinn_conv2d(output_2, output_3, kernel_3, bias_3, params_3);
  csinn_relu(output_3, output_4, params_4);
  csinn_conv2d(output_4, output_5, kernel_5, bias_5, params_5);
  csinn_relu(output_5, output_6, params_6);
  csinn_conv2d(output_6, output_7, kernel_7, bias_7, params_7);
  csinn_conv2d(output_2, output_9, kernel_9, bias_9, params_9);
  csinn_add(output_7, output_9, output_10, params_10);
  csinn_relu(output_10, output_12, params_12);
  csinn_conv2d(output_12, output_13, kernel_13, bias_13, params_13);
  csinn_relu(output_13, output_14, params_14);
  csinn_conv2d(output_14, output_15, kernel_15, bias_15, params_15);
  csinn_relu(output_15, output_16, params_16);
  csinn_conv2d(output_16, output_17, kernel_17, bias_17, params_17);
  csinn_add(output_17, output_12, output_19, params_19);
  csinn_relu(output_19, output_21, params_21);
  csinn_conv2d(output_21, output_22, kernel_22, bias_22, params_22);
  csinn_relu(output_22, output_23, params_23);
  csinn_conv2d(output_23, output_24, kernel_24, bias_24, params_24);
  csinn_relu(output_24, output_25, params_25);
  csinn_conv2d(output_25, output_26, kernel_26, bias_26, params_26);
  csinn_add(output_26, output_21, output_28, params_28);
  csinn_relu(output_28, output_30, params_30);
  csinn_conv2d(output_30, output_31, kernel_31, bias_31, params_31);
  csinn_relu(output_31, output_32, params_32);
  csinn_conv2d(output_32, output_33, kernel_33, bias_33, params_33);
  csinn_relu(output_33, output_34, params_34);
  csinn_conv2d(output_34, output_35, kernel_35, bias_35, params_35);
  csinn_conv2d(output_30, output_37, kernel_37, bias_37, params_37);
  csinn_add(output_35, output_37, output_38, params_38);
  csinn_relu(output_38, output_40, params_40);
  csinn_conv2d(output_40, output_41, kernel_41, bias_41, params_41);
  csinn_relu(output_41, output_42, params_42);
  csinn_conv2d(output_42, output_43, kernel_43, bias_43, params_43);
  csinn_relu(output_43, output_44, params_44);
  csinn_conv2d(output_44, output_45, kernel_45, bias_45, params_45);
  csinn_add(output_45, output_40, output_47, params_47);
  csinn_relu(output_47, output_49, params_49);
  csinn_conv2d(output_49, output_50, kernel_50, bias_50, params_50);
  csinn_relu(output_50, output_51, params_51);
  csinn_conv2d(output_51, output_52, kernel_52, bias_52, params_52);
  csinn_relu(output_52, output_53, params_53);
  csinn_conv2d(output_53, output_54, kernel_54, bias_54, params_54);
  csinn_add(output_54, output_49, output_56, params_56);
  csinn_relu(output_56, output_58, params_58);
  csinn_conv2d(output_58, output_59, kernel_59, bias_59, params_59);
  csinn_relu(output_59, output_60, params_60);
  csinn_conv2d(output_60, output_61, kernel_61, bias_61, params_61);
  csinn_relu(output_61, output_62, params_62);
  csinn_conv2d(output_62, output_63, kernel_63, bias_63, params_63);
  csinn_add(output_63, output_58, output_65, params_65);
  csinn_relu(output_65, output_67, params_67);
  csinn_conv2d(output_67, output_68, kernel_68, bias_68, params_68);
  csinn_relu(output_68, output_69, params_69);
  csinn_conv2d(output_69, output_70, kernel_70, bias_70, params_70);
  csinn_relu(output_70, output_71, params_71);
  csinn_conv2d(output_71, output_72, kernel_72, bias_72, params_72);
  csinn_conv2d(output_67, output_74, kernel_74, bias_74, params_74);
  csinn_add(output_72, output_74, output_75, params_75);
  csinn_relu(output_75, output_77, params_77);
  csinn_conv2d(output_77, output_78, kernel_78, bias_78, params_78);
  csinn_relu(output_78, output_79, params_79);
  csinn_conv2d(output_79, output_80, kernel_80, bias_80, params_80);
  csinn_relu(output_80, output_81, params_81);
  csinn_conv2d(output_81, output_82, kernel_82, bias_82, params_82);
  csinn_add(output_82, output_77, output_84, params_84);
  csinn_relu(output_84, output_86, params_86);
  csinn_conv2d(output_86, output_87, kernel_87, bias_87, params_87);
  csinn_relu(output_87, output_88, params_88);
  csinn_conv2d(output_88, output_89, kernel_89, bias_89, params_89);
  csinn_relu(output_89, output_90, params_90);
  csinn_conv2d(output_90, output_91, kernel_91, bias_91, params_91);
  csinn_add(output_91, output_86, output_93, params_93);
  csinn_relu(output_93, output_95, params_95);
  csinn_conv2d(output_95, output_96, kernel_96, bias_96, params_96);
  csinn_relu(output_96, output_97, params_97);
  csinn_conv2d(output_97, output_98, kernel_98, bias_98, params_98);
  csinn_relu(output_98, output_99, params_99);
  csinn_conv2d(output_99, output_100, kernel_100, bias_100, params_100);
  csinn_add(output_100, output_95, output_102, params_102);
  csinn_relu(output_102, output_104, params_104);
  csinn_conv2d(output_104, output_105, kernel_105, bias_105, params_105);
  csinn_relu(output_105, output_106, params_106);
  csinn_conv2d(output_106, output_107, kernel_107, bias_107, params_107);
  csinn_relu(output_107, output_108, params_108);
  csinn_conv2d(output_108, output_109, kernel_109, bias_109, params_109);
  csinn_add(output_109, output_104, output_111, params_111);
  csinn_relu(output_111, output_113, params_113);
  csinn_conv2d(output_113, output_114, kernel_114, bias_114, params_114);
  csinn_relu(output_114, output_115, params_115);
  csinn_conv2d(output_115, output_116, kernel_116, bias_116, params_116);
  csinn_relu(output_116, output_117, params_117);
  csinn_conv2d(output_117, output_118, kernel_118, bias_118, params_118);
  csinn_add(output_118, output_113, output_120, params_120);
  csinn_relu(output_120, output_122, params_122);
  csinn_conv2d(output_122, output_123, kernel_123, bias_123, params_123);
  csinn_relu(output_123, output_124, params_124);
  csinn_conv2d(output_124, output_125, kernel_125, bias_125, params_125);
  csinn_relu(output_125, output_126, params_126);
  csinn_conv2d(output_126, output_127, kernel_127, bias_127, params_127);
  csinn_conv2d(output_122, output_129, kernel_129, bias_129, params_129);
  csinn_add(output_127, output_129, output_130, params_130);
  csinn_relu(output_130, output_132, params_132);
  csinn_conv2d(output_132, output_133, kernel_133, bias_133, params_133);
  csinn_relu(output_133, output_134, params_134);
  csinn_conv2d(output_134, output_135, kernel_135, bias_135, params_135);
  csinn_relu(output_135, output_136, params_136);
  csinn_conv2d(output_136, output_137, kernel_137, bias_137, params_137);
  csinn_add(output_137, output_132, output_139, params_139);
  csinn_relu(output_139, output_141, params_141);
  csinn_conv2d(output_141, output_142, kernel_142, bias_142, params_142);
  csinn_relu(output_142, output_143, params_143);
  csinn_conv2d(output_143, output_144, kernel_144, bias_144, params_144);
  csinn_relu(output_144, output_145, params_145);
  csinn_conv2d(output_145, output_146, kernel_146, bias_146, params_146);
  csinn_add(output_146, output_141, output_148, params_148);
  csinn_relu(output_148, output_150, params_150);
  csinn_global_avgpool2d(output_150, output_151, params_151);
  csinn_reshape(output_151, output_152, params_152);
  csinn_fullyconnected(output_152, output_153, kernel_153, bias_153, params_153);
  csinn_set_output(0, output_153, sess);

  csinn_session_setup(sess);
  return sess;
}
void csinn_update_input_and_run(struct csinn_tensor **input_tensors , void *sess) {
  csinn_update_input(0, input_tensors[0], sess);
  csinn_session_run(sess);
}
